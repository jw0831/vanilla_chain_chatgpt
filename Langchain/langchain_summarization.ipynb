{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarization\n",
    "\n",
    "https://python.langchain.com/en/latest/modules/chains/index_examples/summarize.html\n",
    "\n",
    "For a more in depth explanation of what these chain types are, see here.\n",
    "- https://docs.langchain.com/docs/components/chains/index_related_chains\n",
    "\n",
    "# Index-related chains\n",
    "이 범주의 체인은 인덱스와 상호 작용하는 데 사용됩니다. 이 체인의 목적은 인덱스에 저장된 자신의 데이터를 LLM과 결합하는 것입니다. 가장 좋은 예는 자신의 문서에 대한 질문 답변입니다.\n",
    "\n",
    "여기에는 여러 문서를 언어 모델에 전달하는 방법을 이해하는 것이 큰 부분을 차지합니다. 이를 위한 몇 가지 다른 방법, 즉 체인이 있습니다. LangChain은 가장 일반적인 네 가지 방법을 지원하며, 더 많은 방법을 추가하기 위해 적극적으로 노력하고 있으니 아이디어가 있으시면 연락주세요! 어떤 방법을 사용할지 결정하는 것은 상황에 따라 매우 달라질 수 있습니다. 가장 간단한 것부터 가장 복잡한 것까지 순서대로 설명합니다:\n",
    "\n",
    "## stuff\n",
    "스터핑은 가장 간단한 방법으로, 모든 관련 데이터를 프롬프트에 컨텍스트로 채워 언어 모델에 전달하기만 하면 됩니다. 이것은 LangChain에서 StuffDocumentsChain으로 구현됩니다.\n",
    "\n",
    "장점: LLM을 한 번만 호출합니다. 텍스트를 생성할 때 LLM이 모든 데이터에 한 번에 액세스할 수 있습니다.\n",
    "\n",
    "단점: 대부분의 LLM에는 컨텍스트 길이가 있으며, 큰 문서(또는 많은 문서)의 경우 컨텍스트 길이보다 큰 프롬프트가 표시되므로 이 방법은 작동하지 않습니다.\n",
    "\n",
    "이 방법의 가장 큰 단점은 작은 데이터 조각에서만 작동한다는 것입니다. 많은 데이터 조각으로 작업하는 경우에는 이 접근 방식을 더 이상 사용할 수 없습니다. 다음 두 가지 접근 방식은 이러한 문제를 해결하기 위해 고안되었습니다.\n",
    "\n",
    "## map_reduce\n",
    "이 방법은 각 데이터 청크에 대해 초기 프롬프트를 실행하는 것입니다(요약 작업의 경우 해당 청크에 대한 요약이 될 수 있고, 질문 답변 작업의 경우 해당 청크에만 기반한 답변이 될 수 있습니다). 그런 다음 다른 프롬프트가 실행되어 모든 초기 출력을 결합합니다. 이것은 LangChain에서 MapReduceDocumentsChain으로 구현됩니다.\n",
    "\n",
    "장점: StuffDocumentsChain보다 더 큰 문서(및 더 많은 문서)로 확장할 수 있습니다. 개별 문서에서 LLM에 대한 호출은 독립적이므로 병렬화할 수 있습니다.\n",
    "\n",
    "단점: StuffDocumentsChain보다 훨씬 더 많은 LLM 호출이 필요합니다. 최종 결합 호출 중에 일부 정보가 손실됩니다.\n",
    "\n",
    "## refine\n",
    "이 방법은 첫 번째 데이터 청크에서 초기 프롬프트를 실행하여 일부 출력을 생성합니다. 나머지 문서의 경우, 해당 출력이 다음 문서와 함께 전달되어 새 문서를 기반으로 출력을 수정하도록 LLM에 요청합니다.\n",
    "\n",
    "장점: 더 관련성 높은 컨텍스트를 가져올 수 있으며, MapReduceDocumentsChain보다 손실이 적을 수 있습니다.\n",
    "\n",
    "단점: StuffDocumentsChain보다 LLM에 대한 호출이 더 많이 필요합니다. 또한 호출은 독립적이지 않으므로 MapReduceDocumentsChain처럼 병렬로 실행할 수 없습니다. 또한 문서 순서에 대한 잠재적인 종속성이 있습니다.\n",
    "\n",
    "## Map-Rerank\n",
    "\n",
    "이 방법은 각 데이터 청크에 대해 초기 프롬프트를 실행하여 작업을 완료하려고 시도할 뿐만 아니라 답변이 얼마나 확실한지에 대한 점수를 부여하는 것을 포함합니다. 그런 다음 이 점수에 따라 응답의 순위를 매기고 가장 높은 점수를 반환합니다.\n",
    "\n",
    "장점: MapReduceDocumentsChain과 비슷한 장점. MapReduceDocumentsChain에 비해 더 적은 호출이 필요합니다.\n",
    "\n",
    "단점: 문서 간 정보를 결합할 수 없습니다. 즉, 하나의 문서에 하나의 간단한 답변이 있을 것으로 예상할 때 가장 유용합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('인공신경망은 특징이 CPU가 잘하는 일은 아니라는 거예요.\\n'\n",
      " '\\n'\n",
      " '숫자가 5를 넘으면 안녕하세요 말하는 코드를 쓴다.\\n'\n",
      " '\\n'\n",
      " '이거는 용량 진짜로 몇 킬로바이트 안 하거든요? 근데 제가 동일한 일을 하려는 걸 인공신경망으로 만들면 용량이 몇백배 커요.\\n'\n",
      " '\\n'\n",
      " 'NVIDIA GPU도 완벽한 칩은 아니에요.\\n'\n",
      " '\\n'\n",
      " '예전 슈퍼컴퓨터에 그래픽카드 만 개를 엮었다고 했잖아요.\\n'\n",
      " '\\n'\n",
      " '근데 그렇게')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "with open('./정인성작가_transcript.txt', 'r', encoding='utf-8') as f:\n",
    "    transcript = f.read()\n",
    "\n",
    "transcript = transcript.replace('. ', '.\\n\\n')\n",
    "pprint(transcript[:200])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI, PromptTemplate, LLMChain\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains.mapreduce import MapReduceChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "text_splitter = CharacterTextSplitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "# def __init__(self, separator: str = \"\\n\\n\", **kwargs: Any):\n",
    "#         \"\"\"Create a new TextSplitter.\"\"\"\n",
    "#         super().__init__(**kwargs)\n",
    "#         self._separator = separator\n",
    "# split_text 함수를 들어가 보면 \\n\\n을 기준으로 split을 하고 있음\n",
    "texts = text_splitter.split_text(transcript)\n",
    "docs = [Document(page_content=t) for t in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (4380 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4380\n",
      "23071\n",
      "10574\n"
     ]
    }
   ],
   "source": [
    "# docs 하나당 몇 토큰인지 알아보자\n",
    "from transformers import AutoTokenizer\n",
    "import tiktoken\n",
    "\n",
    "electra_tokenizer = AutoTokenizer.from_pretrained(\"monologg/koelectra-base-discriminator\")\n",
    "tokenized_electra = electra_tokenizer.encode(transcript)\n",
    "\n",
    "enc = tiktoken.encoding_for_model(\"text-davinci-003\")\n",
    "tokenized_text_davinci003 = enc.encode(transcript)\n",
    "\n",
    "enc35 = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "tokenized_text_chatgpt35 = enc35.encode(transcript)\n",
    "\n",
    "print(len(tokenized_electra)) # electra : 4380\n",
    "print(len(tokenized_text_davinci003)) # davinci : 23071\n",
    "print(len(tokenized_text_chatgpt35)) # chatgpt : 10574\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='인공신경망은 특징이 CPU가 잘하는 일은 아니라는 거예요.\\n\\n숫자가 5를 넘으면 안녕하세요 말하는 코드를 쓴다.\\n\\n이거는 용량 진짜로 몇 킬로바이트 안 하거든요? 근데 제가 동일한 일을 하려는 걸 인공신경망으로 만들면 용량이 몇백배 커요.\\n\\nNVIDIA GPU도 완벽한 칩은 아니에요.\\n\\n예전 슈퍼컴퓨터에 그래픽카드 만 개를 엮었다고 했잖아요.\\n\\n근데 그렇게 엮으면 비효율도 크고 비용도 크거든요.\\n\\nGPT를 통한 인공지능 변호사 이런 거 만들려면 데이터 장벽부터 있는 거예요.\\n\\n예전에는 PC였고 스마트폰이었고 지금은 서버인데 제 사회의 어떤 수요를 만들려면요.\\n\\n안녕하세요.\\n\\n머니인사이드 시청자 여러분 정인성 작가입니다.\\n\\n저는 원래 반도체 회사에서 반도체 관련한 시뮬레이션 일을 하고 있었고요.\\n\\n최근에 인공지능 관련해서도 새로운 책을 쓸 수 있었고요.\\n\\n지금은 이제 동료들이랑 인공지능 개발 쪽으로 와 있습니다.\\n\\n스타릿에서 어떤...\\n\\n반도체들을 완제품을 만들고 나면 이 반도체들을 또 뭉쳐서 그 위에다가 조그마한 컨트롤러를 붙여서 막 동작을 하게 만들어요.\\n\\n쉽게 말하면 원본 반도체가 아니고 반도체들을 결합해서 새로운 가치를 만드는 거죠.\\n\\n이제 그런 것들을 시뮬레이션으로 검증하는 그런 일들을 했죠.\\n\\n인공지능은 용어를 구분할 필요가 있는데 인공지능은 우리 꿈 같은 거예요.\\n\\n그러니까 우리가 하고 싶은 거 쉽게 말하면 이 인공지능이라는 요소가 딱 잘 정의되진 않는데 예를 들면 예전에 있던 그 바둑에 있는 바둑 AI나 그 스타크래프트에서 이제 컴퓨터 상대를 넣었어요.\\n\\n그런 것도 다 인공지능이라고 불러요.\\n\\n실제로는 그렇게 부를 수 있고요.\\n\\n그러니까 인공지능이라는 것 자체가 굉장히 어마어마한 개념이고 그렇진 않은 거예요.\\n\\n근데 이제 우리 일반인들 입장에서는 좀 터미네이터 같은 걸 생각하겠죠.\\n\\n인공지능으로.\\n\\n저 일하는 입장에서 인공지능은 어떤 물건이냐 하면요.\\n\\n스스로 배워요.\\n\\n그러니까 저는 이제 프로그래머를 짜서 뭐 컴파일을 하거나 아니면 뭐 스크립트를 실행하면 얘가 막 돌아가거든요.\\n\\n근데 시킨 대로 돌아가요.\\n\\n얘는.\\n\\n예를 들면 제가 정말 어렵게 엄청 힘든 건데 프로그램을 막 짜서 개랑 고양이 구분하는 프로그램을 짰다고 해볼게요.\\n\\n근데 이 프로그램은요.\\n\\n제가 그 다음에 코끼리를 어떻게 하려고 하면 다시 짜야 돼요.\\n\\n또.\\n\\n코끼리 구분하는 코드를 막 짜야 되죠.\\n\\n근데 이제 저는 사실 어떻게 하고 싶냐.\\n\\n프로그램 하나 만들어 놓고 코끼리 사진만 막 넣으면 코끼리도 구분했으면 좋겠는 거예요.\\n\\n프로그램이.\\n\\n제가 프로그램을 다시 짜는 것과 있는 프로그램 냅두고 사진만 모아서 긁어 넣는 것 중에 뭐가 쉽겠어요.\\n\\n사진만 넣는 게 훨씬 쉽죠.\\n\\n프로그램 짜라 그러면 끼약하겠지만 코끼리 사진을 1,000개 모아오라 하면 아마 즐겁게 모아올 거라고요.\\n\\n그냥.\\n\\n당연히 훨씬 쉽죠.\\n\\n그게.\\n\\n지금 말하는 인공지능에서 중요한 요소들은 그런 거예요.\\n\\n바둑 인공지능도 다 인공지능이고 한데 지금 우리가 중요하게 여기는 요소는 얘가 스스로 배워서 내놓는 결과를 바꾸는 물건이란 거예요.\\n\\n그쪽을 중요하게 봐온 게 그 인공지능인 거예요.\\n\\n그리고 반도체는 그거와 뭐가 관계가 있느냐.\\n\\n지금 제가 말씀드린 건 다 컨셉이죠.\\n\\n어떻게 만드는지에 대한 얘기가 없잖아요.\\n\\n그래서 그런 인공지능을 만드는 아이디어가 여러 개 있었어요.\\n\\nSVM 뭐 이런 방법도 있고 뭐 그냥 코드를 엄청 무식하게 짜보는 방법도 있고요.\\n\\n뭐 IBM 왓슨처럼 막 만드는 방법도 있는데 요거 다 다른 형태의 프로그램이잖아요.\\n\\n요 방법들 중에 제가 A라는 방법을 택하면 예를 들어 CPU가 빨라야 되고 메모리는 적어도 되고 B라는 방법을 쓰면 CPU보다 메모리가 중요하고 요런 식으로 바뀌어요.\\n\\n왜냐하면 프로그램도 그냥 CPU에서 도는 게 아니고요.\\n\\nCPU가 잘하는 일 중심으로 프로그램을 짜야 빠른 거잖아요.\\n\\n그게 반도체랑 인공지능 기술의 핵심인 거예요.\\n\\n우리는 인공지능이라는 추상적인 개념을 만들고 싶고요.\\n\\n그래서 그 추상적인 개념이 돌아가게 하기 위해서 여러 가지 아이디어를 쓰는 거예요.\\n\\n그중에 지금 제일 잘 되는 게 인공신경망이라는 개념이에요.\\n\\n인간의 뇌세포 구조를 좀 따라해서 그 신경망을 이제 우리 학습시킨 방법을 알아냈기 때문에 학습시키면은 우리가 원하던 인공지능 스스로 뭐 배우고 뭐 진짜 의미로 스스로 배우진 않죠 이제.\\n\\n우리가 코드를 다시 짜지 않아도 데이터만 넣어서 다시 학습시키면 원하는 결과 나오고 그런 걸 할 수 있는 게 이제 인공신경망이에요.\\n\\n근데 이 인공신경망은 특징이 CPU가 잘하는 일은 아니라는 거예요 얘가.\\n\\n그러니까 이제 기존에 CPU만 우리 90년대, 2000년대 CPU만 있었는데 지금 NVIDIA GPU를 쓰는 거예요.\\n\\n우리에겐 하고 싶은 일이 있고 그중에 그 일을 제일 잘하는 방법론을 찾아요.\\n\\n어떤 방식으로 프로그램을 만들어야 스스로 잘 배우는 프로그램이 된다.\\n\\n그리고 그 프로그램들은 각자 원하는 반도체가 달라요.\\n\\n그 일을 잘할 수 있는 반도체가 다르죠.\\n\\n그렇게 움직이는 거예요.\\n\\nCPU와 GPU의 큰 차이가? 사실 둘 다 메모리가 아니고 연산용 칩인데 CPU라는 거는 그 조건 파악을 잘해요.\\n\\n예를 들면 제 입장에서 머니인사이드의 시청자가 몇 명 이상이면 참여하고 아니면은 출연하지 마라.\\n\\n이런 식으로 그 조건이 있으면 선택을 하는 거잖아요.\\n\\n이런 식의 일을 되게 잘해요.\\n\\n그게 그 CPU가 잘하는 일이고요.\\n\\n그리고 GPU는 뭘 잘하냐 하면은 숫자 계산을 엄청 잘해요 그냥.\\n\\n0.1 곱하기 0.4 뭐 이런 숫자를 뭐 수만 개 계산하는 걸 엄청 잘해요.\\n\\n근데 우리가 과거에 봤던 수많은 프로그램들은요.\\n\\n앞에 말했던 조건이 중요해요.\\n\\n예를 들면 엑셀이잖아요.\\n\\n제가 엑셀 칸에다가 함수를 넣으면 만약 함수가 sum이면은 더해라.\\n\\n이런 거죠.\\n\\n이렇게 조건이잖아요 다.\\n\\n그래서 그런 걸 잘하게 설계되어 있어요 CPU는.\\n\\n근데 인공신경만 어떻게 돌아가냐 하면 그냥 입력값을 다 소수점으로 바꾼 다음에 소수점 곱셈을 엄청나게 해요.\\n\\n곱셈, 넛셈을 뭐 수억 번씩 하면 결과가 나오는데 그러면은 결과가 잘 나오는 그런 물건이에요.\\n\\n그러니까 어떻게 보면 인간이 조건을 하나씩 넣어주는 형태 프로그램에서 그냥 모두 다 숫자로 바꿔서 숫자로 와장창 곱하면은 이제 원하는 결과가 튀어나오는 좀 신기한 상황이 된 거죠.\\n\\nQ.\\n\\n인공지능 기술은 어떻게 변화할까요? 어떻게 보면 CPU가 좀 더 똑똑한 칩인데 우리가 지금 보는 인공지능 기술은 좀 무식한 방식으로 좀 더 나은 지성이 구현되어 있는 그런 모습이에요.\\n\\n숫자가 인공지능이 돌아가는 원리? 그러니까 인간 머리가 일단 그런 식으로 돌아가잖아요.\\n\\n왜냐하면 인간 유전자 안에 CPU 설계가 들어있겠어요? 그런 복잡한 설계가 있을까요? 인간 안에? 그 CPU 안에는 그 수십억 개 트랜지스터가 막 연결되어 있는 설계도가 있는데 인간은 그렇지 않잖아요.\\n\\n그래서 뇌세포들은 다 보면은 특정 뇌세포에 자극이 들어오면 인접한 뇌세포에다가 특정 그 역치값을 넘으면 자극을 전달하고 역치를 안 넘으면 자극을 안 전달하고 이렇게 돼 있어요.\\n\\n그 연결관계를 수조개 모아놓으면 지성이 되는 거잖아요.\\n\\n그리고 과거에는 문제가 뭐였냐면은 어 그러면 우리 인간 뇌 모습을 좀 따라해서 이렇게 막 연결하면 지성이 나올 거야.\\n\\n이론상.\\n\\n그 문제는 뭐냐? 이 연결이 예를 들면 A라는 뇌세포랑 B라는 뇌세포 사이 연결을 얼마나 강하게 전달해줘야 돼? 이런 걸 하나도 모르는 거예요.\\n\\n그러니까 우리가 앞에서 말한 프로그래밍이라는 개념은 아까 말한 것처럼 조건문을 쓰는 거였는데 이제는 그 세포와 세포 사이 연결 강도가 0.1이냐 0.3이냐 이런 거를 고민해야 되는 상황이 된 거예요.\\n\\n그 문제가 뭐겠어요? 수십억 개가 있는데 그중에 이거 세포 하나 딱 해서 얘네 둘 사이가 이게 영향을 뭘 주는 거야? 하면 그걸 알아내겠냐는 거예요.\\n\\n그걸 알 수가 없잖아요.\\n\\n그래서 오랫동안 힘들었던 거예요.', metadata={}),\n",
      " Document(page_content='그 문제가 뭐겠어요? 수십억 개가 있는데 그중에 이거 세포 하나 딱 해서 얘네 둘 사이가 이게 영향을 뭘 주는 거야? 하면 그걸 알아내겠냐는 거예요.\\n\\n그걸 알 수가 없잖아요.\\n\\n그래서 오랫동안 힘들었던 거예요.\\n\\n인공지능, 인간 뇌세포를 따라해보자는 아이디어가 뭐 그렇게 참신한가요 이게? 60년대에 이미 나왔던 아이디어예요.\\n\\n근데 왜 사장 되고 이제야 떠올랐냐? 그때는 어 그래 이렇게 하면 될 것 같은데 정확하게는 뇌세포와 뇌세포의 연결관계를 어떻게 해줘야 얘가 잘 돌아가는지를 몰랐던 거야.\\n\\n그러니까 몇십 년을 쉰 거죠.\\n\\n이제 몇십 년 동안 그래서 아무도 못 해보고 있다가 캐나다 쪽에서 이제 그거 학습시키는 방법을 알아낸 거예요 그때.\\n\\n아 여기 데이터를 넣고 결과 값에서 어떤 식으로 계산을 해주면 인공신경망이 서서히 정답률이 올라가게 만들 수 있다.\\n\\n요거를 알아냈어요 그때.\\n\\n그 방법을 써보니까 GPU를 써야 빨라요.\\n\\n그렇게 해서 지금의 상황이 된 거예요 이건.\\n\\n쉽게 말하면 프로그램 쓰는 방법이 바뀌어버린 거예요.\\n\\n기존에는 프로그램 쓸 때 제가 순서도를 놓고 이 순서도를 잘못 자면 버그고 그랬는데요.\\n\\n지금은 인공신경망을 크게 구성을 해놓고 그 안에서 값이 정답을 낼 수 있는 형태로 그 수많은 소수점을 바꿔가야 되는 거예요.\\n\\n그래서 GPU가 필요한 거죠.\\n\\nQ.\\n\\n인공신경망을 어떻게 만들어야 할까요? 원래 옛날 게임들은 화면에 표시하는 거랑 게임의 움직임들 표시하는 걸 전부 CPU가 했어요.\\n\\n근데 이제 컴퓨터라는 게 PC라는 게 나오고 계속 유행하다 보니까 사람들이 점점 더 높은 그래픽을 원해요.\\n\\n점점 더 그래픽 좋은 게임도 하고 싶고 영화도 만들고 싶고 이런 거예요.\\n\\n근데 말씀드렸지만 CPU는 분기 처리를 잘해요.\\n\\n조건 처리를 잘하죠.\\n\\n근데 고급 그래픽을 계속 해보니까 이게 CPU에 잘 맞지 않았던 거예요.\\n\\n그래서 CPU에 잘 맞지 않으니까 VGA라고 부르는 그래픽 전용 칩을 만들어서 쉽게 말하면 이런 거예요.\\n\\n제가 여기 인테리어를 해야 되는데 인테리어 디자인도 하고 벽지도 붙이고 청소도 다 했는데 이제는 CPU가 GPU라고 부르는 협력사를 데려와서 저는 여기는 도배하고 여기는 청소하고 시켜놓으면 이걸 하고 가게 하는 거예요.\\n\\n그리고 저는 이제 앉아서 계속 다음번 도배해야 될 거 찾고 있고요.\\n\\nGPU라는 녀석이 와서 도배 같은 일을 해주는 거예요.\\n\\n이 GPU는 제가 하는 일은 잘 못하지만 제가 잘 못하는 걸 잘하는 거죠.\\n\\n결국은 CPU라는 칩이 모든 일을 잘하기에는 한계가 있었던 거예요.\\n\\n왜냐하면 CPU가 아까 말한 조건문 처리를 잘하려면 그쪽에다 소자를 써야 되는데 거기에 소자를 쓰면은 다른 쪽에 쓸 소자가 없잖아요, 제조할 때.\\n\\n그러니까 모든 걸 잘할 수 없으니까 생겨난 일이죠.\\n\\n다행스럽게도 엔비디아가 의도한 바는 아니겠죠, 아마.\\n\\n인공지능 기술을 해내기 위해서 여러 연구를 하는데 제일 잘 되는 기술이 그래픽이랑 비슷한 연산을 요구했던 거예요.\\n\\n제가 그래픽 돌아가는 거...\\n\\n예, 왜냐하면 그래픽도 결국 소수점 많이 곱하고 더하고 하는 거예요.\\n\\n살짝 얻어걸린 느낌도 있죠, 이거는.\\n\\n그래픽을 했는데 회사가 계속 커야 되니까 CPU는 못하고 GPU는 잘하는 일을 계속 찾아다녔어요, 이 회사가.\\n\\n어, 이게 잘 될 거야 라는 그런 느낌으로 바로 가서 2006년, 2007년에 막 질른 게 아니고 전 세계 사람들이 좀 GPU를 쓰기 편하게 이제 CUDA 이런 걸 만들어놨어요.\\n\\n그러니까 엔비디아 생각이 이런 거예요.\\n\\n아, 이게 그래픽에만 쓰진 않겠지.\\n\\n뭐 슈퍼컴퓨터나 시뮬레이션에도 쓸 수 있고 그래서 그 물리연산하는 회사를 인수하기도 하고 그랬어요.\\n\\n근데 이제 그런 걸 그냥 만들어놓고 칩 쓰세요 라고 하면은 쓰는 법을 몰라요, 사람들이.\\n\\n왜냐하면 제가 CPU용으로 프로그램 짜던 사람이 GPU용으로 프로그램 짜려고 하면 진입장벽이 꽤 높거든요.\\n\\n그래서 엔비디아는 그걸 조금이나마 좀 편하게 해주려고 CUDA 이런 것들을 마련을 해놓은 거죠.\\n\\n근데 그걸 마련해놓은 상황이 이거 쉽게 말하면 캐나다에서 집어다 써본 거에 가까워요.\\n\\n어, 그랬더니 연산속도가 5배 빨라졌어요.\\n\\n뭐 이런 식으로 결과가 나오니까 이제 옆방 대학원생이 이걸로 한 달에 하나 쓰던 논문을 한 달에 5개씩 쓰고 있으면 그러면 나도 써야 되고 그럼 그 옆방 대학원생도 쓰고 할 거잖아요, 당연히.\\n\\n근데 이게 굉장히 반도체 비즈니스에서 사실은 중요한 요소예요.\\n\\n옆사람이 썼는데 안 되던 게 됐잖아요.\\n\\n그러면 그걸 본 옆사람이 쓰죠.\\n\\n그러면 이제 이걸 잘 쓴 사람이 논문 찍어내면서 유명해지죠.\\n\\n그러면 어느 순간 그게 거대한 프로그래머 집단으로 변해요.\\n\\n그러면 이제 지금 2023년 상황에서 제가 대학원 갓 졸업하고 논문 써야 되는데 인공지능으로 논문을 써야 되겠는데 그러면 컴퓨터를 마련하는데 뭘 마련할 거냐 이거예요.\\n\\n전 지금 하나도 안 해봤으니까 일단 남들 하는 걸 다 모방해야 된다니까요.\\n\\n남들 쓰는 컴퓨터 사고 그럼 당연히 엔비디아 GPU 들어가요.\\n\\n그리고 인공지능 한 번도 안 돌려봤으니까 인터넷에 돈을 오픈소스를 받아다가 인공지능을 돌려봐야 돼요.\\n\\n그 오픈소스는 뭘로 쓰여 있겠어요.\\n\\n이것도 엔비디아 GPU를 전제하고 써놨다고요 코드를.\\n\\n그러니까 AMD가 못하는 거예요.\\n\\n이거를 AMD 그래픽 카드로 이제 뭔가 해보려고 실제 실험은 하지도 못하는 거예요.\\n\\n제가 근데 엔비디아 거 쓰면 물어보면 되잖아요.\\n\\n야 넌 어떻게 했니? 이렇게.\\n\\n그게 그 반도체 비즈니스에서 되게 중요한 거예요.\\n\\n생태계예요 이게.\\n\\n어떻게 보면 메모리 같은 건 그런 생태계가 좀 약하고요.\\n\\n인텔의 CPU 같은 것도 그런 생태계를 가지고 있잖아요.\\n\\n그러니까 한참 동안 인텔 CPU가 지금도 그렇게 힘들어해도 살아있는 거예요.\\n\\n여기에 맞춰진 프로그램이 많으니까.\\n\\n반도체 시장은 이제 당분간은 거대 신경망 특히 자연화 신경망이 잘 된다고 했으니까 아마 그쪽 연구개발 수요는 올라갈 거예요.\\n\\n근데 연구개발 이상으로 이제 꾸준한 수요를 만들어내려면 많은 부분에서는 연구를 해봐야 된다고 생각해요.\\n\\n왜냐하면 지금 신경망 학습시키는 게 장점만 있는 건 아니에요.\\n\\n단점은 얘가 인간이랑 제일 큰 차이점이 데이터 한 두 개 보고 학습이 안 된다는 거예요.\\n\\n예를 들면 여기 버닝사이드 시청자 여러분은 영상을 만 개씩 봐야 특정 테마를 익힐 수 있는 것이 아니잖아요.\\n\\n하나만 봐도 익히죠.\\n\\n근데 인공지능은 문제와 정답상 하나 가지고 배울 수가 없고 엄청 많이 봐야 돼요.\\n\\nGPT를 통한 인공지능 변호사 이런 거 만들려면 일단 데이터 장벽부터 있는 거예요.\\n\\n질문과 정답상이 충분히 있냐.\\n\\n그런 것들이 지금은 다 조사가 안 돼 있고 이제야 사람들을 찾아보는 중일 거잖아요.\\n\\n그러니까 저는 당분간은 연구개발 수요는 크겠지만 이게 정말 세상을 바꿀 만큼 여기저기 적용될 건지 아니면 마이크로소프트만 자기들 검색엔진과 오피스에 쓸 건지 이거는 저는 좀 봐야 된다고 생각해요.\\n\\n우리나라의 발표체는 어떻게 쓰일 것인가요? 일단 제일 크게 쓰이는 건 역시 메모리죠.\\n\\n인공신경망의 특징 중 하나는요.\\n\\nCPU용으로 짠 프로그램보다 용량이 엄청나게 크다는 거예요.\\n\\n정말 코드를 잘 짜서 숫자가 5를 넘으면 뭐 안녕하세요 말하는 코드를 쓴다.\\n\\n이거는 용량 진짜로 몇 킬로바이트 안 하거든요.\\n\\n근데 제가 동일한 일을 하려는 걸 인공신경망으로 만들면 용량이 몇백배 커요, 실제로는.\\n\\n그래서 메모리 중에 고용량, 고대역폭 메모리가 중요한 거예요, 지금.\\n\\n일단 한국에서 제일 주요하게 팔리는 것들은 인공지능 쪽에 그 HBM 같은 고용량 고속 메모리들이죠.\\n\\n그쪽에서 확실히 수요가 있다고 봐야죠.\\n\\n그러니까 이런 느낌이에요.\\n\\n예를 들면 제가 CPU 프로그램에다가 1 더하기 1을 계산하게 시키면 프로그램 용량 해봤자 얼마나 하겠어요.\\n\\n근데 저한테 1 더하기 1 물어보고 MRI 찍으면 순식간에 뻘겋뻘겋해졌다가 없어진다고요.\\n\\n되게 비율적이잖아요, 그렇게 보면.\\n\\n용량이 크다니까요, 그렇게.\\n\\n여기 뇌세포 하나하나로 옮겨 놓는 거잖아요.', metadata={}),\n",
      " Document(page_content='그러니까 이런 느낌이에요.\\n\\n예를 들면 제가 CPU 프로그램에다가 1 더하기 1을 계산하게 시키면 프로그램 용량 해봤자 얼마나 하겠어요.\\n\\n근데 저한테 1 더하기 1 물어보고 MRI 찍으면 순식간에 뻘겋뻘겋해졌다가 없어진다고요.\\n\\n되게 비율적이잖아요, 그렇게 보면.\\n\\n용량이 크다니까요, 그렇게.\\n\\n여기 뇌세포 하나하나로 옮겨 놓는 거잖아요.\\n\\n1 더하기 1을 하기 위해서 뇌세포를 거쳐가는 신호의 개수가 뭐 3개겠냐 이거예요.\\n\\n1 더하기 1은 2.\\n\\n3개 들어가면 한 개 답이 나오는 게 아니고 수백억 개가 막 여기서 반응을 하잖아요.\\n\\n그거를 재현해야 되는 거잖아요, 컴퓨터의 내부에 맞춰서.\\n\\n고용량 메모리가 필요할 텐데 당장 물량을 딱 고민해보면 마이크로소프트 엣저이 슈퍼컴퓨터가 엔비디아 V100인가 하는 학습용 GPU를 만 개인가 엮었거든요.\\n\\n근데 이거 만 개 엮으면 이게 메모리 용량이 40만 기가바이트 그래요.\\n\\n엄청 큰 것 같지만 우리 평균 스마트폰에 8기가 들어가잖아요.\\n\\n8기가 들어가면 이거 2만 개 팔아도 스마트폰으로 한 5배? 40이랑 8이니까 5배죠? 그러면 스마트폰 판매량으로는 한 10만 개 정도 되겠네요.\\n\\n근데 스마트폰 1년에 10억 개 팔잖아요, 전 세계에.\\n\\n그러니까 이것만으로는 물량이 엄청 크지 않다는 얘기를 하는 거예요.\\n\\n엣저이 슈퍼컴퓨터 1년에 한 100개씩 팔아도 전체 메모리 물량에서 크진 않죠.\\n\\n물론 메모리 용량된 단가는 크게 쳐주겠지만.\\n\\n그래서 이게 GPT 같은 게 메모리 시장에 예전에는 PC였고, 스마트폰이었고, 지금은 서버인데 제사의 어떤 수요를 만들려면요.\\n\\n지금 연구개발 수요로 안 된다는 이야기를 하는 거예요.\\n\\n연구개발 수요 말고 꾸준히 사용되는 수요가 있어야 되는데 왜냐하면 연구개발하는 건 결국 한 번 사고 잘 안 되면 버릴 거잖아요.\\n\\n근데 꾸준히 써야 되면 연구개발용도 계속 사고 상업용으로도 계속 사야 되니까 수요가 꾸준히 늘어나죠.\\n\\n근데 그걸 알려면 사실 메모리 시장이나 엔비디아를 볼 게 아니고 우리가 GPT 같은 걸로 하고 싶은 사업모델 중에 데이터들의 쌍이 잘 갖춰져 있는 곳이 있나 그거를 알아야 답을 할 수 있다는 얘기인 거예요.\\n\\n전 그래서 지금은 그걸로 메모리 시장이 확 바뀔 거다 그렇게까지는 기대하지 않아요.\\n\\n지금 인공지능은요.\\n\\n우리가 좀 이렇게 착각들을 하는 게 인터넷에는 데이터가 무한하니까 그냥 데이터 넣으면 똑똑해지겠네 라고 생각하거나 그렇지가 않아요.\\n\\n예를 들어서 제가 개와 고양이를 구분시켜야 된다고 하면 사진만 넣는 게 아니라 사진에 개라고 써놔야 돼요.\\n\\n고양이 사진 고양이라고 써놔야 되고요.\\n\\n그렇게 질문과 정답 쌍이 있어야 배울 수 있는 거예요.\\n\\n사진은 그래도 좀 쉽죠.\\n\\n이거 뭐 사람 몇 명 쓰면 사진 100만 개 만들 수 있을 거예요.\\n\\n근데 말하는 인공지능은 어떨까요? 이거 질문과 대답 쌍을 만들기 쉬울까요? 우리 인터넷에 글을 그냥 긁으면 질문과 대답 쌍이 충분히 많이 나올까요? 그러니까 그 안에서는 질문과 대답 쌍 자체를 찾는 것도 되게 어렵고요.\\n\\n그리고 그중에 신뢰할 수 있는 말이 있느냐 이것도 되게 중요해요.\\n\\n지금 GPT 같은 게 학습이 잘 될 수밖에 없는 게 요약 같은 거 되게 잘하거든요.\\n\\n해보면 왜 요약이 잘 되냐 하면요.\\n\\n요약은 이미 그 인터넷에 쌍이 많이 있거든요.\\n\\n제가 일일이 GPT에 만들어줄 몇 테라바이트 데이터를 일일이 질문 답변 쓰는 건 수학적으로 말이 안 돼요.\\n\\n왜냐하면 사람이 열심히 쳐봤자 제가 한 만 단어 치는 것도 힘든데 일주일 동안 근데 얘는 수백억 단어가 필요한데 그거 사람 뽑아서 한다고 되겠어요? 그게? 안 되죠.\\n\\n대부분 있는 데이터 중에 좋은 데이터를 정제해서 쓰는 게 중요해요.\\n\\n근데 예를 들면 요약 같은 거는 위키페디아 이런 거 있잖아요.\\n\\n인트로덕션 안에 사실상 요약이에요.\\n\\n그리고 밑에가 본문이잖아요.\\n\\n본문을 주고 이거 요약해줘 한 다음에 정답을 인트로덕션 같은 걸 넣어서 할 수가 있거든요.\\n\\n그런 일들은 잘 되는 거예요.\\n\\n근데 이제 예를 들면 우리가 GPT가 세상을 바꾸려면 그런 식으로 쓸 수 있는 데이터가 있는 곳이어야 적용 가능한 거예요.\\n\\n예를 들면 제가 법조계 쪽으로 GPT를 쓰고 싶고 GPT를 학습시키고 싶잖아요.\\n\\n그러면 그것도 판례랑 답이 있어야 되는데 그것도 이제 얼마나 좋은 판례인지 이런 걸 다 매겨줘야 된다는 거예요.\\n\\n그 양도 많아야 되는 거죠.\\n\\n그리고 그러고 나면 사업성 문제가 생겨요.\\n\\n그렇게 한국에서 이거 학습을 시켰는데 미국에 쓸 수 있어요, 그거? 못 쓰죠.\\n\\n미국법이 아니니까 그건.\\n\\n이거는 상장된 회사는 아닌데 세레브라스 이런 회사들이 있어요.\\n\\n정확하게는 NVIDIA GPU도 완벽한 칩은 아니에요.\\n\\n인공지능 쪽에서는 범용적이고 쓰기 편한 칩이긴 한데 얘도 한계가 있어요.\\n\\n예를 들면 지금 도는 채집 PT 같은 거 말했지만 애저 슈퍼컴퓨터의 그래픽카드 만 개를 엮었다고 했잖아요.\\n\\n근데 그렇게 엮으면 비효율도 크고 비용도 크거든요.\\n\\n그래서 이제 세레브라스 같은 회사는 그만한 GPU를 하나씩 엮을 바에 이따만한 칩을 웨이퍼 하나에 놓고 그 안에 신경망을 한 번에 다 올리자 이런 식으로 얘기를 해요.\\n\\n이거는 단일 GPU 안에 다 안 들어가서 이거를 쪼개서 담기 위한 노력도 많이 하고 그 비효율이 많거든요.\\n\\n근데 이제 그런 거대한 칩에는 신경망이 한 번에 딱 들어가죠.\\n\\n그러면 기존에 이론상으로는 할 수 있지만 GPU의 용량 한 개로 해보기 힘들었던 걸 많이 해볼 수 있어요.\\n\\n그런 칩들을 쓰면.\\n\\n저는 이제 그런 무류의 칩들을 보는 건 나쁘지 않다고 생각해요.\\n\\n정확하게 이제 조건은 두 개 있어요.\\n\\n이런 칩들이 잘 되려면 첫째로 지금 채집 PT와 비슷한데 거대한 언어모델이죠, 이게.\\n\\n내가 하려고 하는 사업 분야에 데이터가 아까 말한 형태의 데이터가 있고요.\\n\\n그런 데이터들이 풍족하고 근데 NVIDIA GPU 쓰면 원가가 좀 안 나오는 애들.\\n\\n이런 애들일 때 가능성이 있는 거예요.\\n\\n예를 들면 제가 비즈니스를 하고 싶은데 이 채집 PT 같은 거 지금 공개된 거는 한 3,000단어 정도만 입력으로 들어갈 수 있어요.\\n\\n제가 채집 PT랑 대화를 주고받는다 그러면 대화 총합이 3,000단어 넘어가면 까먹어요, 얘는.\\n\\n원래 그런 디자인인 거예요.\\n\\n근데 그거를 늘리려면 늘릴 때 데이터도 많이 필요하고요.\\n\\n늘린 다음에 사양도 훨씬 많이 먹어요.\\n\\n이제 기술 발전이 좀 있긴 하겠지만 지금 상황에서는 그 3,000단어를 6,000단어로 늘리면 4배 정도 커져요, 얘가 대충.\\n\\n연산해야 되니까 4배씩 커지게 되니까 제가 이제 사업 모델을 봤더니 아, 3,000단어는 부족하고 뭐 8만 단어까지 하고 싶다.\\n\\n이러면 NVIDIA GPU 지금 1만 개 엮어서 했는데 몇 개 엮어서 할 거예요, 그때? 100만 개 엮어서 할 건가요? 그렇게 할 수 없잖아요.\\n\\n그러면 새로운 반도체 찾는 거죠.\\n\\n그 아파트들의 검폐율을 보면 보통 17%씩 높입니다.\\n\\n땅을 20평만 지어야 돼요.\\n\\n100평 되려면 10층이 돼야 200평 나오잖아요, 그렇죠? 이 시스템만 아시면 아시면 부동산은 제가 장담하고 있는데 반은 이미 안 갑니다.\\n\\n나머지는 디테일입니다.\\n\\n이걸 정확히 모르고 저 땅이 예쁘다, 이런 거 얘기할 필요 없습니다.', metadata={})]\n",
      "3653\n",
      "3850\n",
      "3387\n"
     ]
    }
   ],
   "source": [
    "pprint(docs)\n",
    "\n",
    "for i in range(3):\n",
    "    print(len(enc35.encode(docs[i].page_content))) \n",
    "    # text splitter를 적용된 문서들의 토큰수를 chatgpt3.5 기준으로 확인해보면 4000토큰 미만으로 나누어짐\n",
    "    # 추가적으로 나누어진 텍스트를 보면 이전 doc의 마지막 문장을 어느정도 포함하고 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "191"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 200 미만으로 문장을 chunk_overlap 함\n",
    "'''\n",
    "class TextSplitter(ABC):\n",
    "    \"\"\"Interface for splitting text into chunks.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        chunk_size: int = 4000,\n",
    "        chunk_overlap: int = 200,\n",
    "        length_function: Callable[[str], int] = len,\n",
    "    ):\n",
    "        \"\"\"Create a new TextSplitter.\"\"\"\n",
    "        if chunk_overlap > chunk_size:\n",
    "            raise ValueError(\n",
    "                f\"Got a larger chunk overlap ({chunk_overlap}) than chunk size \"\n",
    "                f\"({chunk_size}), should be smaller.\"\n",
    "            )\n",
    "        self._chunk_size = chunk_size\n",
    "        self._chunk_overlap = chunk_overlap\n",
    "        self._length_function = length_function\n",
    "'''\n",
    "\n",
    "docs[0].page_content.find('그 문제가')\n",
    "docs[0].page_content[3819:]\n",
    "len(docs[0].page_content[3819:]) # 118\n",
    "docs[1].page_content.find('그러니까 이런 느낌이에요')\n",
    "len(docs[1].page_content[3797:]) # 191"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='인공신경망은 특징이 CPU가 잘하는 일은 아니라는 거예요.\\n\\n숫자가 5를 넘으면 안녕하세요 말하는 코드를 쓴다.\\n\\n이거는 용량 진짜로 몇 킬로바이트 안 하거든요? 근데 제가 동일한 일을 하려는 걸 인공신경망으로 만들면 용량이 몇백배 커요.\\n\\nNVIDIA GPU도 완벽한 칩은 아니에요.\\n\\n예전 슈퍼컴퓨터에 그래픽카드 만 개를 엮었다고 했잖아요.\\n\\n근데 그렇게 엮으면 비효율도 크고 비용도 크거든요.\\n\\nGPT를 통한 인공지능 변호사 이런 거 만들려면 데이터 장벽부터 있는 거예요.\\n\\n예전에는 PC였고 스마트폰이었고 지금은 서버인데 제 사회의 어떤 수요를 만들려면요.\\n\\n안녕하세요.\\n\\n머니인사이드 시청자 여러분 정인성 작가입니다.\\n\\n저는 원래 반도체 회사에서 반도체 관련한 시뮬레이션 일을 하고 있었고요.\\n\\n최근에 인공지능 관련해서도 새로운 책을 쓸 수 있었고요.\\n\\n지금은 이제 동료들이랑 인공지능 개발 쪽으로 와 있습니다.\\n\\n스타릿에서 어떤...\\n\\n반도체들을 완제품을 만들고 나면 이 반도체들을 또 뭉쳐서 그 위에다가 조그마한 컨트롤러를 붙여서 막 동작을 하게 만들어요.\\n\\n쉽게 말하면 원본 반도체가 아니고 반도체들을 결합해서 새로운 가치를 만드는 거죠.\\n\\n이제 그런 것들을 시뮬레이션으로 검증하는 그런 일들을 했죠.\\n\\n인공지능은 용어를 구분할 필요가 있는데 인공지능은 우리 꿈 같은 거예요.\\n\\n그러니까 우리가 하고 싶은 거 쉽게 말하면 이 인공지능이라는 요소가 딱 잘 정의되진 않는데 예를 들면 예전에 있던 그 바둑에 있는 바둑 AI나 그 스타크래프트에서 이제 컴퓨터 상대를 넣었어요.\\n\\n그런 것도 다 인공지능이라고 불러요.\\n\\n실제로는 그렇게 부를 수 있고요.\\n\\n그러니까 인공지능이라는 것 자체가 굉장히 어마어마한 개념이고 그렇진 않은 거예요.\\n\\n근데 이제 우리 일반인들 입장에서는 좀 터미네이터 같은 걸 생각하겠죠.\\n\\n인공지능으로.\\n\\n저 일하는 입장에서 인공지능은 어떤 물건이냐 하면요.\\n\\n스스로 배워요.\\n\\n그러니까 저는 이제 프로그래머를 짜서 뭐 컴파일을 하거나 아니면 뭐 스크립트를 실행하면 얘가 막 돌아가거든요.\\n\\n근데 시킨 대로 돌아가요.\\n\\n얘는.\\n\\n예를 들면 제가 정말 어렵게 엄청 힘든 건데 프로그램을 막 짜서 개랑 고양이 구분하는 프로그램을 짰다고 해볼게요.\\n\\n근데 이 프로그램은요.\\n\\n제가 그 다음에 코끼리를 어떻게 하려고 하면 다시 짜야 돼요.\\n\\n또.\\n\\n코끼리 구분하는 코드를 막 짜야 되죠.\\n\\n근데 이제 저는 사실 어떻게 하고 싶냐.\\n\\n프로그램 하나 만들어 놓고 코끼리 사진만 막 넣으면 코끼리도 구분했으면 좋겠는 거예요.\\n\\n프로그램이.\\n\\n제가 프로그램을 다시 짜는 것과 있는 프로그램 냅두고 사진만 모아서 긁어 넣는 것 중에 뭐가 쉽겠어요.\\n\\n사진만 넣는 게 훨씬 쉽죠.\\n\\n프로그램 짜라 그러면 끼약하겠지만 코끼리 사진을 1,000개 모아오라 하면 아마 즐겁게 모아올 거라고요.\\n\\n그냥.\\n\\n당연히 훨씬 쉽죠.\\n\\n그게.\\n\\n지금 말하는 인공지능에서 중요한 요소들은 그런 거예요.\\n\\n바둑 인공지능도 다 인공지능이고 한데 지금 우리가 중요하게 여기는 요소는 얘가 스스로 배워서 내놓는 결과를 바꾸는 물건이란 거예요.\\n\\n그쪽을 중요하게 봐온 게 그 인공지능인 거예요.\\n\\n그리고 반도체는 그거와 뭐가 관계가 있느냐.\\n\\n지금 제가 말씀드린 건 다 컨셉이죠.\\n\\n어떻게 만드는지에 대한 얘기가 없잖아요.\\n\\n그래서 그런 인공지능을 만드는 아이디어가 여러 개 있었어요.\\n\\nSVM 뭐 이런 방법도 있고 뭐 그냥 코드를 엄청 무식하게 짜보는 방법도 있고요.\\n\\n뭐 IBM 왓슨처럼 막 만드는 방법도 있는데 요거 다 다른 형태의 프로그램이잖아요.\\n\\n요 방법들 중에 제가 A라는 방법을 택하면 예를 들어 CPU가 빨라야 되고 메모리는 적어도 되고 B라는 방법을 쓰면 CPU보다 메모리가 중요하고 요런 식으로 바뀌어요.\\n\\n왜냐하면 프로그램도 그냥 CPU에서 도는 게 아니고요.\\n\\nCPU가 잘하는 일 중심으로 프로그램을 짜야 빠른 거잖아요.\\n\\n그게 반도체랑 인공지능 기술의 핵심인 거예요.\\n\\n우리는 인공지능이라는 추상적인 개념을 만들고 싶고요.\\n\\n그래서 그 추상적인 개념이 돌아가게 하기 위해서 여러 가지 아이디어를 쓰는 거예요.\\n\\n그중에 지금 제일 잘 되는 게 인공신경망이라는 개념이에요.\\n\\n인간의 뇌세포 구조를 좀 따라해서 그 신경망을 이제 우리 학습시킨 방법을 알아냈기 때문에 학습시키면은 우리가 원하던 인공지능 스스로 뭐 배우고 뭐 진짜 의미로 스스로 배우진 않죠 이제.\\n\\n우리가 코드를 다시 짜지 않아도 데이터만 넣어서 다시 학습시키면 원하는 결과 나오고 그런 걸 할 수 있는 게 이제 인공신경망이에요.\\n\\n근데 이 인공신경망은 특징이 CPU가 잘하는 일은 아니라는 거예요 얘가.\\n\\n그러니까 이제 기존에 CPU만 우리 90년대, 2000년대 CPU만 있었는데 지금 NVIDIA GPU를 쓰는 거예요.\\n\\n우리에겐 하고 싶은 일이 있고 그중에 그 일을 제일 잘하는 방법론을 찾아요.\\n\\n어떤 방식으로 프로그램을 만들어야 스스로 잘 배우는 프로그램이 된다.\\n\\n그리고 그 프로그램들은 각자 원하는 반도체가 달라요.\\n\\n그 일을 잘할 수 있는 반도체가 다르죠.\\n\\n그렇게 움직이는 거예요.\\n\\nCPU와 GPU의 큰 차이가? 사실 둘 다 메모리가 아니고 연산용 칩인데 CPU라는 거는 그 조건 파악을 잘해요.\\n\\n예를 들면 제 입장에서 머니인사이드의 시청자가 몇 명 이상이면 참여하고 아니면은 출연하지 마라.\\n\\n이런 식으로 그 조건이 있으면 선택을 하는 거잖아요.\\n\\n이런 식의 일을 되게 잘해요.\\n\\n그게 그 CPU가 잘하는 일이고요.\\n\\n그리고 GPU는 뭘 잘하냐 하면은 숫자 계산을 엄청 잘해요 그냥.\\n\\n0.1 곱하기 0.4 뭐 이런 숫자를 뭐 수만 개 계산하는 걸 엄청 잘해요.\\n\\n근데 우리가 과거에 봤던 수많은 프로그램들은요.\\n\\n앞에 말했던 조건이 중요해요.\\n\\n예를 들면 엑셀이잖아요.\\n\\n제가 엑셀 칸에다가 함수를 넣으면 만약 함수가 sum이면은 더해라.\\n\\n이런 거죠.\\n\\n이렇게 조건이잖아요 다.\\n\\n그래서 그런 걸 잘하게 설계되어 있어요 CPU는.\\n\\n근데 인공신경만 어떻게 돌아가냐 하면 그냥 입력값을 다 소수점으로 바꾼 다음에 소수점 곱셈을 엄청나게 해요.', metadata={}),\n",
      " Document(page_content='앞에 말했던 조건이 중요해요.\\n\\n예를 들면 엑셀이잖아요.\\n\\n제가 엑셀 칸에다가 함수를 넣으면 만약 함수가 sum이면은 더해라.\\n\\n이런 거죠.\\n\\n이렇게 조건이잖아요 다.\\n\\n그래서 그런 걸 잘하게 설계되어 있어요 CPU는.\\n\\n근데 인공신경만 어떻게 돌아가냐 하면 그냥 입력값을 다 소수점으로 바꾼 다음에 소수점 곱셈을 엄청나게 해요.\\n\\n곱셈, 넛셈을 뭐 수억 번씩 하면 결과가 나오는데 그러면은 결과가 잘 나오는 그런 물건이에요.\\n\\n그러니까 어떻게 보면 인간이 조건을 하나씩 넣어주는 형태 프로그램에서 그냥 모두 다 숫자로 바꿔서 숫자로 와장창 곱하면은 이제 원하는 결과가 튀어나오는 좀 신기한 상황이 된 거죠.\\n\\nQ.\\n\\n인공지능 기술은 어떻게 변화할까요? 어떻게 보면 CPU가 좀 더 똑똑한 칩인데 우리가 지금 보는 인공지능 기술은 좀 무식한 방식으로 좀 더 나은 지성이 구현되어 있는 그런 모습이에요.\\n\\n숫자가 인공지능이 돌아가는 원리? 그러니까 인간 머리가 일단 그런 식으로 돌아가잖아요.\\n\\n왜냐하면 인간 유전자 안에 CPU 설계가 들어있겠어요? 그런 복잡한 설계가 있을까요? 인간 안에? 그 CPU 안에는 그 수십억 개 트랜지스터가 막 연결되어 있는 설계도가 있는데 인간은 그렇지 않잖아요.\\n\\n그래서 뇌세포들은 다 보면은 특정 뇌세포에 자극이 들어오면 인접한 뇌세포에다가 특정 그 역치값을 넘으면 자극을 전달하고 역치를 안 넘으면 자극을 안 전달하고 이렇게 돼 있어요.\\n\\n그 연결관계를 수조개 모아놓으면 지성이 되는 거잖아요.\\n\\n그리고 과거에는 문제가 뭐였냐면은 어 그러면 우리 인간 뇌 모습을 좀 따라해서 이렇게 막 연결하면 지성이 나올 거야.\\n\\n이론상.\\n\\n그 문제는 뭐냐? 이 연결이 예를 들면 A라는 뇌세포랑 B라는 뇌세포 사이 연결을 얼마나 강하게 전달해줘야 돼? 이런 걸 하나도 모르는 거예요.\\n\\n그러니까 우리가 앞에서 말한 프로그래밍이라는 개념은 아까 말한 것처럼 조건문을 쓰는 거였는데 이제는 그 세포와 세포 사이 연결 강도가 0.1이냐 0.3이냐 이런 거를 고민해야 되는 상황이 된 거예요.\\n\\n그 문제가 뭐겠어요? 수십억 개가 있는데 그중에 이거 세포 하나 딱 해서 얘네 둘 사이가 이게 영향을 뭘 주는 거야? 하면 그걸 알아내겠냐는 거예요.\\n\\n그걸 알 수가 없잖아요.\\n\\n그래서 오랫동안 힘들었던 거예요.\\n\\n인공지능, 인간 뇌세포를 따라해보자는 아이디어가 뭐 그렇게 참신한가요 이게? 60년대에 이미 나왔던 아이디어예요.\\n\\n근데 왜 사장 되고 이제야 떠올랐냐? 그때는 어 그래 이렇게 하면 될 것 같은데 정확하게는 뇌세포와 뇌세포의 연결관계를 어떻게 해줘야 얘가 잘 돌아가는지를 몰랐던 거야.\\n\\n그러니까 몇십 년을 쉰 거죠.\\n\\n이제 몇십 년 동안 그래서 아무도 못 해보고 있다가 캐나다 쪽에서 이제 그거 학습시키는 방법을 알아낸 거예요 그때.\\n\\n아 여기 데이터를 넣고 결과 값에서 어떤 식으로 계산을 해주면 인공신경망이 서서히 정답률이 올라가게 만들 수 있다.\\n\\n요거를 알아냈어요 그때.\\n\\n그 방법을 써보니까 GPU를 써야 빨라요.\\n\\n그렇게 해서 지금의 상황이 된 거예요 이건.\\n\\n쉽게 말하면 프로그램 쓰는 방법이 바뀌어버린 거예요.\\n\\n기존에는 프로그램 쓸 때 제가 순서도를 놓고 이 순서도를 잘못 자면 버그고 그랬는데요.\\n\\n지금은 인공신경망을 크게 구성을 해놓고 그 안에서 값이 정답을 낼 수 있는 형태로 그 수많은 소수점을 바꿔가야 되는 거예요.\\n\\n그래서 GPU가 필요한 거죠.\\n\\nQ.\\n\\n인공신경망을 어떻게 만들어야 할까요? 원래 옛날 게임들은 화면에 표시하는 거랑 게임의 움직임들 표시하는 걸 전부 CPU가 했어요.\\n\\n근데 이제 컴퓨터라는 게 PC라는 게 나오고 계속 유행하다 보니까 사람들이 점점 더 높은 그래픽을 원해요.\\n\\n점점 더 그래픽 좋은 게임도 하고 싶고 영화도 만들고 싶고 이런 거예요.\\n\\n근데 말씀드렸지만 CPU는 분기 처리를 잘해요.\\n\\n조건 처리를 잘하죠.\\n\\n근데 고급 그래픽을 계속 해보니까 이게 CPU에 잘 맞지 않았던 거예요.\\n\\n그래서 CPU에 잘 맞지 않으니까 VGA라고 부르는 그래픽 전용 칩을 만들어서 쉽게 말하면 이런 거예요.\\n\\n제가 여기 인테리어를 해야 되는데 인테리어 디자인도 하고 벽지도 붙이고 청소도 다 했는데 이제는 CPU가 GPU라고 부르는 협력사를 데려와서 저는 여기는 도배하고 여기는 청소하고 시켜놓으면 이걸 하고 가게 하는 거예요.\\n\\n그리고 저는 이제 앉아서 계속 다음번 도배해야 될 거 찾고 있고요.\\n\\nGPU라는 녀석이 와서 도배 같은 일을 해주는 거예요.\\n\\n이 GPU는 제가 하는 일은 잘 못하지만 제가 잘 못하는 걸 잘하는 거죠.\\n\\n결국은 CPU라는 칩이 모든 일을 잘하기에는 한계가 있었던 거예요.\\n\\n왜냐하면 CPU가 아까 말한 조건문 처리를 잘하려면 그쪽에다 소자를 써야 되는데 거기에 소자를 쓰면은 다른 쪽에 쓸 소자가 없잖아요, 제조할 때.\\n\\n그러니까 모든 걸 잘할 수 없으니까 생겨난 일이죠.\\n\\n다행스럽게도 엔비디아가 의도한 바는 아니겠죠, 아마.\\n\\n인공지능 기술을 해내기 위해서 여러 연구를 하는데 제일 잘 되는 기술이 그래픽이랑 비슷한 연산을 요구했던 거예요.\\n\\n제가 그래픽 돌아가는 거...\\n\\n예, 왜냐하면 그래픽도 결국 소수점 많이 곱하고 더하고 하는 거예요.\\n\\n살짝 얻어걸린 느낌도 있죠, 이거는.\\n\\n그래픽을 했는데 회사가 계속 커야 되니까 CPU는 못하고 GPU는 잘하는 일을 계속 찾아다녔어요, 이 회사가.\\n\\n어, 이게 잘 될 거야 라는 그런 느낌으로 바로 가서 2006년, 2007년에 막 질른 게 아니고 전 세계 사람들이 좀 GPU를 쓰기 편하게 이제 CUDA 이런 걸 만들어놨어요.\\n\\n그러니까 엔비디아 생각이 이런 거예요.\\n\\n아, 이게 그래픽에만 쓰진 않겠지.\\n\\n뭐 슈퍼컴퓨터나 시뮬레이션에도 쓸 수 있고 그래서 그 물리연산하는 회사를 인수하기도 하고 그랬어요.\\n\\n근데 이제 그런 걸 그냥 만들어놓고 칩 쓰세요 라고 하면은 쓰는 법을 몰라요, 사람들이.\\n\\n왜냐하면 제가 CPU용으로 프로그램 짜던 사람이 GPU용으로 프로그램 짜려고 하면 진입장벽이 꽤 높거든요.', metadata={}),\n",
      " Document(page_content='아, 이게 그래픽에만 쓰진 않겠지.\\n\\n뭐 슈퍼컴퓨터나 시뮬레이션에도 쓸 수 있고 그래서 그 물리연산하는 회사를 인수하기도 하고 그랬어요.\\n\\n근데 이제 그런 걸 그냥 만들어놓고 칩 쓰세요 라고 하면은 쓰는 법을 몰라요, 사람들이.\\n\\n왜냐하면 제가 CPU용으로 프로그램 짜던 사람이 GPU용으로 프로그램 짜려고 하면 진입장벽이 꽤 높거든요.\\n\\n그래서 엔비디아는 그걸 조금이나마 좀 편하게 해주려고 CUDA 이런 것들을 마련을 해놓은 거죠.\\n\\n근데 그걸 마련해놓은 상황이 이거 쉽게 말하면 캐나다에서 집어다 써본 거에 가까워요.\\n\\n어, 그랬더니 연산속도가 5배 빨라졌어요.\\n\\n뭐 이런 식으로 결과가 나오니까 이제 옆방 대학원생이 이걸로 한 달에 하나 쓰던 논문을 한 달에 5개씩 쓰고 있으면 그러면 나도 써야 되고 그럼 그 옆방 대학원생도 쓰고 할 거잖아요, 당연히.\\n\\n근데 이게 굉장히 반도체 비즈니스에서 사실은 중요한 요소예요.\\n\\n옆사람이 썼는데 안 되던 게 됐잖아요.\\n\\n그러면 그걸 본 옆사람이 쓰죠.\\n\\n그러면 이제 이걸 잘 쓴 사람이 논문 찍어내면서 유명해지죠.\\n\\n그러면 어느 순간 그게 거대한 프로그래머 집단으로 변해요.\\n\\n그러면 이제 지금 2023년 상황에서 제가 대학원 갓 졸업하고 논문 써야 되는데 인공지능으로 논문을 써야 되겠는데 그러면 컴퓨터를 마련하는데 뭘 마련할 거냐 이거예요.\\n\\n전 지금 하나도 안 해봤으니까 일단 남들 하는 걸 다 모방해야 된다니까요.\\n\\n남들 쓰는 컴퓨터 사고 그럼 당연히 엔비디아 GPU 들어가요.\\n\\n그리고 인공지능 한 번도 안 돌려봤으니까 인터넷에 돈을 오픈소스를 받아다가 인공지능을 돌려봐야 돼요.\\n\\n그 오픈소스는 뭘로 쓰여 있겠어요.\\n\\n이것도 엔비디아 GPU를 전제하고 써놨다고요 코드를.\\n\\n그러니까 AMD가 못하는 거예요.\\n\\n이거를 AMD 그래픽 카드로 이제 뭔가 해보려고 실제 실험은 하지도 못하는 거예요.\\n\\n제가 근데 엔비디아 거 쓰면 물어보면 되잖아요.\\n\\n야 넌 어떻게 했니? 이렇게.\\n\\n그게 그 반도체 비즈니스에서 되게 중요한 거예요.\\n\\n생태계예요 이게.\\n\\n어떻게 보면 메모리 같은 건 그런 생태계가 좀 약하고요.\\n\\n인텔의 CPU 같은 것도 그런 생태계를 가지고 있잖아요.\\n\\n그러니까 한참 동안 인텔 CPU가 지금도 그렇게 힘들어해도 살아있는 거예요.\\n\\n여기에 맞춰진 프로그램이 많으니까.\\n\\n반도체 시장은 이제 당분간은 거대 신경망 특히 자연화 신경망이 잘 된다고 했으니까 아마 그쪽 연구개발 수요는 올라갈 거예요.\\n\\n근데 연구개발 이상으로 이제 꾸준한 수요를 만들어내려면 많은 부분에서는 연구를 해봐야 된다고 생각해요.\\n\\n왜냐하면 지금 신경망 학습시키는 게 장점만 있는 건 아니에요.\\n\\n단점은 얘가 인간이랑 제일 큰 차이점이 데이터 한 두 개 보고 학습이 안 된다는 거예요.\\n\\n예를 들면 여기 버닝사이드 시청자 여러분은 영상을 만 개씩 봐야 특정 테마를 익힐 수 있는 것이 아니잖아요.\\n\\n하나만 봐도 익히죠.\\n\\n근데 인공지능은 문제와 정답상 하나 가지고 배울 수가 없고 엄청 많이 봐야 돼요.\\n\\nGPT를 통한 인공지능 변호사 이런 거 만들려면 일단 데이터 장벽부터 있는 거예요.\\n\\n질문과 정답상이 충분히 있냐.\\n\\n그런 것들이 지금은 다 조사가 안 돼 있고 이제야 사람들을 찾아보는 중일 거잖아요.\\n\\n그러니까 저는 당분간은 연구개발 수요는 크겠지만 이게 정말 세상을 바꿀 만큼 여기저기 적용될 건지 아니면 마이크로소프트만 자기들 검색엔진과 오피스에 쓸 건지 이거는 저는 좀 봐야 된다고 생각해요.\\n\\n우리나라의 발표체는 어떻게 쓰일 것인가요? 일단 제일 크게 쓰이는 건 역시 메모리죠.\\n\\n인공신경망의 특징 중 하나는요.\\n\\nCPU용으로 짠 프로그램보다 용량이 엄청나게 크다는 거예요.\\n\\n정말 코드를 잘 짜서 숫자가 5를 넘으면 뭐 안녕하세요 말하는 코드를 쓴다.\\n\\n이거는 용량 진짜로 몇 킬로바이트 안 하거든요.\\n\\n근데 제가 동일한 일을 하려는 걸 인공신경망으로 만들면 용량이 몇백배 커요, 실제로는.\\n\\n그래서 메모리 중에 고용량, 고대역폭 메모리가 중요한 거예요, 지금.\\n\\n일단 한국에서 제일 주요하게 팔리는 것들은 인공지능 쪽에 그 HBM 같은 고용량 고속 메모리들이죠.\\n\\n그쪽에서 확실히 수요가 있다고 봐야죠.\\n\\n그러니까 이런 느낌이에요.\\n\\n예를 들면 제가 CPU 프로그램에다가 1 더하기 1을 계산하게 시키면 프로그램 용량 해봤자 얼마나 하겠어요.\\n\\n근데 저한테 1 더하기 1 물어보고 MRI 찍으면 순식간에 뻘겋뻘겋해졌다가 없어진다고요.\\n\\n되게 비율적이잖아요, 그렇게 보면.\\n\\n용량이 크다니까요, 그렇게.\\n\\n여기 뇌세포 하나하나로 옮겨 놓는 거잖아요.\\n\\n1 더하기 1을 하기 위해서 뇌세포를 거쳐가는 신호의 개수가 뭐 3개겠냐 이거예요.\\n\\n1 더하기 1은 2.\\n\\n3개 들어가면 한 개 답이 나오는 게 아니고 수백억 개가 막 여기서 반응을 하잖아요.\\n\\n그거를 재현해야 되는 거잖아요, 컴퓨터의 내부에 맞춰서.\\n\\n고용량 메모리가 필요할 텐데 당장 물량을 딱 고민해보면 마이크로소프트 엣저이 슈퍼컴퓨터가 엔비디아 V100인가 하는 학습용 GPU를 만 개인가 엮었거든요.\\n\\n근데 이거 만 개 엮으면 이게 메모리 용량이 40만 기가바이트 그래요.\\n\\n엄청 큰 것 같지만 우리 평균 스마트폰에 8기가 들어가잖아요.\\n\\n8기가 들어가면 이거 2만 개 팔아도 스마트폰으로 한 5배? 40이랑 8이니까 5배죠? 그러면 스마트폰 판매량으로는 한 10만 개 정도 되겠네요.\\n\\n근데 스마트폰 1년에 10억 개 팔잖아요, 전 세계에.\\n\\n그러니까 이것만으로는 물량이 엄청 크지 않다는 얘기를 하는 거예요.\\n\\n엣저이 슈퍼컴퓨터 1년에 한 100개씩 팔아도 전체 메모리 물량에서 크진 않죠.\\n\\n물론 메모리 용량된 단가는 크게 쳐주겠지만.\\n\\n그래서 이게 GPT 같은 게 메모리 시장에 예전에는 PC였고, 스마트폰이었고, 지금은 서버인데 제사의 어떤 수요를 만들려면요.\\n\\n지금 연구개발 수요로 안 된다는 이야기를 하는 거예요.\\n\\n연구개발 수요 말고 꾸준히 사용되는 수요가 있어야 되는데 왜냐하면 연구개발하는 건 결국 한 번 사고 잘 안 되면 버릴 거잖아요.', metadata={}),\n",
      " Document(page_content='그래서 이게 GPT 같은 게 메모리 시장에 예전에는 PC였고, 스마트폰이었고, 지금은 서버인데 제사의 어떤 수요를 만들려면요.\\n\\n지금 연구개발 수요로 안 된다는 이야기를 하는 거예요.\\n\\n연구개발 수요 말고 꾸준히 사용되는 수요가 있어야 되는데 왜냐하면 연구개발하는 건 결국 한 번 사고 잘 안 되면 버릴 거잖아요.\\n\\n근데 꾸준히 써야 되면 연구개발용도 계속 사고 상업용으로도 계속 사야 되니까 수요가 꾸준히 늘어나죠.\\n\\n근데 그걸 알려면 사실 메모리 시장이나 엔비디아를 볼 게 아니고 우리가 GPT 같은 걸로 하고 싶은 사업모델 중에 데이터들의 쌍이 잘 갖춰져 있는 곳이 있나 그거를 알아야 답을 할 수 있다는 얘기인 거예요.\\n\\n전 그래서 지금은 그걸로 메모리 시장이 확 바뀔 거다 그렇게까지는 기대하지 않아요.\\n\\n지금 인공지능은요.\\n\\n우리가 좀 이렇게 착각들을 하는 게 인터넷에는 데이터가 무한하니까 그냥 데이터 넣으면 똑똑해지겠네 라고 생각하거나 그렇지가 않아요.\\n\\n예를 들어서 제가 개와 고양이를 구분시켜야 된다고 하면 사진만 넣는 게 아니라 사진에 개라고 써놔야 돼요.\\n\\n고양이 사진 고양이라고 써놔야 되고요.\\n\\n그렇게 질문과 정답 쌍이 있어야 배울 수 있는 거예요.\\n\\n사진은 그래도 좀 쉽죠.\\n\\n이거 뭐 사람 몇 명 쓰면 사진 100만 개 만들 수 있을 거예요.\\n\\n근데 말하는 인공지능은 어떨까요? 이거 질문과 대답 쌍을 만들기 쉬울까요? 우리 인터넷에 글을 그냥 긁으면 질문과 대답 쌍이 충분히 많이 나올까요? 그러니까 그 안에서는 질문과 대답 쌍 자체를 찾는 것도 되게 어렵고요.\\n\\n그리고 그중에 신뢰할 수 있는 말이 있느냐 이것도 되게 중요해요.\\n\\n지금 GPT 같은 게 학습이 잘 될 수밖에 없는 게 요약 같은 거 되게 잘하거든요.\\n\\n해보면 왜 요약이 잘 되냐 하면요.\\n\\n요약은 이미 그 인터넷에 쌍이 많이 있거든요.\\n\\n제가 일일이 GPT에 만들어줄 몇 테라바이트 데이터를 일일이 질문 답변 쓰는 건 수학적으로 말이 안 돼요.\\n\\n왜냐하면 사람이 열심히 쳐봤자 제가 한 만 단어 치는 것도 힘든데 일주일 동안 근데 얘는 수백억 단어가 필요한데 그거 사람 뽑아서 한다고 되겠어요? 그게? 안 되죠.\\n\\n대부분 있는 데이터 중에 좋은 데이터를 정제해서 쓰는 게 중요해요.\\n\\n근데 예를 들면 요약 같은 거는 위키페디아 이런 거 있잖아요.\\n\\n인트로덕션 안에 사실상 요약이에요.\\n\\n그리고 밑에가 본문이잖아요.\\n\\n본문을 주고 이거 요약해줘 한 다음에 정답을 인트로덕션 같은 걸 넣어서 할 수가 있거든요.\\n\\n그런 일들은 잘 되는 거예요.\\n\\n근데 이제 예를 들면 우리가 GPT가 세상을 바꾸려면 그런 식으로 쓸 수 있는 데이터가 있는 곳이어야 적용 가능한 거예요.\\n\\n예를 들면 제가 법조계 쪽으로 GPT를 쓰고 싶고 GPT를 학습시키고 싶잖아요.\\n\\n그러면 그것도 판례랑 답이 있어야 되는데 그것도 이제 얼마나 좋은 판례인지 이런 걸 다 매겨줘야 된다는 거예요.\\n\\n그 양도 많아야 되는 거죠.\\n\\n그리고 그러고 나면 사업성 문제가 생겨요.\\n\\n그렇게 한국에서 이거 학습을 시켰는데 미국에 쓸 수 있어요, 그거? 못 쓰죠.\\n\\n미국법이 아니니까 그건.\\n\\n이거는 상장된 회사는 아닌데 세레브라스 이런 회사들이 있어요.\\n\\n정확하게는 NVIDIA GPU도 완벽한 칩은 아니에요.\\n\\n인공지능 쪽에서는 범용적이고 쓰기 편한 칩이긴 한데 얘도 한계가 있어요.\\n\\n예를 들면 지금 도는 채집 PT 같은 거 말했지만 애저 슈퍼컴퓨터의 그래픽카드 만 개를 엮었다고 했잖아요.\\n\\n근데 그렇게 엮으면 비효율도 크고 비용도 크거든요.\\n\\n그래서 이제 세레브라스 같은 회사는 그만한 GPU를 하나씩 엮을 바에 이따만한 칩을 웨이퍼 하나에 놓고 그 안에 신경망을 한 번에 다 올리자 이런 식으로 얘기를 해요.\\n\\n이거는 단일 GPU 안에 다 안 들어가서 이거를 쪼개서 담기 위한 노력도 많이 하고 그 비효율이 많거든요.\\n\\n근데 이제 그런 거대한 칩에는 신경망이 한 번에 딱 들어가죠.\\n\\n그러면 기존에 이론상으로는 할 수 있지만 GPU의 용량 한 개로 해보기 힘들었던 걸 많이 해볼 수 있어요.\\n\\n그런 칩들을 쓰면.\\n\\n저는 이제 그런 무류의 칩들을 보는 건 나쁘지 않다고 생각해요.\\n\\n정확하게 이제 조건은 두 개 있어요.\\n\\n이런 칩들이 잘 되려면 첫째로 지금 채집 PT와 비슷한데 거대한 언어모델이죠, 이게.\\n\\n내가 하려고 하는 사업 분야에 데이터가 아까 말한 형태의 데이터가 있고요.\\n\\n그런 데이터들이 풍족하고 근데 NVIDIA GPU 쓰면 원가가 좀 안 나오는 애들.\\n\\n이런 애들일 때 가능성이 있는 거예요.\\n\\n예를 들면 제가 비즈니스를 하고 싶은데 이 채집 PT 같은 거 지금 공개된 거는 한 3,000단어 정도만 입력으로 들어갈 수 있어요.\\n\\n제가 채집 PT랑 대화를 주고받는다 그러면 대화 총합이 3,000단어 넘어가면 까먹어요, 얘는.\\n\\n원래 그런 디자인인 거예요.\\n\\n근데 그거를 늘리려면 늘릴 때 데이터도 많이 필요하고요.\\n\\n늘린 다음에 사양도 훨씬 많이 먹어요.\\n\\n이제 기술 발전이 좀 있긴 하겠지만 지금 상황에서는 그 3,000단어를 6,000단어로 늘리면 4배 정도 커져요, 얘가 대충.\\n\\n연산해야 되니까 4배씩 커지게 되니까 제가 이제 사업 모델을 봤더니 아, 3,000단어는 부족하고 뭐 8만 단어까지 하고 싶다.\\n\\n이러면 NVIDIA GPU 지금 1만 개 엮어서 했는데 몇 개 엮어서 할 거예요, 그때? 100만 개 엮어서 할 건가요? 그렇게 할 수 없잖아요.\\n\\n그러면 새로운 반도체 찾는 거죠.\\n\\n그 아파트들의 검폐율을 보면 보통 17%씩 높입니다.\\n\\n땅을 20평만 지어야 돼요.\\n\\n100평 되려면 10층이 돼야 200평 나오잖아요, 그렇죠? 이 시스템만 아시면 아시면 부동산은 제가 장담하고 있는데 반은 이미 안 갑니다.\\n\\n나머지는 디테일입니다.\\n\\n이걸 정확히 모르고 저 땅이 예쁘다, 이런 거 얘기할 필요 없습니다.', metadata={})]\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RefineDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"인공신경망은 특징이 CPU가 잘하는 일은 아니라는 거예요.\n",
      "\n",
      "숫자가 5를 넘으면 안녕하세요 말하는 코드를 쓴다.\n",
      "\n",
      "이거는 용량 진짜로 몇 킬로바이트 안 하거든요? 근데 제가 동일한 일을 하려는 걸 인공신경망으로 만들면 용량이 몇백배 커요.\n",
      "\n",
      "NVIDIA GPU도 완벽한 칩은 아니에요.\n",
      "\n",
      "예전 슈퍼컴퓨터에 그래픽카드 만 개를 엮었다고 했잖아요.\n",
      "\n",
      "근데 그렇게 엮으면 비효율도 크고 비용도 크거든요.\n",
      "\n",
      "GPT를 통한 인공지능 변호사 이런 거 만들려면 데이터 장벽부터 있는 거예요.\n",
      "\n",
      "예전에는 PC였고 스마트폰이었고 지금은 서버인데 제 사회의 어떤 수요를 만들려면요.\n",
      "\n",
      "안녕하세요.\n",
      "\n",
      "머니인사이드 시청자 여러분 정인성 작가입니다.\n",
      "\n",
      "저는 원래 반도체 회사에서 반도체 관련한 시뮬레이션 일을 하고 있었고요.\n",
      "\n",
      "최근에 인공지능 관련해서도 새로운 책을 쓸 수 있었고요.\n",
      "\n",
      "지금은 이제 동료들이랑 인공지능 개발 쪽으로 와 있습니다.\n",
      "\n",
      "스타릿에서 어떤...\n",
      "\n",
      "반도체들을 완제품을 만들고 나면 이 반도체들을 또 뭉쳐서 그 위에다가 조그마한 컨트롤러를 붙여서 막 동작을 하게 만들어요.\n",
      "\n",
      "쉽게 말하면 원본 반도체가 아니고 반도체들을 결합해서 새로운 가치를 만드는 거죠.\n",
      "\n",
      "이제 그런 것들을 시뮬레이션으로 검증하는 그런 일들을 했죠.\n",
      "\n",
      "인공지능은 용어를 구분할 필요가 있는데 인공지능은 우리 꿈 같은 거예요.\n",
      "\n",
      "그러니까 우리가 하고 싶은 거 쉽게 말하면 이 인공지능이라는 요소가 딱 잘 정의되진 않는데 예를 들면 예전에 있던 그 바둑에 있는 바둑 AI나 그 스타크래프트에서 이제 컴퓨터 상대를 넣었어요.\n",
      "\n",
      "그런 것도 다 인공지능이라고 불러요.\n",
      "\n",
      "실제로는 그렇게 부를 수 있고요.\n",
      "\n",
      "그러니까 인공지능이라는 것 자체가 굉장히 어마어마한 개념이고 그렇진 않은 거예요.\n",
      "\n",
      "근데 이제 우리 일반인들 입장에서는 좀 터미네이터 같은 걸 생각하겠죠.\n",
      "\n",
      "인공지능으로.\n",
      "\n",
      "저 일하는 입장에서 인공지능은 어떤 물건이냐 하면요.\n",
      "\n",
      "스스로 배워요.\n",
      "\n",
      "그러니까 저는 이제 프로그래머를 짜서 뭐 컴파일을 하거나 아니면 뭐 스크립트를 실행하면 얘가 막 돌아가거든요.\n",
      "\n",
      "근데 시킨 대로 돌아가요.\n",
      "\n",
      "얘는.\n",
      "\n",
      "예를 들면 제가 정말 어렵게 엄청 힘든 건데 프로그램을 막 짜서 개랑 고양이 구분하는 프로그램을 짰다고 해볼게요.\n",
      "\n",
      "근데 이 프로그램은요.\n",
      "\n",
      "제가 그 다음에 코끼리를 어떻게 하려고 하면 다시 짜야 돼요.\n",
      "\n",
      "또.\n",
      "\n",
      "코끼리 구분하는 코드를 막 짜야 되죠.\n",
      "\n",
      "근데 이제 저는 사실 어떻게 하고 싶냐.\n",
      "\n",
      "프로그램 하나 만들어 놓고 코끼리 사진만 막 넣으면 코끼리도 구분했으면 좋겠는 거예요.\n",
      "\n",
      "프로그램이.\n",
      "\n",
      "제가 프로그램을 다시 짜는 것과 있는 프로그램 냅두고 사진만 모아서 긁어 넣는 것 중에 뭐가 쉽겠어요.\n",
      "\n",
      "사진만 넣는 게 훨씬 쉽죠.\n",
      "\n",
      "프로그램 짜라 그러면 끼약하겠지만 코끼리 사진을 1,000개 모아오라 하면 아마 즐겁게 모아올 거라고요.\n",
      "\n",
      "그냥.\n",
      "\n",
      "당연히 훨씬 쉽죠.\n",
      "\n",
      "그게.\n",
      "\n",
      "지금 말하는 인공지능에서 중요한 요소들은 그런 거예요.\n",
      "\n",
      "바둑 인공지능도 다 인공지능이고 한데 지금 우리가 중요하게 여기는 요소는 얘가 스스로 배워서 내놓는 결과를 바꾸는 물건이란 거예요.\n",
      "\n",
      "그쪽을 중요하게 봐온 게 그 인공지능인 거예요.\n",
      "\n",
      "그리고 반도체는 그거와 뭐가 관계가 있느냐.\n",
      "\n",
      "지금 제가 말씀드린 건 다 컨셉이죠.\n",
      "\n",
      "어떻게 만드는지에 대한 얘기가 없잖아요.\n",
      "\n",
      "그래서 그런 인공지능을 만드는 아이디어가 여러 개 있었어요.\n",
      "\n",
      "SVM 뭐 이런 방법도 있고 뭐 그냥 코드를 엄청 무식하게 짜보는 방법도 있고요.\n",
      "\n",
      "뭐 IBM 왓슨처럼 막 만드는 방법도 있는데 요거 다 다른 형태의 프로그램이잖아요.\n",
      "\n",
      "요 방법들 중에 제가 A라는 방법을 택하면 예를 들어 CPU가 빨라야 되고 메모리는 적어도 되고 B라는 방법을 쓰면 CPU보다 메모리가 중요하고 요런 식으로 바뀌어요.\n",
      "\n",
      "왜냐하면 프로그램도 그냥 CPU에서 도는 게 아니고요.\n",
      "\n",
      "CPU가 잘하는 일 중심으로 프로그램을 짜야 빠른 거잖아요.\n",
      "\n",
      "그게 반도체랑 인공지능 기술의 핵심인 거예요.\n",
      "\n",
      "우리는 인공지능이라는 추상적인 개념을 만들고 싶고요.\n",
      "\n",
      "그래서 그 추상적인 개념이 돌아가게 하기 위해서 여러 가지 아이디어를 쓰는 거예요.\n",
      "\n",
      "그중에 지금 제일 잘 되는 게 인공신경망이라는 개념이에요.\n",
      "\n",
      "인간의 뇌세포 구조를 좀 따라해서 그 신경망을 이제 우리 학습시킨 방법을 알아냈기 때문에 학습시키면은 우리가 원하던 인공지능 스스로 뭐 배우고 뭐 진짜 의미로 스스로 배우진 않죠 이제.\n",
      "\n",
      "우리가 코드를 다시 짜지 않아도 데이터만 넣어서 다시 학습시키면 원하는 결과 나오고 그런 걸 할 수 있는 게 이제 인공신경망이에요.\n",
      "\n",
      "근데 이 인공신경망은 특징이 CPU가 잘하는 일은 아니라는 거예요 얘가.\n",
      "\n",
      "그러니까 이제 기존에 CPU만 우리 90년대, 2000년대 CPU만 있었는데 지금 NVIDIA GPU를 쓰는 거예요.\n",
      "\n",
      "우리에겐 하고 싶은 일이 있고 그중에 그 일을 제일 잘하는 방법론을 찾아요.\n",
      "\n",
      "어떤 방식으로 프로그램을 만들어야 스스로 잘 배우는 프로그램이 된다.\n",
      "\n",
      "그리고 그 프로그램들은 각자 원하는 반도체가 달라요.\n",
      "\n",
      "그 일을 잘할 수 있는 반도체가 다르죠.\n",
      "\n",
      "그렇게 움직이는 거예요.\n",
      "\n",
      "CPU와 GPU의 큰 차이가? 사실 둘 다 메모리가 아니고 연산용 칩인데 CPU라는 거는 그 조건 파악을 잘해요.\n",
      "\n",
      "예를 들면 제 입장에서 머니인사이드의 시청자가 몇 명 이상이면 참여하고 아니면은 출연하지 마라.\n",
      "\n",
      "이런 식으로 그 조건이 있으면 선택을 하는 거잖아요.\n",
      "\n",
      "이런 식의 일을 되게 잘해요.\n",
      "\n",
      "그게 그 CPU가 잘하는 일이고요.\n",
      "\n",
      "그리고 GPU는 뭘 잘하냐 하면은 숫자 계산을 엄청 잘해요 그냥.\n",
      "\n",
      "0.1 곱하기 0.4 뭐 이런 숫자를 뭐 수만 개 계산하는 걸 엄청 잘해요.\n",
      "\n",
      "근데 우리가 과거에 봤던 수많은 프로그램들은요.\n",
      "\n",
      "앞에 말했던 조건이 중요해요.\n",
      "\n",
      "예를 들면 엑셀이잖아요.\n",
      "\n",
      "제가 엑셀 칸에다가 함수를 넣으면 만약 함수가 sum이면은 더해라.\n",
      "\n",
      "이런 거죠.\n",
      "\n",
      "이렇게 조건이잖아요 다.\n",
      "\n",
      "그래서 그런 걸 잘하게 설계되어 있어요 CPU는.\n",
      "\n",
      "근데 인공신경만 어떻게 돌아가냐 하면 그냥 입력값을 다 소수점으로 바꾼 다음에 소수점 곱셈을 엄청나게 해요.\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY IN KOREAN:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m다음 문장을 요약해주세요:\n",
      "\n",
      "앞에 말했던 조건이 중요해요.\n",
      "\n",
      "예를 들면 엑셀이잖아요.\n",
      "\n",
      "제가 엑셀 칸에다가 함수를 넣으면 만약 함수가 sum이면은 더해라.\n",
      "\n",
      "이런 거죠.\n",
      "\n",
      "이렇게 조건이잖아요 다.\n",
      "\n",
      "그래서 그런 걸 잘하게 설계되어 있어요 CPU는.\n",
      "\n",
      "근데 인공신경만 어떻게 돌아가냐 하면 그냥 입력값을 다 소수점으로 바꾼 다음에 소수점 곱셈을 엄청나게 해요.\n",
      "\n",
      "곱셈, 넛셈을 뭐 수억 번씩 하면 결과가 나오는데 그러면은 결과가 잘 나오는 그런 물건이에요.\n",
      "\n",
      "그러니까 어떻게 보면 인간이 조건을 하나씩 넣어주는 형태 프로그램에서 그냥 모두 다 숫자로 바꿔서 숫자로 와장창 곱하면은 이제 원하는 결과가 튀어나오는 좀 신기한 상황이 된 거죠.\n",
      "\n",
      "Q.\n",
      "\n",
      "인공지능 기술은 어떻게 변화할까요? 어떻게 보면 CPU가 좀 더 똑똑한 칩인데 우리가 지금 보는 인공지능 기술은 좀 무식한 방식으로 좀 더 나은 지성이 구현되어 있는 그런 모습이에요.\n",
      "\n",
      "숫자가 인공지능이 돌아가는 원리? 그러니까 인간 머리가 일단 그런 식으로 돌아가잖아요.\n",
      "\n",
      "왜냐하면 인간 유전자 안에 CPU 설계가 들어있겠어요? 그런 복잡한 설계가 있을까요? 인간 안에? 그 CPU 안에는 그 수십억 개 트랜지스터가 막 연결되어 있는 설계도가 있는데 인간은 그렇지 않잖아요.\n",
      "\n",
      "그래서 뇌세포들은 다 보면은 특정 뇌세포에 자극이 들어오면 인접한 뇌세포에다가 특정 그 역치값을 넘으면 자극을 전달하고 역치를 안 넘으면 자극을 안 전달하고 이렇게 돼 있어요.\n",
      "\n",
      "그 연결관계를 수조개 모아놓으면 지성이 되는 거잖아요.\n",
      "\n",
      "그리고 과거에는 문제가 뭐였냐면은 어 그러면 우리 인간 뇌 모습을 좀 따라해서 이렇게 막 연결하면 지성이 나올 거야.\n",
      "\n",
      "이론상.\n",
      "\n",
      "그 문제는 뭐냐? 이 연결이 예를 들면 A라는 뇌세포랑 B라는 뇌세포 사이 연결을 얼마나 강하게 전달해줘야 돼? 이런 걸 하나도 모르는 거예요.\n",
      "\n",
      "그러니까 우리가 앞에서 말한 프로그래밍이라는 개념은 아까 말한 것처럼 조건문을 쓰는 거였는데 이제는 그 세포와 세포 사이 연결 강도가 0.1이냐 0.3이냐 이런 거를 고민해야 되는 상황이 된 거예요.\n",
      "\n",
      "그 문제가 뭐겠어요? 수십억 개가 있는데 그중에 이거 세포 하나 딱 해서 얘네 둘 사이가 이게 영향을 뭘 주는 거야? 하면 그걸 알아내겠냐는 거예요.\n",
      "\n",
      "그걸 알 수가 없잖아요.\n",
      "\n",
      "그래서 오랫동안 힘들었던 거예요.\n",
      "\n",
      "인공지능, 인간 뇌세포를 따라해보자는 아이디어가 뭐 그렇게 참신한가요 이게? 60년대에 이미 나왔던 아이디어예요.\n",
      "\n",
      "근데 왜 사장 되고 이제야 떠올랐냐? 그때는 어 그래 이렇게 하면 될 것 같은데 정확하게는 뇌세포와 뇌세포의 연결관계를 어떻게 해줘야 얘가 잘 돌아가는지를 몰랐던 거야.\n",
      "\n",
      "그러니까 몇십 년을 쉰 거죠.\n",
      "\n",
      "이제 몇십 년 동안 그래서 아무도 못 해보고 있다가 캐나다 쪽에서 이제 그거 학습시키는 방법을 알아낸 거예요 그때.\n",
      "\n",
      "아 여기 데이터를 넣고 결과 값에서 어떤 식으로 계산을 해주면 인공신경망이 서서히 정답률이 올라가게 만들 수 있다.\n",
      "\n",
      "요거를 알아냈어요 그때.\n",
      "\n",
      "그 방법을 써보니까 GPU를 써야 빨라요.\n",
      "\n",
      "그렇게 해서 지금의 상황이 된 거예요 이건.\n",
      "\n",
      "쉽게 말하면 프로그램 쓰는 방법이 바뀌어버린 거예요.\n",
      "\n",
      "기존에는 프로그램 쓸 때 제가 순서도를 놓고 이 순서도를 잘못 자면 버그고 그랬는데요.\n",
      "\n",
      "지금은 인공신경망을 크게 구성을 해놓고 그 안에서 값이 정답을 낼 수 있는 형태로 그 수많은 소수점을 바꿔가야 되는 거예요.\n",
      "\n",
      "그래서 GPU가 필요한 거죠.\n",
      "\n",
      "Q.\n",
      "\n",
      "인공신경망을 어떻게 만들어야 할까요? 원래 옛날 게임들은 화면에 표시하는 거랑 게임의 움직임들 표시하는 걸 전부 CPU가 했어요.\n",
      "\n",
      "근데 이제 컴퓨터라는 게 PC라는 게 나오고 계속 유행하다 보니까 사람들이 점점 더 높은 그래픽을 원해요.\n",
      "\n",
      "점점 더 그래픽 좋은 게임도 하고 싶고 영화도 만들고 싶고 이런 거예요.\n",
      "\n",
      "근데 말씀드렸지만 CPU는 분기 처리를 잘해요.\n",
      "\n",
      "조건 처리를 잘하죠.\n",
      "\n",
      "근데 고급 그래픽을 계속 해보니까 이게 CPU에 잘 맞지 않았던 거예요.\n",
      "\n",
      "그래서 CPU에 잘 맞지 않으니까 VGA라고 부르는 그래픽 전용 칩을 만들어서 쉽게 말하면 이런 거예요.\n",
      "\n",
      "제가 여기 인테리어를 해야 되는데 인테리어 디자인도 하고 벽지도 붙이고 청소도 다 했는데 이제는 CPU가 GPU라고 부르는 협력사를 데려와서 저는 여기는 도배하고 여기는 청소하고 시켜놓으면 이걸 하고 가게 하는 거예요.\n",
      "\n",
      "그리고 저는 이제 앉아서 계속 다음번 도배해야 될 거 찾고 있고요.\n",
      "\n",
      "GPU라는 녀석이 와서 도배 같은 일을 해주는 거예요.\n",
      "\n",
      "이 GPU는 제가 하는 일은 잘 못하지만 제가 잘 못하는 걸 잘하는 거죠.\n",
      "\n",
      "결국은 CPU라는 칩이 모든 일을 잘하기에는 한계가 있었던 거예요.\n",
      "\n",
      "왜냐하면 CPU가 아까 말한 조건문 처리를 잘하려면 그쪽에다 소자를 써야 되는데 거기에 소자를 쓰면은 다른 쪽에 쓸 소자가 없잖아요, 제조할 때.\n",
      "\n",
      "그러니까 모든 걸 잘할 수 없으니까 생겨난 일이죠.\n",
      "\n",
      "다행스럽게도 엔비디아가 의도한 바는 아니겠죠, 아마.\n",
      "\n",
      "인공지능 기술을 해내기 위해서 여러 연구를 하는데 제일 잘 되는 기술이 그래픽이랑 비슷한 연산을 요구했던 거예요.\n",
      "\n",
      "제가 그래픽 돌아가는 거...\n",
      "\n",
      "예, 왜냐하면 그래픽도 결국 소수점 많이 곱하고 더하고 하는 거예요.\n",
      "\n",
      "살짝 얻어걸린 느낌도 있죠, 이거는.\n",
      "\n",
      "그래픽을 했는데 회사가 계속 커야 되니까 CPU는 못하고 GPU는 잘하는 일을 계속 찾아다녔어요, 이 회사가.\n",
      "\n",
      "어, 이게 잘 될 거야 라는 그런 느낌으로 바로 가서 2006년, 2007년에 막 질른 게 아니고 전 세계 사람들이 좀 GPU를 쓰기 편하게 이제 CUDA 이런 걸 만들어놨어요.\n",
      "\n",
      "그러니까 엔비디아 생각이 이런 거예요.\n",
      "\n",
      "아, 이게 그래픽에만 쓰진 않겠지.\n",
      "\n",
      "뭐 슈퍼컴퓨터나 시뮬레이션에도 쓸 수 있고 그래서 그 물리연산하는 회사를 인수하기도 하고 그랬어요.\n",
      "\n",
      "근데 이제 그런 걸 그냥 만들어놓고 칩 쓰세요 라고 하면은 쓰는 법을 몰라요, 사람들이.\n",
      "\n",
      "왜냐하면 제가 CPU용으로 프로그램 짜던 사람이 GPU용으로 프로그램 짜려고 하면 진입장벽이 꽤 높거든요.\n",
      "\n",
      "한국어 문장요약 결과:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m다음 문장을 요약해주세요:\n",
      "\n",
      "아, 이게 그래픽에만 쓰진 않겠지.\n",
      "\n",
      "뭐 슈퍼컴퓨터나 시뮬레이션에도 쓸 수 있고 그래서 그 물리연산하는 회사를 인수하기도 하고 그랬어요.\n",
      "\n",
      "근데 이제 그런 걸 그냥 만들어놓고 칩 쓰세요 라고 하면은 쓰는 법을 몰라요, 사람들이.\n",
      "\n",
      "왜냐하면 제가 CPU용으로 프로그램 짜던 사람이 GPU용으로 프로그램 짜려고 하면 진입장벽이 꽤 높거든요.\n",
      "\n",
      "그래서 엔비디아는 그걸 조금이나마 좀 편하게 해주려고 CUDA 이런 것들을 마련을 해놓은 거죠.\n",
      "\n",
      "근데 그걸 마련해놓은 상황이 이거 쉽게 말하면 캐나다에서 집어다 써본 거에 가까워요.\n",
      "\n",
      "어, 그랬더니 연산속도가 5배 빨라졌어요.\n",
      "\n",
      "뭐 이런 식으로 결과가 나오니까 이제 옆방 대학원생이 이걸로 한 달에 하나 쓰던 논문을 한 달에 5개씩 쓰고 있으면 그러면 나도 써야 되고 그럼 그 옆방 대학원생도 쓰고 할 거잖아요, 당연히.\n",
      "\n",
      "근데 이게 굉장히 반도체 비즈니스에서 사실은 중요한 요소예요.\n",
      "\n",
      "옆사람이 썼는데 안 되던 게 됐잖아요.\n",
      "\n",
      "그러면 그걸 본 옆사람이 쓰죠.\n",
      "\n",
      "그러면 이제 이걸 잘 쓴 사람이 논문 찍어내면서 유명해지죠.\n",
      "\n",
      "그러면 어느 순간 그게 거대한 프로그래머 집단으로 변해요.\n",
      "\n",
      "그러면 이제 지금 2023년 상황에서 제가 대학원 갓 졸업하고 논문 써야 되는데 인공지능으로 논문을 써야 되겠는데 그러면 컴퓨터를 마련하는데 뭘 마련할 거냐 이거예요.\n",
      "\n",
      "전 지금 하나도 안 해봤으니까 일단 남들 하는 걸 다 모방해야 된다니까요.\n",
      "\n",
      "남들 쓰는 컴퓨터 사고 그럼 당연히 엔비디아 GPU 들어가요.\n",
      "\n",
      "그리고 인공지능 한 번도 안 돌려봤으니까 인터넷에 돈을 오픈소스를 받아다가 인공지능을 돌려봐야 돼요.\n",
      "\n",
      "그 오픈소스는 뭘로 쓰여 있겠어요.\n",
      "\n",
      "이것도 엔비디아 GPU를 전제하고 써놨다고요 코드를.\n",
      "\n",
      "그러니까 AMD가 못하는 거예요.\n",
      "\n",
      "이거를 AMD 그래픽 카드로 이제 뭔가 해보려고 실제 실험은 하지도 못하는 거예요.\n",
      "\n",
      "제가 근데 엔비디아 거 쓰면 물어보면 되잖아요.\n",
      "\n",
      "야 넌 어떻게 했니? 이렇게.\n",
      "\n",
      "그게 그 반도체 비즈니스에서 되게 중요한 거예요.\n",
      "\n",
      "생태계예요 이게.\n",
      "\n",
      "어떻게 보면 메모리 같은 건 그런 생태계가 좀 약하고요.\n",
      "\n",
      "인텔의 CPU 같은 것도 그런 생태계를 가지고 있잖아요.\n",
      "\n",
      "그러니까 한참 동안 인텔 CPU가 지금도 그렇게 힘들어해도 살아있는 거예요.\n",
      "\n",
      "여기에 맞춰진 프로그램이 많으니까.\n",
      "\n",
      "반도체 시장은 이제 당분간은 거대 신경망 특히 자연화 신경망이 잘 된다고 했으니까 아마 그쪽 연구개발 수요는 올라갈 거예요.\n",
      "\n",
      "근데 연구개발 이상으로 이제 꾸준한 수요를 만들어내려면 많은 부분에서는 연구를 해봐야 된다고 생각해요.\n",
      "\n",
      "왜냐하면 지금 신경망 학습시키는 게 장점만 있는 건 아니에요.\n",
      "\n",
      "단점은 얘가 인간이랑 제일 큰 차이점이 데이터 한 두 개 보고 학습이 안 된다는 거예요.\n",
      "\n",
      "예를 들면 여기 버닝사이드 시청자 여러분은 영상을 만 개씩 봐야 특정 테마를 익힐 수 있는 것이 아니잖아요.\n",
      "\n",
      "하나만 봐도 익히죠.\n",
      "\n",
      "근데 인공지능은 문제와 정답상 하나 가지고 배울 수가 없고 엄청 많이 봐야 돼요.\n",
      "\n",
      "GPT를 통한 인공지능 변호사 이런 거 만들려면 일단 데이터 장벽부터 있는 거예요.\n",
      "\n",
      "질문과 정답상이 충분히 있냐.\n",
      "\n",
      "그런 것들이 지금은 다 조사가 안 돼 있고 이제야 사람들을 찾아보는 중일 거잖아요.\n",
      "\n",
      "그러니까 저는 당분간은 연구개발 수요는 크겠지만 이게 정말 세상을 바꿀 만큼 여기저기 적용될 건지 아니면 마이크로소프트만 자기들 검색엔진과 오피스에 쓸 건지 이거는 저는 좀 봐야 된다고 생각해요.\n",
      "\n",
      "우리나라의 발표체는 어떻게 쓰일 것인가요? 일단 제일 크게 쓰이는 건 역시 메모리죠.\n",
      "\n",
      "인공신경망의 특징 중 하나는요.\n",
      "\n",
      "CPU용으로 짠 프로그램보다 용량이 엄청나게 크다는 거예요.\n",
      "\n",
      "정말 코드를 잘 짜서 숫자가 5를 넘으면 뭐 안녕하세요 말하는 코드를 쓴다.\n",
      "\n",
      "이거는 용량 진짜로 몇 킬로바이트 안 하거든요.\n",
      "\n",
      "근데 제가 동일한 일을 하려는 걸 인공신경망으로 만들면 용량이 몇백배 커요, 실제로는.\n",
      "\n",
      "그래서 메모리 중에 고용량, 고대역폭 메모리가 중요한 거예요, 지금.\n",
      "\n",
      "일단 한국에서 제일 주요하게 팔리는 것들은 인공지능 쪽에 그 HBM 같은 고용량 고속 메모리들이죠.\n",
      "\n",
      "그쪽에서 확실히 수요가 있다고 봐야죠.\n",
      "\n",
      "그러니까 이런 느낌이에요.\n",
      "\n",
      "예를 들면 제가 CPU 프로그램에다가 1 더하기 1을 계산하게 시키면 프로그램 용량 해봤자 얼마나 하겠어요.\n",
      "\n",
      "근데 저한테 1 더하기 1 물어보고 MRI 찍으면 순식간에 뻘겋뻘겋해졌다가 없어진다고요.\n",
      "\n",
      "되게 비율적이잖아요, 그렇게 보면.\n",
      "\n",
      "용량이 크다니까요, 그렇게.\n",
      "\n",
      "여기 뇌세포 하나하나로 옮겨 놓는 거잖아요.\n",
      "\n",
      "1 더하기 1을 하기 위해서 뇌세포를 거쳐가는 신호의 개수가 뭐 3개겠냐 이거예요.\n",
      "\n",
      "1 더하기 1은 2.\n",
      "\n",
      "3개 들어가면 한 개 답이 나오는 게 아니고 수백억 개가 막 여기서 반응을 하잖아요.\n",
      "\n",
      "그거를 재현해야 되는 거잖아요, 컴퓨터의 내부에 맞춰서.\n",
      "\n",
      "고용량 메모리가 필요할 텐데 당장 물량을 딱 고민해보면 마이크로소프트 엣저이 슈퍼컴퓨터가 엔비디아 V100인가 하는 학습용 GPU를 만 개인가 엮었거든요.\n",
      "\n",
      "근데 이거 만 개 엮으면 이게 메모리 용량이 40만 기가바이트 그래요.\n",
      "\n",
      "엄청 큰 것 같지만 우리 평균 스마트폰에 8기가 들어가잖아요.\n",
      "\n",
      "8기가 들어가면 이거 2만 개 팔아도 스마트폰으로 한 5배? 40이랑 8이니까 5배죠? 그러면 스마트폰 판매량으로는 한 10만 개 정도 되겠네요.\n",
      "\n",
      "근데 스마트폰 1년에 10억 개 팔잖아요, 전 세계에.\n",
      "\n",
      "그러니까 이것만으로는 물량이 엄청 크지 않다는 얘기를 하는 거예요.\n",
      "\n",
      "엣저이 슈퍼컴퓨터 1년에 한 100개씩 팔아도 전체 메모리 물량에서 크진 않죠.\n",
      "\n",
      "물론 메모리 용량된 단가는 크게 쳐주겠지만.\n",
      "\n",
      "그래서 이게 GPT 같은 게 메모리 시장에 예전에는 PC였고, 스마트폰이었고, 지금은 서버인데 제사의 어떤 수요를 만들려면요.\n",
      "\n",
      "지금 연구개발 수요로 안 된다는 이야기를 하는 거예요.\n",
      "\n",
      "연구개발 수요 말고 꾸준히 사용되는 수요가 있어야 되는데 왜냐하면 연구개발하는 건 결국 한 번 사고 잘 안 되면 버릴 거잖아요.\n",
      "\n",
      "한국어 문장요약 결과:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m다음 문장을 요약해주세요:\n",
      "\n",
      "그래서 이게 GPT 같은 게 메모리 시장에 예전에는 PC였고, 스마트폰이었고, 지금은 서버인데 제사의 어떤 수요를 만들려면요.\n",
      "\n",
      "지금 연구개발 수요로 안 된다는 이야기를 하는 거예요.\n",
      "\n",
      "연구개발 수요 말고 꾸준히 사용되는 수요가 있어야 되는데 왜냐하면 연구개발하는 건 결국 한 번 사고 잘 안 되면 버릴 거잖아요.\n",
      "\n",
      "근데 꾸준히 써야 되면 연구개발용도 계속 사고 상업용으로도 계속 사야 되니까 수요가 꾸준히 늘어나죠.\n",
      "\n",
      "근데 그걸 알려면 사실 메모리 시장이나 엔비디아를 볼 게 아니고 우리가 GPT 같은 걸로 하고 싶은 사업모델 중에 데이터들의 쌍이 잘 갖춰져 있는 곳이 있나 그거를 알아야 답을 할 수 있다는 얘기인 거예요.\n",
      "\n",
      "전 그래서 지금은 그걸로 메모리 시장이 확 바뀔 거다 그렇게까지는 기대하지 않아요.\n",
      "\n",
      "지금 인공지능은요.\n",
      "\n",
      "우리가 좀 이렇게 착각들을 하는 게 인터넷에는 데이터가 무한하니까 그냥 데이터 넣으면 똑똑해지겠네 라고 생각하거나 그렇지가 않아요.\n",
      "\n",
      "예를 들어서 제가 개와 고양이를 구분시켜야 된다고 하면 사진만 넣는 게 아니라 사진에 개라고 써놔야 돼요.\n",
      "\n",
      "고양이 사진 고양이라고 써놔야 되고요.\n",
      "\n",
      "그렇게 질문과 정답 쌍이 있어야 배울 수 있는 거예요.\n",
      "\n",
      "사진은 그래도 좀 쉽죠.\n",
      "\n",
      "이거 뭐 사람 몇 명 쓰면 사진 100만 개 만들 수 있을 거예요.\n",
      "\n",
      "근데 말하는 인공지능은 어떨까요? 이거 질문과 대답 쌍을 만들기 쉬울까요? 우리 인터넷에 글을 그냥 긁으면 질문과 대답 쌍이 충분히 많이 나올까요? 그러니까 그 안에서는 질문과 대답 쌍 자체를 찾는 것도 되게 어렵고요.\n",
      "\n",
      "그리고 그중에 신뢰할 수 있는 말이 있느냐 이것도 되게 중요해요.\n",
      "\n",
      "지금 GPT 같은 게 학습이 잘 될 수밖에 없는 게 요약 같은 거 되게 잘하거든요.\n",
      "\n",
      "해보면 왜 요약이 잘 되냐 하면요.\n",
      "\n",
      "요약은 이미 그 인터넷에 쌍이 많이 있거든요.\n",
      "\n",
      "제가 일일이 GPT에 만들어줄 몇 테라바이트 데이터를 일일이 질문 답변 쓰는 건 수학적으로 말이 안 돼요.\n",
      "\n",
      "왜냐하면 사람이 열심히 쳐봤자 제가 한 만 단어 치는 것도 힘든데 일주일 동안 근데 얘는 수백억 단어가 필요한데 그거 사람 뽑아서 한다고 되겠어요? 그게? 안 되죠.\n",
      "\n",
      "대부분 있는 데이터 중에 좋은 데이터를 정제해서 쓰는 게 중요해요.\n",
      "\n",
      "근데 예를 들면 요약 같은 거는 위키페디아 이런 거 있잖아요.\n",
      "\n",
      "인트로덕션 안에 사실상 요약이에요.\n",
      "\n",
      "그리고 밑에가 본문이잖아요.\n",
      "\n",
      "본문을 주고 이거 요약해줘 한 다음에 정답을 인트로덕션 같은 걸 넣어서 할 수가 있거든요.\n",
      "\n",
      "그런 일들은 잘 되는 거예요.\n",
      "\n",
      "근데 이제 예를 들면 우리가 GPT가 세상을 바꾸려면 그런 식으로 쓸 수 있는 데이터가 있는 곳이어야 적용 가능한 거예요.\n",
      "\n",
      "예를 들면 제가 법조계 쪽으로 GPT를 쓰고 싶고 GPT를 학습시키고 싶잖아요.\n",
      "\n",
      "그러면 그것도 판례랑 답이 있어야 되는데 그것도 이제 얼마나 좋은 판례인지 이런 걸 다 매겨줘야 된다는 거예요.\n",
      "\n",
      "그 양도 많아야 되는 거죠.\n",
      "\n",
      "그리고 그러고 나면 사업성 문제가 생겨요.\n",
      "\n",
      "그렇게 한국에서 이거 학습을 시켰는데 미국에 쓸 수 있어요, 그거? 못 쓰죠.\n",
      "\n",
      "미국법이 아니니까 그건.\n",
      "\n",
      "이거는 상장된 회사는 아닌데 세레브라스 이런 회사들이 있어요.\n",
      "\n",
      "정확하게는 NVIDIA GPU도 완벽한 칩은 아니에요.\n",
      "\n",
      "인공지능 쪽에서는 범용적이고 쓰기 편한 칩이긴 한데 얘도 한계가 있어요.\n",
      "\n",
      "예를 들면 지금 도는 채집 PT 같은 거 말했지만 애저 슈퍼컴퓨터의 그래픽카드 만 개를 엮었다고 했잖아요.\n",
      "\n",
      "근데 그렇게 엮으면 비효율도 크고 비용도 크거든요.\n",
      "\n",
      "그래서 이제 세레브라스 같은 회사는 그만한 GPU를 하나씩 엮을 바에 이따만한 칩을 웨이퍼 하나에 놓고 그 안에 신경망을 한 번에 다 올리자 이런 식으로 얘기를 해요.\n",
      "\n",
      "이거는 단일 GPU 안에 다 안 들어가서 이거를 쪼개서 담기 위한 노력도 많이 하고 그 비효율이 많거든요.\n",
      "\n",
      "근데 이제 그런 거대한 칩에는 신경망이 한 번에 딱 들어가죠.\n",
      "\n",
      "그러면 기존에 이론상으로는 할 수 있지만 GPU의 용량 한 개로 해보기 힘들었던 걸 많이 해볼 수 있어요.\n",
      "\n",
      "그런 칩들을 쓰면.\n",
      "\n",
      "저는 이제 그런 무류의 칩들을 보는 건 나쁘지 않다고 생각해요.\n",
      "\n",
      "정확하게 이제 조건은 두 개 있어요.\n",
      "\n",
      "이런 칩들이 잘 되려면 첫째로 지금 채집 PT와 비슷한데 거대한 언어모델이죠, 이게.\n",
      "\n",
      "내가 하려고 하는 사업 분야에 데이터가 아까 말한 형태의 데이터가 있고요.\n",
      "\n",
      "그런 데이터들이 풍족하고 근데 NVIDIA GPU 쓰면 원가가 좀 안 나오는 애들.\n",
      "\n",
      "이런 애들일 때 가능성이 있는 거예요.\n",
      "\n",
      "예를 들면 제가 비즈니스를 하고 싶은데 이 채집 PT 같은 거 지금 공개된 거는 한 3,000단어 정도만 입력으로 들어갈 수 있어요.\n",
      "\n",
      "제가 채집 PT랑 대화를 주고받는다 그러면 대화 총합이 3,000단어 넘어가면 까먹어요, 얘는.\n",
      "\n",
      "원래 그런 디자인인 거예요.\n",
      "\n",
      "근데 그거를 늘리려면 늘릴 때 데이터도 많이 필요하고요.\n",
      "\n",
      "늘린 다음에 사양도 훨씬 많이 먹어요.\n",
      "\n",
      "이제 기술 발전이 좀 있긴 하겠지만 지금 상황에서는 그 3,000단어를 6,000단어로 늘리면 4배 정도 커져요, 얘가 대충.\n",
      "\n",
      "연산해야 되니까 4배씩 커지게 되니까 제가 이제 사업 모델을 봤더니 아, 3,000단어는 부족하고 뭐 8만 단어까지 하고 싶다.\n",
      "\n",
      "이러면 NVIDIA GPU 지금 1만 개 엮어서 했는데 몇 개 엮어서 할 거예요, 그때? 100만 개 엮어서 할 건가요? 그렇게 할 수 없잖아요.\n",
      "\n",
      "그러면 새로운 반도체 찾는 거죠.\n",
      "\n",
      "그 아파트들의 검폐율을 보면 보통 17%씩 높입니다.\n",
      "\n",
      "땅을 20평만 지어야 돼요.\n",
      "\n",
      "100평 되려면 10층이 돼야 200평 나오잖아요, 그렇죠? 이 시스템만 아시면 아시면 부동산은 제가 장담하고 있는데 반은 이미 안 갑니다.\n",
      "\n",
      "나머지는 디테일입니다.\n",
      "\n",
      "이걸 정확히 모르고 저 땅이 예쁘다, 이런 거 얘기할 필요 없습니다.\n",
      "\n",
      "한국어 문장요약 결과:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'intermediate_steps': ['인공신경망은 CPU와는 다른 역할을 수행하며, 데이터 입력만으로 학습되어 용량이 커집니다. 인공지능 기술 개발에는 SVM 등 다양한 아이디어가 사용되며, 인공신경망은 인간의 뇌세포 구조를 모방하면서 학습 시킬 수 있는 방법론 중 하나입니다. CPU는 조건을 잘 처리하는데, GPU는 숫자 계산을 잘합니다.',\n",
       "  'AI 기술은 CPU가 좀 더 똑똑한 칩인데, 현재는 무식한 방식으로 좀 더 나은 지성이 구현된 상태이다. 인공신경망은 CPU에 비해 더 좋은 성능을 보이는 GPU를 사용하여 계산한다. 하지만 GPU를 사용하는 것은 CPU를 사용하는 것보다 진입장벽이 높기 때문에 쓰는 방법을 파악하는 것이 중요하다. 인공신경망을 만들기 위해서는 뇌세포와 뇌세포의 연결관계를 고려해야 하기 때문에 연구는 어렵지만, GPU와 연결하면 좋은 성능을 보인다.',\n",
       "  '엔비디아의 그래픽 처리 장치(GPU)가 인공지능, 슈퍼컴퓨터 등에 사용되어 성능이 크게 개선되었고, 이는 생태계를 형성하는 반도체 비즈니스에서 중요한 요소가 되었다. 메모리 중에서도 고용량 고속 메모리(HBM) 수요가 높아진 상황이며, 한국에서도 인공지능 분야에서 HBM 등이 많이 사용된다. 하지만, 단순한 연구개발 수요보다는 꾸준한 사용 수요가 필요하며, 이는 연구를 통해 만들어야 한다는 전문가의 견해도 있다.',\n",
       "  'GPT와 같은 인공지능 메모리 시장은 꾸준한 사용 수요가 필요하며, 따라서 데이터 쌍이 잘 갖춰져 있는 곳에서 조용히 발전해야 한다. 현재 인공지능은 데이터 쌍이 필요한데 인터넷에서 적합한 데이터를 찾기 어렵고, 그 중에서도 신뢰할 수 있는 말이 있는지가 중요하다. GPT는 요약 작업에 유용하기 때문에 이미 인터넷에 많은 요약 데이터가 있으며, 이 데이터를 이용해 학습할 수 있다. 하지만 GPT가 사용되는 사업 분야가 다양해질수록 많은 데이터와 더 나은 반도체가 필요하게 된다.'],\n",
       " 'output_text': 'GPT와 같은 인공지능 메모리 시장은 꾸준한 사용 수요가 필요하며, 따라서 데이터 쌍이 잘 갖춰져 있는 곳에서 조용히 발전해야 한다. 현재 인공지능은 데이터 쌍이 필요한데 인터넷에서 적합한 데이터를 찾기 어렵고, 그 중에서도 신뢰할 수 있는 말이 있는지가 중요하다. GPT는 요약 작업에 유용하기 때문에 이미 인터넷에 많은 요약 데이터가 있으며, 이 데이터를 이용해 학습할 수 있다. 하지만 GPT가 사용되는 사업 분야가 다양해질수록 많은 데이터와 더 나은 반도체가 필요하게 된다.'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# refine\n",
    "# https://python.langchain.com/en/latest/reference/modules/text_splitter.html\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain import OpenAI, PromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.docstore.document import Document\n",
    "from pprint import pprint\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "\n",
    "\n",
    "with open('./정인성작가_transcript.txt', 'r', encoding='utf-8') as f:\n",
    "    transcript = f.read()\n",
    "\n",
    "transcript = transcript.replace('. ', '.\\n\\n')\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=3000, chunk_overlap=200)\n",
    "texts = text_splitter.split_text(transcript) # 문장 분리 길이 4000 미만 및 chunk_overlap 200\n",
    "docs = [Document(page_content=t) for t in texts]\n",
    "pprint(docs)\n",
    "\n",
    "############################################################################################################\n",
    "bullet_point_prompt_template = \"\"\"다음 문장을 요약해주세요:\n",
    "\n",
    "{text}\n",
    "\n",
    "한국어 문장요약 결과:\n",
    "\"\"\"\n",
    "############################################################################################################\n",
    "bullet_point_prompt = PromptTemplate(template=bullet_point_prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "llmc = ChatOpenAI(temperature=0.9, model_name=\"gpt-3.5-turbo\")\n",
    "chain = load_summarize_chain(llmc, chain_type=\"refine\", return_intermediate_steps=True, refine_prompt=bullet_point_prompt, verbose=False)\n",
    "# chain = load_summarize_chain(llmc, chain_type=\"refine\", return_intermediate_steps=True, verbose=True)\n",
    "\n",
    "res = chain({\"input_documents\": docs}, return_only_outputs=True)\n",
    "res\n",
    "\n",
    "# Load_summarize_chain 함수를 들어가보면 refine_prompt가 있음 그리고 refine_prompt는 PromptTemplate 이 내부적으로 있는데 \n",
    "# documents가 여러개라고 했을때 첫번때 doc은 영어로된 프롬프트 먼저 받고 2번째 부터 내가 넣어준 템플릿을 따르는 경향이 있음.. 이거 에러 아닌가?\n",
    "\n",
    "'''\n",
    "issue: \n",
    "fork and pull request로 기여해보자\n",
    "To contribute to this project, please follow a \"fork and pull request\" workflow. Please do not try to push directly to this repo unless you are maintainer.\n",
    "https://github.com/hwchase17/langchain/blob/master/.github/CONTRIBUTING.md\n",
    "\n",
    "요약 체인에서 제가 정의한 프롬프트로 요약을 진행하려고 하면, 먼저 사전에 정의된 refine.py 의 프롬프트가 1차적으로 실행된 뒤 제가 정의한 프롬프트가 2번째 부터 적용됩니다. \n",
    "When I try to run the summarization with the prompts I defined in the summarization chain, the predefined prompts from refine.py are executed first, and then the prompts I defined are applied second. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('GPT와 같은 인공지능 메모리 시장은 꾸준한 사용 수요가 필요하며, 따라서 데이터 쌍이 잘 갖춰져 있는 곳에서 조용히 발전해야 한다. '\n",
      " '현재 인공지능은 데이터 쌍이 필요한데 인터넷에서 적합한 데이터를 찾기 어렵고, 그 중에서도 신뢰할 수 있는 말이 있는지가 중요하다. '\n",
      " 'GPT는 요약 작업에 유용하기 때문에 이미 인터넷에 많은 요약 데이터가 있으며, 이 데이터를 이용해 학습할 수 있다. 하지만 GPT가 '\n",
      " '사용되는 사업 분야가 다양해질수록 많은 데이터와 더 나은 반도체가 필요하게 된다.')\n"
     ]
    }
   ],
   "source": [
    "pprint(res['output_text'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# The `stuff` chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='인공신경망은 특징이 CPU가 잘하는 일은 아니라는 거예요.\\n\\n숫자가 5를 넘으면 안녕하세요 말하는 코드를 쓴다.\\n\\n이거는 용량 진짜로 몇 킬로바이트 안 하거든요? 근데 제가 동일한 일을 하려는 걸 인공신경망으로 만들면 용량이 몇백배 커요.\\n\\nNVIDIA GPU도 완벽한 칩은 아니에요.\\n\\n예전 슈퍼컴퓨터에 그래픽카드 만 개를 엮었다고 했잖아요.\\n\\n근데 그렇게 엮으면 비효율도 크고 비용도 크거든요.\\n\\nGPT를 통한 인공지능 변호사 이런 거 만들려면 데이터 장벽부터 있는 거예요.\\n\\n예전에는 PC였고 스마트폰이었고 지금은 서버인데 제 사회의 어떤 수요를 만들려면요.\\n\\n안녕하세요.\\n\\n머니인사이드 시청자 여러분 정인성 작가입니다.\\n\\n저는 원래 반도체 회사에서 반도체 관련한 시뮬레이션 일을 하고 있었고요.\\n\\n최근에 인공지능 관련해서도 새로운 책을 쓸 수 있었고요.\\n\\n지금은 이제 동료들이랑 인공지능 개발 쪽으로 와 있습니다.\\n\\n스타릿에서 어떤...\\n\\n반도체들을 완제품을 만들고 나면 이 반도체들을 또 뭉쳐서 그 위에다가 조그마한 컨트롤러를 붙여서 막 동작을 하게 만들어요.\\n\\n쉽게 말하면 원본 반도체가 아니고 반도체들을 결합해서 새로운 가치를 만드는 거죠.\\n\\n이제 그런 것들을 시뮬레이션으로 검증하는 그런 일들을 했죠.\\n\\n인공지능은 용어를 구분할 필요가 있는데 인공지능은 우리 꿈 같은 거예요.\\n\\n그러니까 우리가 하고 싶은 거 쉽게 말하면 이 인공지능이라는 요소가 딱 잘 정의되진 않는데 예를 들면 예전에 있던 그 바둑에 있는 바둑 AI나 그 스타크래프트에서 이제 컴퓨터 상대를 넣었어요.\\n\\n그런 것도 다 인공지능이라고 불러요.\\n\\n실제로는 그렇게 부를 수 있고요.\\n\\n그러니까 인공지능이라는 것 자체가 굉장히 어마어마한 개념이고 그렇진 않은 거예요.\\n\\n근데 이제 우리 일반인들 입장에서는 좀 터미네이터 같은 걸 생각하겠죠.\\n\\n인공지능으로.\\n\\n저 일하는 입장에서 인공지능은 어떤 물건이냐 하면요.\\n\\n스스로 배워요.\\n\\n그러니까 저는 이제 프로그래머를 짜서 뭐 컴파일을 하거나 아니면 뭐 스크립트를 실행하면 얘가 막 돌아가거든요.\\n\\n근데 시킨 대로 돌아가요.\\n\\n얘는.\\n\\n예를 들면 제가 정말 어렵게 엄청 힘든 건데 프로그램을 막 짜서 개랑 고양이 구분하는 프로그램을 짰다고 해볼게요.\\n\\n근데 이 프로그램은요.\\n\\n제가 그 다음에 코끼리를 어떻게 하려고 하면 다시 짜야 돼요.\\n\\n또.\\n\\n코끼리 구분하는 코드를 막 짜야 되죠.\\n\\n근데 이제 저는 사실 어떻게 하고 싶냐.\\n\\n프로그램 하나 만들어 놓고 코끼리 사진만 막 넣으면 코끼리도 구분했으면 좋겠는 거예요.\\n\\n프로그램이.\\n\\n제가 프로그램을 다시 짜는 것과 있는 프로그램 냅두고 사진만 모아서 긁어 넣는 것 중에 뭐가 쉽겠어요.\\n\\n사진만 넣는 게 훨씬 쉽죠.\\n\\n프로그램 짜라 그러면 끼약하겠지만 코끼리 사진을 1,000개 모아오라 하면 아마 즐겁게 모아올 거라고요.\\n\\n그냥.\\n\\n당연히 훨씬 쉽죠.\\n\\n그게.\\n\\n지금 말하는 인공지능에서 중요한 요소들은 그런 거예요.\\n\\n바둑 인공지능도 다 인공지능이고 한데 지금 우리가 중요하게 여기는 요소는 얘가 스스로 배워서 내놓는 결과를 바꾸는 물건이란 거예요.\\n\\n그쪽을 중요하게 봐온 게 그 인공지능인 거예요.\\n\\n그리고 반도체는 그거와 뭐가 관계가 있느냐.\\n\\n지금 제가 말씀드린 건 다 컨셉이죠.\\n\\n어떻게 만드는지에 대한 얘기가 없잖아요.\\n\\n그래서 그런 인공지능을 만드는 아이디어가 여러 개 있었어요.\\n\\nSVM 뭐 이런 방법도 있고 뭐 그냥 코드를 엄청 무식하게 짜보는 방법도 있고요.\\n\\n뭐 IBM 왓슨처럼 막 만드는 방법도 있는데 요거 다 다른 형태의 프로그램이잖아요.\\n\\n요 방법들 중에 제가 A라는 방법을 택하면 예를 들어 CPU가 빨라야 되고 메모리는 적어도 되고 B라는 방법을 쓰면 CPU보다 메모리가 중요하고 요런 식으로 바뀌어요.\\n\\n왜냐하면 프로그램도 그냥 CPU에서 도는 게 아니고요.\\n\\nCPU가 잘하는 일 중심으로 프로그램을 짜야 빠른 거잖아요.\\n\\n그게 반도체랑 인공지능 기술의 핵심인 거예요.\\n\\n우리는 인공지능이라는 추상적인 개념을 만들고 싶고요.\\n\\n그래서 그 추상적인 개념이 돌아가게 하기 위해서 여러 가지 아이디어를 쓰는 거예요.\\n\\n그중에 지금 제일 잘 되는 게 인공신경망이라는 개념이에요.\\n\\n인간의 뇌세포 구조를 좀 따라해서 그 신경망을 이제 우리 학습시킨 방법을 알아냈기 때문에 학습시키면은 우리가 원하던 인공지능 스스로 뭐 배우고 뭐 진짜 의미로 스스로 배우진 않죠 이제.\\n\\n우리가 코드를 다시 짜지 않아도 데이터만 넣어서 다시 학습시키면 원하는 결과 나오고 그런 걸 할 수 있는 게 이제 인공신경망이에요.\\n\\n근데 이 인공신경망은 특징이 CPU가 잘하는 일은 아니라는 거예요 얘가.\\n\\n그러니까 이제 기존에 CPU만 우리 90년대, 2000년대 CPU만 있었는데 지금 NVIDIA GPU를 쓰는 거예요.\\n\\n우리에겐 하고 싶은 일이 있고 그중에 그 일을 제일 잘하는 방법론을 찾아요.\\n\\n어떤 방식으로 프로그램을 만들어야 스스로 잘 배우는 프로그램이 된다.\\n\\n그리고 그 프로그램들은 각자 원하는 반도체가 달라요.\\n\\n그 일을 잘할 수 있는 반도체가 다르죠.\\n\\n그렇게 움직이는 거예요.\\n\\nCPU와 GPU의 큰 차이가? 사실 둘 다 메모리가 아니고 연산용 칩인데 CPU라는 거는 그 조건 파악을 잘해요.\\n\\n예를 들면 제 입장에서 머니인사이드의 시청자가 몇 명 이상이면 참여하고 아니면은 출연하지 마라.\\n\\n이런 식으로 그 조건이 있으면 선택을 하는 거잖아요.\\n\\n이런 식의 일을 되게 잘해요.\\n\\n그게 그 CPU가 잘하는 일이고요.\\n\\n그리고 GPU는 뭘 잘하냐 하면은 숫자 계산을 엄청 잘해요 그냥.\\n\\n0.1 곱하기 0.4 뭐 이런 숫자를 뭐 수만 개 계산하는 걸 엄청 잘해요.\\n\\n근데 우리가 과거에 봤던 수많은 프로그램들은요.\\n\\n앞에 말했던 조건이 중요해요.\\n\\n예를 들면 엑셀이잖아요.\\n\\n제가 엑셀 칸에다가 함수를 넣으면 만약 함수가 sum이면은 더해라.\\n\\n이런 거죠.\\n\\n이렇게 조건이잖아요 다.\\n\\n그래서 그런 걸 잘하게 설계되어 있어요 CPU는.\\n\\n근데 인공신경만 어떻게 돌아가냐 하면 그냥 입력값을 다 소수점으로 바꾼 다음에 소수점 곱셈을 엄청나게 해요.', metadata={}),\n",
      " Document(page_content='앞에 말했던 조건이 중요해요.\\n\\n예를 들면 엑셀이잖아요.\\n\\n제가 엑셀 칸에다가 함수를 넣으면 만약 함수가 sum이면은 더해라.\\n\\n이런 거죠.\\n\\n이렇게 조건이잖아요 다.\\n\\n그래서 그런 걸 잘하게 설계되어 있어요 CPU는.\\n\\n근데 인공신경만 어떻게 돌아가냐 하면 그냥 입력값을 다 소수점으로 바꾼 다음에 소수점 곱셈을 엄청나게 해요.\\n\\n곱셈, 넛셈을 뭐 수억 번씩 하면 결과가 나오는데 그러면은 결과가 잘 나오는 그런 물건이에요.\\n\\n그러니까 어떻게 보면 인간이 조건을 하나씩 넣어주는 형태 프로그램에서 그냥 모두 다 숫자로 바꿔서 숫자로 와장창 곱하면은 이제 원하는 결과가 튀어나오는 좀 신기한 상황이 된 거죠.\\n\\nQ.\\n\\n인공지능 기술은 어떻게 변화할까요? 어떻게 보면 CPU가 좀 더 똑똑한 칩인데 우리가 지금 보는 인공지능 기술은 좀 무식한 방식으로 좀 더 나은 지성이 구현되어 있는 그런 모습이에요.\\n\\n숫자가 인공지능이 돌아가는 원리? 그러니까 인간 머리가 일단 그런 식으로 돌아가잖아요.\\n\\n왜냐하면 인간 유전자 안에 CPU 설계가 들어있겠어요? 그런 복잡한 설계가 있을까요? 인간 안에? 그 CPU 안에는 그 수십억 개 트랜지스터가 막 연결되어 있는 설계도가 있는데 인간은 그렇지 않잖아요.\\n\\n그래서 뇌세포들은 다 보면은 특정 뇌세포에 자극이 들어오면 인접한 뇌세포에다가 특정 그 역치값을 넘으면 자극을 전달하고 역치를 안 넘으면 자극을 안 전달하고 이렇게 돼 있어요.\\n\\n그 연결관계를 수조개 모아놓으면 지성이 되는 거잖아요.\\n\\n그리고 과거에는 문제가 뭐였냐면은 어 그러면 우리 인간 뇌 모습을 좀 따라해서 이렇게 막 연결하면 지성이 나올 거야.\\n\\n이론상.\\n\\n그 문제는 뭐냐? 이 연결이 예를 들면 A라는 뇌세포랑 B라는 뇌세포 사이 연결을 얼마나 강하게 전달해줘야 돼? 이런 걸 하나도 모르는 거예요.\\n\\n그러니까 우리가 앞에서 말한 프로그래밍이라는 개념은 아까 말한 것처럼 조건문을 쓰는 거였는데 이제는 그 세포와 세포 사이 연결 강도가 0.1이냐 0.3이냐 이런 거를 고민해야 되는 상황이 된 거예요.\\n\\n그 문제가 뭐겠어요? 수십억 개가 있는데 그중에 이거 세포 하나 딱 해서 얘네 둘 사이가 이게 영향을 뭘 주는 거야? 하면 그걸 알아내겠냐는 거예요.\\n\\n그걸 알 수가 없잖아요.\\n\\n그래서 오랫동안 힘들었던 거예요.\\n\\n인공지능, 인간 뇌세포를 따라해보자는 아이디어가 뭐 그렇게 참신한가요 이게? 60년대에 이미 나왔던 아이디어예요.\\n\\n근데 왜 사장 되고 이제야 떠올랐냐? 그때는 어 그래 이렇게 하면 될 것 같은데 정확하게는 뇌세포와 뇌세포의 연결관계를 어떻게 해줘야 얘가 잘 돌아가는지를 몰랐던 거야.\\n\\n그러니까 몇십 년을 쉰 거죠.\\n\\n이제 몇십 년 동안 그래서 아무도 못 해보고 있다가 캐나다 쪽에서 이제 그거 학습시키는 방법을 알아낸 거예요 그때.\\n\\n아 여기 데이터를 넣고 결과 값에서 어떤 식으로 계산을 해주면 인공신경망이 서서히 정답률이 올라가게 만들 수 있다.\\n\\n요거를 알아냈어요 그때.\\n\\n그 방법을 써보니까 GPU를 써야 빨라요.\\n\\n그렇게 해서 지금의 상황이 된 거예요 이건.\\n\\n쉽게 말하면 프로그램 쓰는 방법이 바뀌어버린 거예요.\\n\\n기존에는 프로그램 쓸 때 제가 순서도를 놓고 이 순서도를 잘못 자면 버그고 그랬는데요.\\n\\n지금은 인공신경망을 크게 구성을 해놓고 그 안에서 값이 정답을 낼 수 있는 형태로 그 수많은 소수점을 바꿔가야 되는 거예요.\\n\\n그래서 GPU가 필요한 거죠.\\n\\nQ.\\n\\n인공신경망을 어떻게 만들어야 할까요? 원래 옛날 게임들은 화면에 표시하는 거랑 게임의 움직임들 표시하는 걸 전부 CPU가 했어요.\\n\\n근데 이제 컴퓨터라는 게 PC라는 게 나오고 계속 유행하다 보니까 사람들이 점점 더 높은 그래픽을 원해요.\\n\\n점점 더 그래픽 좋은 게임도 하고 싶고 영화도 만들고 싶고 이런 거예요.\\n\\n근데 말씀드렸지만 CPU는 분기 처리를 잘해요.\\n\\n조건 처리를 잘하죠.\\n\\n근데 고급 그래픽을 계속 해보니까 이게 CPU에 잘 맞지 않았던 거예요.\\n\\n그래서 CPU에 잘 맞지 않으니까 VGA라고 부르는 그래픽 전용 칩을 만들어서 쉽게 말하면 이런 거예요.\\n\\n제가 여기 인테리어를 해야 되는데 인테리어 디자인도 하고 벽지도 붙이고 청소도 다 했는데 이제는 CPU가 GPU라고 부르는 협력사를 데려와서 저는 여기는 도배하고 여기는 청소하고 시켜놓으면 이걸 하고 가게 하는 거예요.\\n\\n그리고 저는 이제 앉아서 계속 다음번 도배해야 될 거 찾고 있고요.\\n\\nGPU라는 녀석이 와서 도배 같은 일을 해주는 거예요.\\n\\n이 GPU는 제가 하는 일은 잘 못하지만 제가 잘 못하는 걸 잘하는 거죠.\\n\\n결국은 CPU라는 칩이 모든 일을 잘하기에는 한계가 있었던 거예요.\\n\\n왜냐하면 CPU가 아까 말한 조건문 처리를 잘하려면 그쪽에다 소자를 써야 되는데 거기에 소자를 쓰면은 다른 쪽에 쓸 소자가 없잖아요, 제조할 때.\\n\\n그러니까 모든 걸 잘할 수 없으니까 생겨난 일이죠.\\n\\n다행스럽게도 엔비디아가 의도한 바는 아니겠죠, 아마.\\n\\n인공지능 기술을 해내기 위해서 여러 연구를 하는데 제일 잘 되는 기술이 그래픽이랑 비슷한 연산을 요구했던 거예요.\\n\\n제가 그래픽 돌아가는 거...\\n\\n예, 왜냐하면 그래픽도 결국 소수점 많이 곱하고 더하고 하는 거예요.\\n\\n살짝 얻어걸린 느낌도 있죠, 이거는.\\n\\n그래픽을 했는데 회사가 계속 커야 되니까 CPU는 못하고 GPU는 잘하는 일을 계속 찾아다녔어요, 이 회사가.\\n\\n어, 이게 잘 될 거야 라는 그런 느낌으로 바로 가서 2006년, 2007년에 막 질른 게 아니고 전 세계 사람들이 좀 GPU를 쓰기 편하게 이제 CUDA 이런 걸 만들어놨어요.\\n\\n그러니까 엔비디아 생각이 이런 거예요.\\n\\n아, 이게 그래픽에만 쓰진 않겠지.\\n\\n뭐 슈퍼컴퓨터나 시뮬레이션에도 쓸 수 있고 그래서 그 물리연산하는 회사를 인수하기도 하고 그랬어요.\\n\\n근데 이제 그런 걸 그냥 만들어놓고 칩 쓰세요 라고 하면은 쓰는 법을 몰라요, 사람들이.\\n\\n왜냐하면 제가 CPU용으로 프로그램 짜던 사람이 GPU용으로 프로그램 짜려고 하면 진입장벽이 꽤 높거든요.', metadata={}),\n",
      " Document(page_content='아, 이게 그래픽에만 쓰진 않겠지.\\n\\n뭐 슈퍼컴퓨터나 시뮬레이션에도 쓸 수 있고 그래서 그 물리연산하는 회사를 인수하기도 하고 그랬어요.\\n\\n근데 이제 그런 걸 그냥 만들어놓고 칩 쓰세요 라고 하면은 쓰는 법을 몰라요, 사람들이.\\n\\n왜냐하면 제가 CPU용으로 프로그램 짜던 사람이 GPU용으로 프로그램 짜려고 하면 진입장벽이 꽤 높거든요.\\n\\n그래서 엔비디아는 그걸 조금이나마 좀 편하게 해주려고 CUDA 이런 것들을 마련을 해놓은 거죠.\\n\\n근데 그걸 마련해놓은 상황이 이거 쉽게 말하면 캐나다에서 집어다 써본 거에 가까워요.\\n\\n어, 그랬더니 연산속도가 5배 빨라졌어요.\\n\\n뭐 이런 식으로 결과가 나오니까 이제 옆방 대학원생이 이걸로 한 달에 하나 쓰던 논문을 한 달에 5개씩 쓰고 있으면 그러면 나도 써야 되고 그럼 그 옆방 대학원생도 쓰고 할 거잖아요, 당연히.\\n\\n근데 이게 굉장히 반도체 비즈니스에서 사실은 중요한 요소예요.\\n\\n옆사람이 썼는데 안 되던 게 됐잖아요.\\n\\n그러면 그걸 본 옆사람이 쓰죠.\\n\\n그러면 이제 이걸 잘 쓴 사람이 논문 찍어내면서 유명해지죠.\\n\\n그러면 어느 순간 그게 거대한 프로그래머 집단으로 변해요.\\n\\n그러면 이제 지금 2023년 상황에서 제가 대학원 갓 졸업하고 논문 써야 되는데 인공지능으로 논문을 써야 되겠는데 그러면 컴퓨터를 마련하는데 뭘 마련할 거냐 이거예요.\\n\\n전 지금 하나도 안 해봤으니까 일단 남들 하는 걸 다 모방해야 된다니까요.\\n\\n남들 쓰는 컴퓨터 사고 그럼 당연히 엔비디아 GPU 들어가요.\\n\\n그리고 인공지능 한 번도 안 돌려봤으니까 인터넷에 돈을 오픈소스를 받아다가 인공지능을 돌려봐야 돼요.\\n\\n그 오픈소스는 뭘로 쓰여 있겠어요.\\n\\n이것도 엔비디아 GPU를 전제하고 써놨다고요 코드를.\\n\\n그러니까 AMD가 못하는 거예요.\\n\\n이거를 AMD 그래픽 카드로 이제 뭔가 해보려고 실제 실험은 하지도 못하는 거예요.\\n\\n제가 근데 엔비디아 거 쓰면 물어보면 되잖아요.\\n\\n야 넌 어떻게 했니? 이렇게.\\n\\n그게 그 반도체 비즈니스에서 되게 중요한 거예요.\\n\\n생태계예요 이게.\\n\\n어떻게 보면 메모리 같은 건 그런 생태계가 좀 약하고요.\\n\\n인텔의 CPU 같은 것도 그런 생태계를 가지고 있잖아요.\\n\\n그러니까 한참 동안 인텔 CPU가 지금도 그렇게 힘들어해도 살아있는 거예요.\\n\\n여기에 맞춰진 프로그램이 많으니까.\\n\\n반도체 시장은 이제 당분간은 거대 신경망 특히 자연화 신경망이 잘 된다고 했으니까 아마 그쪽 연구개발 수요는 올라갈 거예요.\\n\\n근데 연구개발 이상으로 이제 꾸준한 수요를 만들어내려면 많은 부분에서는 연구를 해봐야 된다고 생각해요.\\n\\n왜냐하면 지금 신경망 학습시키는 게 장점만 있는 건 아니에요.\\n\\n단점은 얘가 인간이랑 제일 큰 차이점이 데이터 한 두 개 보고 학습이 안 된다는 거예요.\\n\\n예를 들면 여기 버닝사이드 시청자 여러분은 영상을 만 개씩 봐야 특정 테마를 익힐 수 있는 것이 아니잖아요.\\n\\n하나만 봐도 익히죠.\\n\\n근데 인공지능은 문제와 정답상 하나 가지고 배울 수가 없고 엄청 많이 봐야 돼요.\\n\\nGPT를 통한 인공지능 변호사 이런 거 만들려면 일단 데이터 장벽부터 있는 거예요.\\n\\n질문과 정답상이 충분히 있냐.\\n\\n그런 것들이 지금은 다 조사가 안 돼 있고 이제야 사람들을 찾아보는 중일 거잖아요.\\n\\n그러니까 저는 당분간은 연구개발 수요는 크겠지만 이게 정말 세상을 바꿀 만큼 여기저기 적용될 건지 아니면 마이크로소프트만 자기들 검색엔진과 오피스에 쓸 건지 이거는 저는 좀 봐야 된다고 생각해요.\\n\\n우리나라의 발표체는 어떻게 쓰일 것인가요? 일단 제일 크게 쓰이는 건 역시 메모리죠.\\n\\n인공신경망의 특징 중 하나는요.\\n\\nCPU용으로 짠 프로그램보다 용량이 엄청나게 크다는 거예요.\\n\\n정말 코드를 잘 짜서 숫자가 5를 넘으면 뭐 안녕하세요 말하는 코드를 쓴다.\\n\\n이거는 용량 진짜로 몇 킬로바이트 안 하거든요.\\n\\n근데 제가 동일한 일을 하려는 걸 인공신경망으로 만들면 용량이 몇백배 커요, 실제로는.\\n\\n그래서 메모리 중에 고용량, 고대역폭 메모리가 중요한 거예요, 지금.\\n\\n일단 한국에서 제일 주요하게 팔리는 것들은 인공지능 쪽에 그 HBM 같은 고용량 고속 메모리들이죠.\\n\\n그쪽에서 확실히 수요가 있다고 봐야죠.\\n\\n그러니까 이런 느낌이에요.\\n\\n예를 들면 제가 CPU 프로그램에다가 1 더하기 1을 계산하게 시키면 프로그램 용량 해봤자 얼마나 하겠어요.\\n\\n근데 저한테 1 더하기 1 물어보고 MRI 찍으면 순식간에 뻘겋뻘겋해졌다가 없어진다고요.\\n\\n되게 비율적이잖아요, 그렇게 보면.\\n\\n용량이 크다니까요, 그렇게.\\n\\n여기 뇌세포 하나하나로 옮겨 놓는 거잖아요.\\n\\n1 더하기 1을 하기 위해서 뇌세포를 거쳐가는 신호의 개수가 뭐 3개겠냐 이거예요.\\n\\n1 더하기 1은 2.\\n\\n3개 들어가면 한 개 답이 나오는 게 아니고 수백억 개가 막 여기서 반응을 하잖아요.\\n\\n그거를 재현해야 되는 거잖아요, 컴퓨터의 내부에 맞춰서.\\n\\n고용량 메모리가 필요할 텐데 당장 물량을 딱 고민해보면 마이크로소프트 엣저이 슈퍼컴퓨터가 엔비디아 V100인가 하는 학습용 GPU를 만 개인가 엮었거든요.\\n\\n근데 이거 만 개 엮으면 이게 메모리 용량이 40만 기가바이트 그래요.\\n\\n엄청 큰 것 같지만 우리 평균 스마트폰에 8기가 들어가잖아요.\\n\\n8기가 들어가면 이거 2만 개 팔아도 스마트폰으로 한 5배? 40이랑 8이니까 5배죠? 그러면 스마트폰 판매량으로는 한 10만 개 정도 되겠네요.\\n\\n근데 스마트폰 1년에 10억 개 팔잖아요, 전 세계에.\\n\\n그러니까 이것만으로는 물량이 엄청 크지 않다는 얘기를 하는 거예요.\\n\\n엣저이 슈퍼컴퓨터 1년에 한 100개씩 팔아도 전체 메모리 물량에서 크진 않죠.\\n\\n물론 메모리 용량된 단가는 크게 쳐주겠지만.\\n\\n그래서 이게 GPT 같은 게 메모리 시장에 예전에는 PC였고, 스마트폰이었고, 지금은 서버인데 제사의 어떤 수요를 만들려면요.\\n\\n지금 연구개발 수요로 안 된다는 이야기를 하는 거예요.\\n\\n연구개발 수요 말고 꾸준히 사용되는 수요가 있어야 되는데 왜냐하면 연구개발하는 건 결국 한 번 사고 잘 안 되면 버릴 거잖아요.', metadata={}),\n",
      " Document(page_content='그래서 이게 GPT 같은 게 메모리 시장에 예전에는 PC였고, 스마트폰이었고, 지금은 서버인데 제사의 어떤 수요를 만들려면요.\\n\\n지금 연구개발 수요로 안 된다는 이야기를 하는 거예요.\\n\\n연구개발 수요 말고 꾸준히 사용되는 수요가 있어야 되는데 왜냐하면 연구개발하는 건 결국 한 번 사고 잘 안 되면 버릴 거잖아요.\\n\\n근데 꾸준히 써야 되면 연구개발용도 계속 사고 상업용으로도 계속 사야 되니까 수요가 꾸준히 늘어나죠.\\n\\n근데 그걸 알려면 사실 메모리 시장이나 엔비디아를 볼 게 아니고 우리가 GPT 같은 걸로 하고 싶은 사업모델 중에 데이터들의 쌍이 잘 갖춰져 있는 곳이 있나 그거를 알아야 답을 할 수 있다는 얘기인 거예요.\\n\\n전 그래서 지금은 그걸로 메모리 시장이 확 바뀔 거다 그렇게까지는 기대하지 않아요.\\n\\n지금 인공지능은요.\\n\\n우리가 좀 이렇게 착각들을 하는 게 인터넷에는 데이터가 무한하니까 그냥 데이터 넣으면 똑똑해지겠네 라고 생각하거나 그렇지가 않아요.\\n\\n예를 들어서 제가 개와 고양이를 구분시켜야 된다고 하면 사진만 넣는 게 아니라 사진에 개라고 써놔야 돼요.\\n\\n고양이 사진 고양이라고 써놔야 되고요.\\n\\n그렇게 질문과 정답 쌍이 있어야 배울 수 있는 거예요.\\n\\n사진은 그래도 좀 쉽죠.\\n\\n이거 뭐 사람 몇 명 쓰면 사진 100만 개 만들 수 있을 거예요.\\n\\n근데 말하는 인공지능은 어떨까요? 이거 질문과 대답 쌍을 만들기 쉬울까요? 우리 인터넷에 글을 그냥 긁으면 질문과 대답 쌍이 충분히 많이 나올까요? 그러니까 그 안에서는 질문과 대답 쌍 자체를 찾는 것도 되게 어렵고요.\\n\\n그리고 그중에 신뢰할 수 있는 말이 있느냐 이것도 되게 중요해요.\\n\\n지금 GPT 같은 게 학습이 잘 될 수밖에 없는 게 요약 같은 거 되게 잘하거든요.\\n\\n해보면 왜 요약이 잘 되냐 하면요.\\n\\n요약은 이미 그 인터넷에 쌍이 많이 있거든요.\\n\\n제가 일일이 GPT에 만들어줄 몇 테라바이트 데이터를 일일이 질문 답변 쓰는 건 수학적으로 말이 안 돼요.\\n\\n왜냐하면 사람이 열심히 쳐봤자 제가 한 만 단어 치는 것도 힘든데 일주일 동안 근데 얘는 수백억 단어가 필요한데 그거 사람 뽑아서 한다고 되겠어요? 그게? 안 되죠.\\n\\n대부분 있는 데이터 중에 좋은 데이터를 정제해서 쓰는 게 중요해요.\\n\\n근데 예를 들면 요약 같은 거는 위키페디아 이런 거 있잖아요.\\n\\n인트로덕션 안에 사실상 요약이에요.\\n\\n그리고 밑에가 본문이잖아요.\\n\\n본문을 주고 이거 요약해줘 한 다음에 정답을 인트로덕션 같은 걸 넣어서 할 수가 있거든요.\\n\\n그런 일들은 잘 되는 거예요.\\n\\n근데 이제 예를 들면 우리가 GPT가 세상을 바꾸려면 그런 식으로 쓸 수 있는 데이터가 있는 곳이어야 적용 가능한 거예요.\\n\\n예를 들면 제가 법조계 쪽으로 GPT를 쓰고 싶고 GPT를 학습시키고 싶잖아요.\\n\\n그러면 그것도 판례랑 답이 있어야 되는데 그것도 이제 얼마나 좋은 판례인지 이런 걸 다 매겨줘야 된다는 거예요.\\n\\n그 양도 많아야 되는 거죠.\\n\\n그리고 그러고 나면 사업성 문제가 생겨요.\\n\\n그렇게 한국에서 이거 학습을 시켰는데 미국에 쓸 수 있어요, 그거? 못 쓰죠.\\n\\n미국법이 아니니까 그건.\\n\\n이거는 상장된 회사는 아닌데 세레브라스 이런 회사들이 있어요.\\n\\n정확하게는 NVIDIA GPU도 완벽한 칩은 아니에요.\\n\\n인공지능 쪽에서는 범용적이고 쓰기 편한 칩이긴 한데 얘도 한계가 있어요.\\n\\n예를 들면 지금 도는 채집 PT 같은 거 말했지만 애저 슈퍼컴퓨터의 그래픽카드 만 개를 엮었다고 했잖아요.\\n\\n근데 그렇게 엮으면 비효율도 크고 비용도 크거든요.\\n\\n그래서 이제 세레브라스 같은 회사는 그만한 GPU를 하나씩 엮을 바에 이따만한 칩을 웨이퍼 하나에 놓고 그 안에 신경망을 한 번에 다 올리자 이런 식으로 얘기를 해요.\\n\\n이거는 단일 GPU 안에 다 안 들어가서 이거를 쪼개서 담기 위한 노력도 많이 하고 그 비효율이 많거든요.\\n\\n근데 이제 그런 거대한 칩에는 신경망이 한 번에 딱 들어가죠.\\n\\n그러면 기존에 이론상으로는 할 수 있지만 GPU의 용량 한 개로 해보기 힘들었던 걸 많이 해볼 수 있어요.\\n\\n그런 칩들을 쓰면.\\n\\n저는 이제 그런 무류의 칩들을 보는 건 나쁘지 않다고 생각해요.\\n\\n정확하게 이제 조건은 두 개 있어요.\\n\\n이런 칩들이 잘 되려면 첫째로 지금 채집 PT와 비슷한데 거대한 언어모델이죠, 이게.\\n\\n내가 하려고 하는 사업 분야에 데이터가 아까 말한 형태의 데이터가 있고요.\\n\\n그런 데이터들이 풍족하고 근데 NVIDIA GPU 쓰면 원가가 좀 안 나오는 애들.\\n\\n이런 애들일 때 가능성이 있는 거예요.\\n\\n예를 들면 제가 비즈니스를 하고 싶은데 이 채집 PT 같은 거 지금 공개된 거는 한 3,000단어 정도만 입력으로 들어갈 수 있어요.\\n\\n제가 채집 PT랑 대화를 주고받는다 그러면 대화 총합이 3,000단어 넘어가면 까먹어요, 얘는.\\n\\n원래 그런 디자인인 거예요.\\n\\n근데 그거를 늘리려면 늘릴 때 데이터도 많이 필요하고요.\\n\\n늘린 다음에 사양도 훨씬 많이 먹어요.\\n\\n이제 기술 발전이 좀 있긴 하겠지만 지금 상황에서는 그 3,000단어를 6,000단어로 늘리면 4배 정도 커져요, 얘가 대충.\\n\\n연산해야 되니까 4배씩 커지게 되니까 제가 이제 사업 모델을 봤더니 아, 3,000단어는 부족하고 뭐 8만 단어까지 하고 싶다.\\n\\n이러면 NVIDIA GPU 지금 1만 개 엮어서 했는데 몇 개 엮어서 할 거예요, 그때? 100만 개 엮어서 할 건가요? 그렇게 할 수 없잖아요.\\n\\n그러면 새로운 반도체 찾는 거죠.\\n\\n그 아파트들의 검폐율을 보면 보통 17%씩 높입니다.\\n\\n땅을 20평만 지어야 돼요.\\n\\n100평 되려면 10층이 돼야 200평 나오잖아요, 그렇죠? 이 시스템만 아시면 아시면 부동산은 제가 장담하고 있는데 반은 이미 안 갑니다.\\n\\n나머지는 디테일입니다.\\n\\n이걸 정확히 모르고 저 땅이 예쁘다, 이런 거 얘기할 필요 없습니다.', metadata={})]\n",
      "2730\n",
      "2823\n",
      "2895\n",
      "2650\n",
      "11098\n"
     ]
    },
    {
     "ename": "InvalidRequestError",
     "evalue": "This model's maximum context length is 4097 tokens. However, your messages resulted in 11128 tokens. Please reduce the length of the messages.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/jaden/Documents/code_collec/ChatGPT/langchain/langchain_summarization.ipynb 셀 11\u001b[0m in \u001b[0;36m<cell line: 59>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jaden/Documents/code_collec/ChatGPT/langchain/langchain_summarization.ipynb#X20sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jaden/Documents/code_collec/ChatGPT/langchain/langchain_summarization.ipynb#X20sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39m스터핑은 가장 간단한 방법으로, 모든 관련 데이터를 프롬프트에 컨텍스트로 채워 언어 모델에 전달하기만 하면 됩니다. 이것은 LangChain에서 StuffDocumentsChain으로 구현됩니다.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jaden/Documents/code_collec/ChatGPT/langchain/langchain_summarization.ipynb#X20sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jaden/Documents/code_collec/ChatGPT/langchain/langchain_summarization.ipynb#X20sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39m이 방법의 가장 큰 단점은 작은 데이터 조각에서만 작동한다는 것입니다. 많은 데이터 조각으로 작업하는 경우에는 이 접근 방식을 더 이상 사용할 수 없습니다. 다음 두 가지 접근 방식은 이러한 문제를 해결하기 위해 고안되었습니다.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jaden/Documents/code_collec/ChatGPT/langchain/langchain_summarization.ipynb#X20sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jaden/Documents/code_collec/ChatGPT/langchain/langchain_summarization.ipynb#X20sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39m# res = chain({\"input_documents\": docs}, return_only_outputs=True)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jaden/Documents/code_collec/ChatGPT/langchain/langchain_summarization.ipynb#X20sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m chain\u001b[39m.\u001b[39;49mrun(docs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jaden/Documents/code_collec/ChatGPT/langchain/langchain_summarization.ipynb#X20sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m res\n",
      "File \u001b[0;32m~/miniforge3/envs/autogpt/lib/python3.9/site-packages/langchain/chains/base.py:213\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    212\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`run` supports only one positional argument.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 213\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(args[\u001b[39m0\u001b[39;49m])[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n\u001b[1;32m    215\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(kwargs)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n",
      "File \u001b[0;32m~/miniforge3/envs/autogpt/lib/python3.9/site-packages/langchain/chains/base.py:116\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    115\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[0;32m--> 116\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    117\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_end(outputs, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[1;32m    118\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001b[0;32m~/miniforge3/envs/autogpt/lib/python3.9/site-packages/langchain/chains/base.py:113\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    108\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[1;32m    109\u001b[0m     inputs,\n\u001b[1;32m    110\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose,\n\u001b[1;32m    111\u001b[0m )\n\u001b[1;32m    112\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs)\n\u001b[1;32m    114\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    115\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n",
      "File \u001b[0;32m~/miniforge3/envs/autogpt/lib/python3.9/site-packages/langchain/chains/combine_documents/base.py:75\u001b[0m, in \u001b[0;36mBaseCombineDocumentsChain._call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[39m# Other keys are assumed to be needed for LLM prediction\u001b[39;00m\n\u001b[1;32m     74\u001b[0m other_keys \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m inputs\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_key}\n\u001b[0;32m---> 75\u001b[0m output, extra_return_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcombine_docs(docs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mother_keys)\n\u001b[1;32m     76\u001b[0m extra_return_dict[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key] \u001b[39m=\u001b[39m output\n\u001b[1;32m     77\u001b[0m \u001b[39mreturn\u001b[39;00m extra_return_dict\n",
      "File \u001b[0;32m~/miniforge3/envs/autogpt/lib/python3.9/site-packages/langchain/chains/combine_documents/stuff.py:83\u001b[0m, in \u001b[0;36mStuffDocumentsChain.combine_docs\u001b[0;34m(self, docs, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_inputs(docs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     82\u001b[0m \u001b[39m# Call predict on the LLM.\u001b[39;00m\n\u001b[0;32m---> 83\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm_chain\u001b[39m.\u001b[39;49mpredict(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs), {}\n",
      "File \u001b[0;32m~/miniforge3/envs/autogpt/lib/python3.9/site-packages/langchain/chains/llm.py:151\u001b[0m, in \u001b[0;36mLLMChain.predict\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m    138\u001b[0m     \u001b[39m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \n\u001b[1;32m    140\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[39m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 151\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(kwargs)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key]\n",
      "File \u001b[0;32m~/miniforge3/envs/autogpt/lib/python3.9/site-packages/langchain/chains/base.py:116\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    115\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[0;32m--> 116\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    117\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_end(outputs, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[1;32m    118\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001b[0;32m~/miniforge3/envs/autogpt/lib/python3.9/site-packages/langchain/chains/base.py:113\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    108\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[1;32m    109\u001b[0m     inputs,\n\u001b[1;32m    110\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose,\n\u001b[1;32m    111\u001b[0m )\n\u001b[1;32m    112\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs)\n\u001b[1;32m    114\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    115\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n",
      "File \u001b[0;32m~/miniforge3/envs/autogpt/lib/python3.9/site-packages/langchain/chains/llm.py:57\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\u001b[39mself\u001b[39m, inputs: Dict[\u001b[39mstr\u001b[39m, Any]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply([inputs])[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniforge3/envs/autogpt/lib/python3.9/site-packages/langchain/chains/llm.py:118\u001b[0m, in \u001b[0;36mLLMChain.apply\u001b[0;34m(self, input_list)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\u001b[39mself\u001b[39m, input_list: List[Dict[\u001b[39mstr\u001b[39m, Any]]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]]:\n\u001b[1;32m    117\u001b[0m     \u001b[39m\"\"\"Utilize the LLM generate method for speed gains.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(input_list)\n\u001b[1;32m    119\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_outputs(response)\n",
      "File \u001b[0;32m~/miniforge3/envs/autogpt/lib/python3.9/site-packages/langchain/chains/llm.py:62\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[0;34m(self, input_list)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39m\"\"\"Generate LLM result from inputs.\"\"\"\u001b[39;00m\n\u001b[1;32m     61\u001b[0m prompts, stop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_prompts(input_list)\n\u001b[0;32m---> 62\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm\u001b[39m.\u001b[39;49mgenerate_prompt(prompts, stop)\n",
      "File \u001b[0;32m~/miniforge3/envs/autogpt/lib/python3.9/site-packages/langchain/chat_models/base.py:82\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     81\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_llm_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[0;32m---> 82\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m     83\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_llm_end(output, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[1;32m     84\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/miniforge3/envs/autogpt/lib/python3.9/site-packages/langchain/chat_models/base.py:79\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_llm_start(\n\u001b[1;32m     76\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m}, prompt_strings, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose\n\u001b[1;32m     77\u001b[0m )\n\u001b[1;32m     78\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 79\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(prompt_messages, stop\u001b[39m=\u001b[39;49mstop)\n\u001b[1;32m     80\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     81\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_llm_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n",
      "File \u001b[0;32m~/miniforge3/envs/autogpt/lib/python3.9/site-packages/langchain/chat_models/base.py:54\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate\u001b[39m(\n\u001b[1;32m     51\u001b[0m     \u001b[39mself\u001b[39m, messages: List[List[BaseMessage]], stop: Optional[List[\u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     52\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m     53\u001b[0m     \u001b[39m\"\"\"Top Level call\"\"\"\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m     results \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(m, stop\u001b[39m=\u001b[39mstop) \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m messages]\n\u001b[1;32m     55\u001b[0m     llm_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_combine_llm_outputs([res\u001b[39m.\u001b[39mllm_output \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results])\n\u001b[1;32m     56\u001b[0m     generations \u001b[39m=\u001b[39m [res\u001b[39m.\u001b[39mgenerations \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results]\n",
      "File \u001b[0;32m~/miniforge3/envs/autogpt/lib/python3.9/site-packages/langchain/chat_models/base.py:54\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate\u001b[39m(\n\u001b[1;32m     51\u001b[0m     \u001b[39mself\u001b[39m, messages: List[List[BaseMessage]], stop: Optional[List[\u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     52\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m     53\u001b[0m     \u001b[39m\"\"\"Top Level call\"\"\"\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m     results \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(m, stop\u001b[39m=\u001b[39;49mstop) \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m messages]\n\u001b[1;32m     55\u001b[0m     llm_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_combine_llm_outputs([res\u001b[39m.\u001b[39mllm_output \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results])\n\u001b[1;32m     56\u001b[0m     generations \u001b[39m=\u001b[39m [res\u001b[39m.\u001b[39mgenerations \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results]\n",
      "File \u001b[0;32m~/miniforge3/envs/autogpt/lib/python3.9/site-packages/langchain/chat_models/openai.py:266\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[0;34m(self, messages, stop)\u001b[0m\n\u001b[1;32m    262\u001b[0m     message \u001b[39m=\u001b[39m _convert_dict_to_message(\n\u001b[1;32m    263\u001b[0m         {\u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: inner_completion, \u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: role}\n\u001b[1;32m    264\u001b[0m     )\n\u001b[1;32m    265\u001b[0m     \u001b[39mreturn\u001b[39;00m ChatResult(generations\u001b[39m=\u001b[39m[ChatGeneration(message\u001b[39m=\u001b[39mmessage)])\n\u001b[0;32m--> 266\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompletion_with_retry(messages\u001b[39m=\u001b[39;49mmessage_dicts, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m    267\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[0;32m~/miniforge3/envs/autogpt/lib/python3.9/site-packages/langchain/chat_models/openai.py:228\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[1;32m    225\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    226\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 228\u001b[0m \u001b[39mreturn\u001b[39;00m _completion_with_retry(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/autogpt/lib/python3.9/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/miniforge3/envs/autogpt/lib/python3.9/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[1;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/autogpt/lib/python3.9/site-packages/tenacity/__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    312\u001b[0m is_explicit_retry \u001b[39m=\u001b[39m fut\u001b[39m.\u001b[39mfailed \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(fut\u001b[39m.\u001b[39mexception(), TryAgain)\n\u001b[1;32m    313\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (is_explicit_retry \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretry(retry_state)):\n\u001b[0;32m--> 314\u001b[0m     \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    316\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter(retry_state)\n",
      "File \u001b[0;32m~/miniforge3/envs/autogpt/lib/python3.9/concurrent/futures/_base.py:433\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    432\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 433\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    435\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    437\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/miniforge3/envs/autogpt/lib/python3.9/concurrent/futures/_base.py:389\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__get_result\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m--> 389\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    390\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\n",
      "File \u001b[0;32m~/miniforge3/envs/autogpt/lib/python3.9/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    383\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n\u001b[1;32m    384\u001b[0m         retry_state\u001b[39m.\u001b[39mset_exception(sys\u001b[39m.\u001b[39mexc_info())  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/autogpt/lib/python3.9/site-packages/langchain/chat_models/openai.py:226\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry.<locals>._completion_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[1;32m    225\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m--> 226\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/autogpt/lib/python3.9/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/miniforge3/envs/autogpt/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/miniforge3/envs/autogpt/lib/python3.9/site-packages/openai/api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    206\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    207\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    215\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    216\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    217\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    218\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    225\u001b[0m     )\n\u001b[0;32m--> 226\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    227\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/miniforge3/envs/autogpt/lib/python3.9/site-packages/openai/api_requestor.py:619\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    612\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    613\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    614\u001b[0m         )\n\u001b[1;32m    615\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    616\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    618\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 619\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    620\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    621\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    622\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    623\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    624\u001b[0m         ),\n\u001b[1;32m    625\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    626\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/autogpt/lib/python3.9/site-packages/openai/api_requestor.py:682\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    680\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    681\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 682\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    683\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: This model's maximum context length is 4097 tokens. However, your messages resulted in 11128 tokens. Please reduce the length of the messages."
     ]
    }
   ],
   "source": [
    "# stuff chain은 한번에 통째로 입력을 집어넣어서 요약을 진행함으로 문장을 모델이 감당할 수 있을 정도로 미리 정의해서 넣어줘야함\n",
    "# 그리고 아래 출력은 넘어갔을때 에러를 일부로 보여주는 예시임\n",
    "\n",
    "# https://python.langchain.com/en/latest/reference/modules/text_splitter.html\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain import OpenAI, PromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.docstore.document import Document\n",
    "from pprint import pprint\n",
    "import tiktoken\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "\n",
    "\n",
    "with open('./정인성작가_transcript.txt', 'r', encoding='utf-8') as f:\n",
    "    transcript = f.read()\n",
    "\n",
    "transcript = transcript.replace('. ', '.\\n\\n')\n",
    "enc35 = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "# tokenized_text_chatgpt35 = enc35.encode(transcript)\n",
    "# print(len(tokenized_text_chatgpt35))\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=3000, chunk_overlap=200)\n",
    "texts = text_splitter.split_text(transcript) # 문장 분리 길이 4000 미만 및 chunk_overlap 200\n",
    "docs = [Document(page_content=t) for t in texts]\n",
    "pprint(docs)\n",
    "tmp_tok = 0\n",
    "for doc in docs:\n",
    "    tokenized_text_chatgpt35 = enc35.encode(doc.page_content)\n",
    "    # print(len(tokenized_text_chatgpt35))\n",
    "    tmp_tok += len(tokenized_text_chatgpt35)\n",
    "print('전체 토큰수', tmp_tok)\n",
    "\n",
    "############################################################################################################\n",
    "bullet_point_prompt_template = \"\"\"다음 문장을 요약해주세요:\n",
    "\n",
    "{text}\n",
    "\n",
    "한국어 문장요약 결과:\n",
    "\"\"\"\n",
    "############################################################################################################\n",
    "bullet_point_prompt = PromptTemplate(template=bullet_point_prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "# 모든 데이터에 한번에 엑세스 하므로 전체 토큰이 \n",
    "llmc = ChatOpenAI(temperature=0.9, model_name=\"gpt-3.5-turbo\")\n",
    "chain = load_summarize_chain(llmc, \n",
    "                             chain_type=\"stuff\",  \n",
    "                             prompt=bullet_point_prompt)\n",
    "'''\n",
    "스터핑은 가장 간단한 방법으로, 모든 관련 데이터를 프롬프트에 컨텍스트로 채워 언어 모델에 전달하기만 하면 됩니다. 이것은 LangChain에서 StuffDocumentsChain으로 구현됩니다.\n",
    "\n",
    "장점: LLM을 한 번만 호출합니다. 텍스트를 생성할 때 LLM이 모든 데이터에 한 번에 액세스할 수 있습니다.\n",
    "\n",
    "단점: 대부분의 LLM에는 컨텍스트 길이가 있으며, 큰 문서(또는 많은 문서)의 경우 컨텍스트 길이보다 큰 프롬프트가 표시되므로 이 방법은 작동하지 않습니다.\n",
    "\n",
    "이 방법의 가장 큰 단점은 작은 데이터 조각에서만 작동한다는 것입니다. 많은 데이터 조각으로 작업하는 경우에는 이 접근 방식을 더 이상 사용할 수 없습니다. 다음 두 가지 접근 방식은 이러한 문제를 해결하기 위해 고안되었습니다.\n",
    "'''\n",
    "\n",
    "# res = chain({\"input_documents\": docs}, return_only_outputs=True)\n",
    "chain.run(docs) # 이렇게 stuff는 한번에 언어모델이 감당할 수 있는 토큰수를 넘어가면 안됨\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'인공신경망은 특징이 CPU가 잘하는 일은 아니라는 거예요.\\n\\n숫자가 5를 넘으면 안녕하세요 말하는 코드를 쓴다.\\n\\n이거는 용량 진짜로 몇 킬로바이트 안 하거든요? 근데 제가 동일한 일을 하려는 걸 인공신경망으로 만들면 용량이 몇백배 커요.\\n\\nNVIDIA GPU도 완벽한 칩은 아니에요.\\n\\n예전 슈퍼컴퓨터에 그래픽카드 만 개를 엮었다고 했잖아요.\\n\\n근데 그렇게 엮으면 비효율도 크고 비용도 크거든요.\\n\\nGPT를 통한 인공지능 변호사 이런 거 만들려면 데이터 장벽부터 있는 거예요.\\n\\n예전에는 PC였고 스마트폰이었고 지금은 서버인데 제 사회의 어떤 수요를 만들려면요.\\n\\n안녕하세요.\\n\\n머니인사이드 시청자 여러분 정인성 작가입니다.\\n\\n저는 원래 반도체 회사에서 반도체 관련한 시뮬레이션 일을 하고 있었고요.\\n\\n최근에 인공지능 관련해서도 새로운 책을 쓸 수 있었고요.\\n\\n지금은 이제 동료들이랑 인공지능 개발 쪽으로 와 있습니다.\\n\\n스타릿에서 어떤...\\n\\n반도체들을 완제품을 만들고 나면 이 반도체들을 또 뭉쳐서 그 위에다가 조그마한 컨트롤러를 붙여서 막 동작을 하게 만들어요.\\n\\n쉽게 말하면 원본 반도체가 아니고 반도체들을 결합해서 새로운 가치를 만드는 거죠.\\n\\n이제 그런 것들을 시뮬레이션으로 검증하는 그런 일들을 했죠.\\n\\n인공지능은 용어를 구분할 필요가 있는데 인공지능은 우리 꿈 같은 거예요.\\n\\n그러니까 우리가 하고 싶은 거 쉽게 말하면 이 인공지능이라는 요소가 딱 잘 정의되진 않는데 예를 들면 예전에 있던 그 바둑에 있는 바둑 AI나 그 스타크래프트에서 이제 컴퓨터 상대를 넣었어요.\\n\\n그런 것도 다 인공지능이라고 불러요.\\n\\n실제로는 그렇게 부를 수 있고요.\\n\\n그러니까 인공지능이라는 것 자체가 굉장히 어마어마한 개념이고 그렇진 않은 거예요.\\n\\n근데 이제 우리 일반인들 입장에서는 좀 터미네이터 같은 걸 생각하겠죠.\\n\\n인공지능으로.\\n\\n저 일하는 입장에서 인공지능은 어떤 물건이냐 하면요.\\n\\n스스로 배워요.\\n\\n그러니까 저는 이제 프로그래머를 짜서 뭐 컴파일을 하거나 아니면 뭐 스크립트를 실행하면 얘가 막 돌아가거든요.\\n\\n근데 시킨 대로 돌아가요.\\n\\n얘는.\\n\\n예를 들면 제가 정말 어렵게 엄청 힘든 건데 프로그램을 막 짜서 개랑 고양이 구분하는 프로그램을 짰다고 해볼게요.\\n\\n근데 이 프로그램은요.\\n\\n제가 그 다음에 코끼리를 어떻게 하려고 하면 다시 짜야 돼요.\\n\\n또.\\n\\n코끼리 구분하는 코드를 막 짜야 되죠.\\n\\n근데 이제 저는 사실 어떻게 하고 싶냐.\\n\\n프로그램 하나 만들어 놓고 코끼리 사진만 막 넣으면 코끼리도 구분했으면 좋겠는 거예요.\\n\\n프로그램이.\\n\\n제가 프로그램을 다시 짜는 것과 있는 프로그램 냅두고 사진만 모아서 긁어 넣는 것 중에 뭐가 쉽겠어요.\\n\\n사진만 넣는 게 훨씬 쉽죠.\\n\\n프로그램 짜라 그러면 끼약하겠지만 코끼리 사진을 1,000개 모아오라 하면 아마 즐겁게 모아올 거라고요.\\n\\n그냥.\\n\\n당연히 훨씬 쉽죠.\\n\\n그게.\\n\\n지금 말하는 인공지능에서 중요한 요소들은 그런 거예요.\\n\\n바둑 인공지능도 다 인공지능이고 한데 지금 우리가 중요하게 여기는 요소는 얘가 스스로 배워서 내놓는 결과를 바꾸는 물건이란 거예요.\\n\\n그쪽을 중요하게 봐온 게 그 인공지능인 거예요.\\n\\n그리고 반도체는 그거와 뭐가 관계가 있느냐.\\n\\n지금 제가 말씀드린 건 다 컨셉이죠.\\n\\n어떻게 만드는지에 대한 얘기가 없잖아요.\\n\\n그래서 그런 인공지능을 만드는 아이디어가 여러 개 있었어요.\\n\\nSVM 뭐 이런 방법도 있고 뭐 그냥 코드를 엄청 무식하게 짜보는 방법도 있고요.\\n\\n뭐 IBM 왓슨처럼 막 만드는 방법도 있는데 요거 다 다른 형태의 프로그램이잖아요.\\n\\n요 방법들 중에 제가 A라는 방법을 택하면 예를 들어 CPU가 빨라야 되고 메모리는 적어도 되고 B라는 방법을 쓰면 CPU보다 메모리가 중요하고 요런 식으로 바뀌어요.\\n\\n왜냐하면 프로그램도 그냥 CPU에서 도는 게 아니고요.\\n\\nCPU가 잘하는 일 중심으로 프로그램을 짜야 빠른 거잖아요.\\n\\n그게 반도체랑 인공지능 기술의 핵심인 거예요.\\n\\n우리는 인공지능이라는 추상적인 개념을 만들고 싶고요.\\n\\n그래서 그 추상적인 개념이 돌아가게 하기 위해서 여러 가지 아이디어를 쓰는 거예요.\\n\\n그중에 지금 제일 잘 되는 게 인공신경망이라는 개념이에요.\\n\\n인간의 뇌세포 구조를 좀 따라해서 그 신경망을 이제 우리 학습시킨 방법을 알아냈기 때문에 학습시키면은 우리가 원하던 인공지능 스스로 뭐 배우고 뭐 진짜 의미로 스스로 배우진 않죠 이제.\\n\\n우리가 코드를 다시 짜지 않아도 데이터만 넣어서 다시 학습시키면 원하는 결과 나오고 그런 걸 할 수 있는 게 이제 인공신경망이에요.\\n\\n근데 이 인공신경망은 특징이 CPU가 잘하는 일은 아니라는 거예요 얘가.\\n\\n그러니까 이제 기존에 CPU만 우리 90년대, 2000년대 CPU만 있었는데 지금 NVIDIA GPU를 쓰는 거예요.\\n\\n우리에겐 하고 싶은 일이 있고 그중에 그 일을 제일 잘하는 방법론을 찾아요.\\n\\n어떤 방식으로 프로그램을 만들어야 스스로 잘 배우는 프로그램이 된다.\\n\\n그리고 그 프로그램들은 각자 원하는 반도체가 달라요.\\n\\n그 일을 잘할 수 있는 반도체가 다르죠.\\n\\n그렇게 움직이는 거예요.\\n\\nCPU와 GPU의 큰 차이가? 사실 둘 다 메모리가 아니고 연산용 칩인데 CPU라는 거는 그 조건 파악을 잘해요.\\n\\n예를 들면 제 입장에서 머니인사이드의 시청자가 몇 명 이상이면 참여하고 아니면은 출연하지 마라.\\n\\n이런 식으로 그 조건이 있으면 선택을 하는 거잖아요.\\n\\n이런 식의 일을 되게 잘해요.\\n\\n그게 그 CPU가 잘하는 일이고요.\\n\\n그리고 GPU는 뭘 잘하냐 하면은 숫자 계산을 엄청 잘해요 그냥.\\n\\n0.1 곱하기 0.4 뭐 이런 숫자를 뭐 수만 개 계산하는 걸 엄청 잘해요.\\n\\n근데 우리가 과거에 봤던 수많은 프로그램들은요.\\n\\n앞에 말했던 조건이 중요해요.\\n\\n예를 들면 엑셀이잖아요.\\n\\n제가 엑셀 칸에다가 함수를 넣으면 만약 함수가 sum이면은 더해라.\\n\\n이런 거죠.\\n\\n이렇게 조건이잖아요 다.\\n\\n그래서 그런 걸 잘하게 설계되어 있어요 CPU는.\\n\\n근데 인공신경만 어떻게 돌아가냐 하면 그냥 입력값을 다 소수점으로 바꾼 다음에 소수점 곱셈을 엄청나게 해요.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='인공신경망은 특징이 CPU가 잘하는 일은 아니라는 거예요.\\n\\n숫자가 5를 넘으면 안녕하세요 말하는 코드를 쓴다.\\n\\n이거는 용량 진짜로 몇 킬로바이트 안 하거든요? 근데 제가 동일한 일을 하려는 걸 인공신경망으로 만들면 용량이 몇백배 커요.\\n\\nNVIDIA GPU도 완벽한 칩은 아니에요.\\n\\n예전 슈퍼컴퓨터에 그래픽카드 만 개를 엮었다고 했잖아요.\\n\\n근데 그렇게 엮으면 비효율도 크고 비용도 크거든요.\\n\\nGPT를 통한 인공지능 변호사 이런 거 만들려면 데이터 장벽부터 있는 거예요.\\n\\n예전에는 PC였고 스마트폰이었고 지금은 서버인데 제 사회의 어떤 수요를 만들려면요.\\n\\n안녕하세요.\\n\\n머니인사이드 시청자 여러분 정인성 작가입니다.\\n\\n저는 원래 반도체 회사에서 반도체 관련한 시뮬레이션 일을 하고 있었고요.\\n\\n최근에 인공지능 관련해서도 새로운 책을 쓸 수 있었고요.\\n\\n지금은 이제 동료들이랑 인공지능 개발 쪽으로 와 있습니다.\\n\\n스타릿에서 어떤...\\n\\n반도체들을 완제품을 만들고 나면 이 반도체들을 또 뭉쳐서 그 위에다가 조그마한 컨트롤러를 붙여서 막 동작을 하게 만들어요.\\n\\n쉽게 말하면 원본 반도체가 아니고 반도체들을 결합해서 새로운 가치를 만드는 거죠.\\n\\n이제 그런 것들을 시뮬레이션으로 검증하는 그런 일들을 했죠.\\n\\n인공지능은 용어를 구분할 필요가 있는데 인공지능은 우리 꿈 같은 거예요.\\n\\n그러니까 우리가 하고 싶은 거 쉽게 말하면 이 인공지능이라는 요소가 딱 잘 정의되진 않는데 예를 들면 예전에 있던 그 바둑에 있는 바둑 AI나 그 스타크래프트에서 이제 컴퓨터 상대를 넣었어요.\\n\\n그런 것도 다 인공지능이라고 불러요.\\n\\n실제로는 그렇게 부를 수 있고요.\\n\\n그러니까 인공지능이라는 것 자체가 굉장히 어마어마한 개념이고 그렇진 않은 거예요.\\n\\n근데 이제 우리 일반인들 입장에서는 좀 터미네이터 같은 걸 생각하겠죠.\\n\\n인공지능으로.\\n\\n저 일하는 입장에서 인공지능은 어떤 물건이냐 하면요.\\n\\n스스로 배워요.\\n\\n그러니까 저는 이제 프로그래머를 짜서 뭐 컴파일을 하거나 아니면 뭐 스크립트를 실행하면 얘가 막 돌아가거든요.\\n\\n근데 시킨 대로 돌아가요.\\n\\n얘는.\\n\\n예를 들면 제가 정말 어렵게 엄청 힘든 건데 프로그램을 막 짜서 개랑 고양이 구분하는 프로그램을 짰다고 해볼게요.\\n\\n근데 이 프로그램은요.\\n\\n제가 그 다음에 코끼리를 어떻게 하려고 하면 다시 짜야 돼요.\\n\\n또.\\n\\n코끼리 구분하는 코드를 막 짜야 되죠.\\n\\n근데 이제 저는 사실 어떻게 하고 싶냐.\\n\\n프로그램 하나 만들어 놓고 코끼리 사진만 막 넣으면 코끼리도 구분했으면 좋겠는 거예요.\\n\\n프로그램이.\\n\\n제가 프로그램을 다시 짜는 것과 있는 프로그램 냅두고 사진만 모아서 긁어 넣는 것 중에 뭐가 쉽겠어요.\\n\\n사진만 넣는 게 훨씬 쉽죠.\\n\\n프로그램 짜라 그러면 끼약하겠지만 코끼리 사진을 1,000개 모아오라 하면 아마 즐겁게 모아올 거라고요.\\n\\n그냥.\\n\\n당연히 훨씬 쉽죠.\\n\\n그게.\\n\\n지금 말하는 인공지능에서 중요한 요소들은 그런 거예요.\\n\\n바둑 인공지능도 다 인공지능이고 한데 지금 우리가 중요하게 여기는 요소는 얘가 스스로 배워서 내놓는 결과를 바꾸는 물건이란 거예요.\\n\\n그쪽을 중요하게 봐온 게 그 인공지능인 거예요.\\n\\n그리고 반도체는 그거와 뭐가 관계가 있느냐.\\n\\n지금 제가 말씀드린 건 다 컨셉이죠.\\n\\n어떻게 만드는지에 대한 얘기가 없잖아요.\\n\\n그래서 그런 인공지능을 만드는 아이디어가 여러 개 있었어요.\\n\\nSVM 뭐 이런 방법도 있고 뭐 그냥 코드를 엄청 무식하게 짜보는 방법도 있고요.\\n\\n뭐 IBM 왓슨처럼 막 만드는 방법도 있는데 요거 다 다른 형태의 프로그램이잖아요.\\n\\n요 방법들 중에 제가 A라는 방법을 택하면 예를 들어 CPU가 빨라야 되고 메모리는 적어도 되고 B라는 방법을 쓰면 CPU보다 메모리가 중요하고 요런 식으로 바뀌어요.\\n\\n왜냐하면 프로그램도 그냥 CPU에서 도는 게 아니고요.\\n\\nCPU가 잘하는 일 중심으로 프로그램을 짜야 빠른 거잖아요.\\n\\n그게 반도체랑 인공지능 기술의 핵심인 거예요.\\n\\n우리는 인공지능이라는 추상적인 개념을 만들고 싶고요.\\n\\n그래서 그 추상적인 개념이 돌아가게 하기 위해서 여러 가지 아이디어를 쓰는 거예요.\\n\\n그중에 지금 제일 잘 되는 게 인공신경망이라는 개념이에요.\\n\\n인간의 뇌세포 구조를 좀 따라해서 그 신경망을 이제 우리 학습시킨 방법을 알아냈기 때문에 학습시키면은 우리가 원하던 인공지능 스스로 뭐 배우고 뭐 진짜 의미로 스스로 배우진 않죠 이제.\\n\\n우리가 코드를 다시 짜지 않아도 데이터만 넣어서 다시 학습시키면 원하는 결과 나오고 그런 걸 할 수 있는 게 이제 인공신경망이에요.\\n\\n근데 이 인공신경망은 특징이 CPU가 잘하는 일은 아니라는 거예요 얘가.\\n\\n그러니까 이제 기존에 CPU만 우리 90년대, 2000년대 CPU만 있었는데 지금 NVIDIA GPU를 쓰는 거예요.\\n\\n우리에겐 하고 싶은 일이 있고 그중에 그 일을 제일 잘하는 방법론을 찾아요.\\n\\n어떤 방식으로 프로그램을 만들어야 스스로 잘 배우는 프로그램이 된다.\\n\\n그리고 그 프로그램들은 각자 원하는 반도체가 달라요.\\n\\n그 일을 잘할 수 있는 반도체가 다르죠.\\n\\n그렇게 움직이는 거예요.\\n\\nCPU와 GPU의 큰 차이가? 사실 둘 다 메모리가 아니고 연산용 칩인데 CPU라는 거는 그 조건 파악을 잘해요.\\n\\n예를 들면 제 입장에서 머니인사이드의 시청자가 몇 명 이상이면 참여하고 아니면은 출연하지 마라.\\n\\n이런 식으로 그 조건이 있으면 선택을 하는 거잖아요.\\n\\n이런 식의 일을 되게 잘해요.\\n\\n그게 그 CPU가 잘하는 일이고요.\\n\\n그리고 GPU는 뭘 잘하냐 하면은 숫자 계산을 엄청 잘해요 그냥.\\n\\n0.1 곱하기 0.4 뭐 이런 숫자를 뭐 수만 개 계산하는 걸 엄청 잘해요.\\n\\n근데 우리가 과거에 봤던 수많은 프로그램들은요.\\n\\n앞에 말했던 조건이 중요해요.\\n\\n예를 들면 엑셀이잖아요.\\n\\n제가 엑셀 칸에다가 함수를 넣으면 만약 함수가 sum이면은 더해라.\\n\\n이런 거죠.\\n\\n이렇게 조건이잖아요 다.\\n\\n그래서 그런 걸 잘하게 설계되어 있어요 CPU는.\\n\\n근데 인공신경만 어떻게 돌아가냐 하면 그냥 입력값을 다 소수점으로 바꾼 다음에 소수점 곱셈을 엄청나게 해요.', metadata={}),\n",
      " Document(page_content='앞에 말했던 조건이 중요해요.\\n\\n예를 들면 엑셀이잖아요.\\n\\n제가 엑셀 칸에다가 함수를 넣으면 만약 함수가 sum이면은 더해라.\\n\\n이런 거죠.\\n\\n이렇게 조건이잖아요 다.\\n\\n그래서 그런 걸 잘하게 설계되어 있어요 CPU는.\\n\\n근데 인공신경만 어떻게 돌아가냐 하면 그냥 입력값을 다 소수점으로 바꾼 다음에 소수점 곱셈을 엄청나게 해요.\\n\\n곱셈, 넛셈을 뭐 수억 번씩 하면 결과가 나오는데 그러면은 결과가 잘 나오는 그런 물건이에요.\\n\\n그러니까 어떻게 보면 인간이 조건을 하나씩 넣어주는 형태 프로그램에서 그냥 모두 다 숫자로 바꿔서 숫자로 와장창 곱하면은 이제 원하는 결과가 튀어나오는 좀 신기한 상황이 된 거죠.\\n\\nQ.\\n\\n인공지능 기술은 어떻게 변화할까요? 어떻게 보면 CPU가 좀 더 똑똑한 칩인데 우리가 지금 보는 인공지능 기술은 좀 무식한 방식으로 좀 더 나은 지성이 구현되어 있는 그런 모습이에요.\\n\\n숫자가 인공지능이 돌아가는 원리? 그러니까 인간 머리가 일단 그런 식으로 돌아가잖아요.\\n\\n왜냐하면 인간 유전자 안에 CPU 설계가 들어있겠어요? 그런 복잡한 설계가 있을까요? 인간 안에? 그 CPU 안에는 그 수십억 개 트랜지스터가 막 연결되어 있는 설계도가 있는데 인간은 그렇지 않잖아요.\\n\\n그래서 뇌세포들은 다 보면은 특정 뇌세포에 자극이 들어오면 인접한 뇌세포에다가 특정 그 역치값을 넘으면 자극을 전달하고 역치를 안 넘으면 자극을 안 전달하고 이렇게 돼 있어요.\\n\\n그 연결관계를 수조개 모아놓으면 지성이 되는 거잖아요.\\n\\n그리고 과거에는 문제가 뭐였냐면은 어 그러면 우리 인간 뇌 모습을 좀 따라해서 이렇게 막 연결하면 지성이 나올 거야.\\n\\n이론상.\\n\\n그 문제는 뭐냐? 이 연결이 예를 들면 A라는 뇌세포랑 B라는 뇌세포 사이 연결을 얼마나 강하게 전달해줘야 돼? 이런 걸 하나도 모르는 거예요.\\n\\n그러니까 우리가 앞에서 말한 프로그래밍이라는 개념은 아까 말한 것처럼 조건문을 쓰는 거였는데 이제는 그 세포와 세포 사이 연결 강도가 0.1이냐 0.3이냐 이런 거를 고민해야 되는 상황이 된 거예요.\\n\\n그 문제가 뭐겠어요? 수십억 개가 있는데 그중에 이거 세포 하나 딱 해서 얘네 둘 사이가 이게 영향을 뭘 주는 거야? 하면 그걸 알아내겠냐는 거예요.\\n\\n그걸 알 수가 없잖아요.\\n\\n그래서 오랫동안 힘들었던 거예요.\\n\\n인공지능, 인간 뇌세포를 따라해보자는 아이디어가 뭐 그렇게 참신한가요 이게? 60년대에 이미 나왔던 아이디어예요.\\n\\n근데 왜 사장 되고 이제야 떠올랐냐? 그때는 어 그래 이렇게 하면 될 것 같은데 정확하게는 뇌세포와 뇌세포의 연결관계를 어떻게 해줘야 얘가 잘 돌아가는지를 몰랐던 거야.\\n\\n그러니까 몇십 년을 쉰 거죠.\\n\\n이제 몇십 년 동안 그래서 아무도 못 해보고 있다가 캐나다 쪽에서 이제 그거 학습시키는 방법을 알아낸 거예요 그때.\\n\\n아 여기 데이터를 넣고 결과 값에서 어떤 식으로 계산을 해주면 인공신경망이 서서히 정답률이 올라가게 만들 수 있다.\\n\\n요거를 알아냈어요 그때.\\n\\n그 방법을 써보니까 GPU를 써야 빨라요.\\n\\n그렇게 해서 지금의 상황이 된 거예요 이건.\\n\\n쉽게 말하면 프로그램 쓰는 방법이 바뀌어버린 거예요.\\n\\n기존에는 프로그램 쓸 때 제가 순서도를 놓고 이 순서도를 잘못 자면 버그고 그랬는데요.\\n\\n지금은 인공신경망을 크게 구성을 해놓고 그 안에서 값이 정답을 낼 수 있는 형태로 그 수많은 소수점을 바꿔가야 되는 거예요.\\n\\n그래서 GPU가 필요한 거죠.\\n\\nQ.\\n\\n인공신경망을 어떻게 만들어야 할까요? 원래 옛날 게임들은 화면에 표시하는 거랑 게임의 움직임들 표시하는 걸 전부 CPU가 했어요.\\n\\n근데 이제 컴퓨터라는 게 PC라는 게 나오고 계속 유행하다 보니까 사람들이 점점 더 높은 그래픽을 원해요.\\n\\n점점 더 그래픽 좋은 게임도 하고 싶고 영화도 만들고 싶고 이런 거예요.\\n\\n근데 말씀드렸지만 CPU는 분기 처리를 잘해요.\\n\\n조건 처리를 잘하죠.\\n\\n근데 고급 그래픽을 계속 해보니까 이게 CPU에 잘 맞지 않았던 거예요.\\n\\n그래서 CPU에 잘 맞지 않으니까 VGA라고 부르는 그래픽 전용 칩을 만들어서 쉽게 말하면 이런 거예요.\\n\\n제가 여기 인테리어를 해야 되는데 인테리어 디자인도 하고 벽지도 붙이고 청소도 다 했는데 이제는 CPU가 GPU라고 부르는 협력사를 데려와서 저는 여기는 도배하고 여기는 청소하고 시켜놓으면 이걸 하고 가게 하는 거예요.\\n\\n그리고 저는 이제 앉아서 계속 다음번 도배해야 될 거 찾고 있고요.\\n\\nGPU라는 녀석이 와서 도배 같은 일을 해주는 거예요.\\n\\n이 GPU는 제가 하는 일은 잘 못하지만 제가 잘 못하는 걸 잘하는 거죠.\\n\\n결국은 CPU라는 칩이 모든 일을 잘하기에는 한계가 있었던 거예요.\\n\\n왜냐하면 CPU가 아까 말한 조건문 처리를 잘하려면 그쪽에다 소자를 써야 되는데 거기에 소자를 쓰면은 다른 쪽에 쓸 소자가 없잖아요, 제조할 때.\\n\\n그러니까 모든 걸 잘할 수 없으니까 생겨난 일이죠.\\n\\n다행스럽게도 엔비디아가 의도한 바는 아니겠죠, 아마.\\n\\n인공지능 기술을 해내기 위해서 여러 연구를 하는데 제일 잘 되는 기술이 그래픽이랑 비슷한 연산을 요구했던 거예요.\\n\\n제가 그래픽 돌아가는 거...\\n\\n예, 왜냐하면 그래픽도 결국 소수점 많이 곱하고 더하고 하는 거예요.\\n\\n살짝 얻어걸린 느낌도 있죠, 이거는.\\n\\n그래픽을 했는데 회사가 계속 커야 되니까 CPU는 못하고 GPU는 잘하는 일을 계속 찾아다녔어요, 이 회사가.\\n\\n어, 이게 잘 될 거야 라는 그런 느낌으로 바로 가서 2006년, 2007년에 막 질른 게 아니고 전 세계 사람들이 좀 GPU를 쓰기 편하게 이제 CUDA 이런 걸 만들어놨어요.\\n\\n그러니까 엔비디아 생각이 이런 거예요.\\n\\n아, 이게 그래픽에만 쓰진 않겠지.\\n\\n뭐 슈퍼컴퓨터나 시뮬레이션에도 쓸 수 있고 그래서 그 물리연산하는 회사를 인수하기도 하고 그랬어요.\\n\\n근데 이제 그런 걸 그냥 만들어놓고 칩 쓰세요 라고 하면은 쓰는 법을 몰라요, 사람들이.\\n\\n왜냐하면 제가 CPU용으로 프로그램 짜던 사람이 GPU용으로 프로그램 짜려고 하면 진입장벽이 꽤 높거든요.', metadata={}),\n",
      " Document(page_content='아, 이게 그래픽에만 쓰진 않겠지.\\n\\n뭐 슈퍼컴퓨터나 시뮬레이션에도 쓸 수 있고 그래서 그 물리연산하는 회사를 인수하기도 하고 그랬어요.\\n\\n근데 이제 그런 걸 그냥 만들어놓고 칩 쓰세요 라고 하면은 쓰는 법을 몰라요, 사람들이.\\n\\n왜냐하면 제가 CPU용으로 프로그램 짜던 사람이 GPU용으로 프로그램 짜려고 하면 진입장벽이 꽤 높거든요.\\n\\n그래서 엔비디아는 그걸 조금이나마 좀 편하게 해주려고 CUDA 이런 것들을 마련을 해놓은 거죠.\\n\\n근데 그걸 마련해놓은 상황이 이거 쉽게 말하면 캐나다에서 집어다 써본 거에 가까워요.\\n\\n어, 그랬더니 연산속도가 5배 빨라졌어요.\\n\\n뭐 이런 식으로 결과가 나오니까 이제 옆방 대학원생이 이걸로 한 달에 하나 쓰던 논문을 한 달에 5개씩 쓰고 있으면 그러면 나도 써야 되고 그럼 그 옆방 대학원생도 쓰고 할 거잖아요, 당연히.\\n\\n근데 이게 굉장히 반도체 비즈니스에서 사실은 중요한 요소예요.\\n\\n옆사람이 썼는데 안 되던 게 됐잖아요.\\n\\n그러면 그걸 본 옆사람이 쓰죠.\\n\\n그러면 이제 이걸 잘 쓴 사람이 논문 찍어내면서 유명해지죠.\\n\\n그러면 어느 순간 그게 거대한 프로그래머 집단으로 변해요.\\n\\n그러면 이제 지금 2023년 상황에서 제가 대학원 갓 졸업하고 논문 써야 되는데 인공지능으로 논문을 써야 되겠는데 그러면 컴퓨터를 마련하는데 뭘 마련할 거냐 이거예요.\\n\\n전 지금 하나도 안 해봤으니까 일단 남들 하는 걸 다 모방해야 된다니까요.\\n\\n남들 쓰는 컴퓨터 사고 그럼 당연히 엔비디아 GPU 들어가요.\\n\\n그리고 인공지능 한 번도 안 돌려봤으니까 인터넷에 돈을 오픈소스를 받아다가 인공지능을 돌려봐야 돼요.\\n\\n그 오픈소스는 뭘로 쓰여 있겠어요.\\n\\n이것도 엔비디아 GPU를 전제하고 써놨다고요 코드를.\\n\\n그러니까 AMD가 못하는 거예요.\\n\\n이거를 AMD 그래픽 카드로 이제 뭔가 해보려고 실제 실험은 하지도 못하는 거예요.\\n\\n제가 근데 엔비디아 거 쓰면 물어보면 되잖아요.\\n\\n야 넌 어떻게 했니? 이렇게.\\n\\n그게 그 반도체 비즈니스에서 되게 중요한 거예요.\\n\\n생태계예요 이게.\\n\\n어떻게 보면 메모리 같은 건 그런 생태계가 좀 약하고요.\\n\\n인텔의 CPU 같은 것도 그런 생태계를 가지고 있잖아요.\\n\\n그러니까 한참 동안 인텔 CPU가 지금도 그렇게 힘들어해도 살아있는 거예요.\\n\\n여기에 맞춰진 프로그램이 많으니까.\\n\\n반도체 시장은 이제 당분간은 거대 신경망 특히 자연화 신경망이 잘 된다고 했으니까 아마 그쪽 연구개발 수요는 올라갈 거예요.\\n\\n근데 연구개발 이상으로 이제 꾸준한 수요를 만들어내려면 많은 부분에서는 연구를 해봐야 된다고 생각해요.\\n\\n왜냐하면 지금 신경망 학습시키는 게 장점만 있는 건 아니에요.\\n\\n단점은 얘가 인간이랑 제일 큰 차이점이 데이터 한 두 개 보고 학습이 안 된다는 거예요.\\n\\n예를 들면 여기 버닝사이드 시청자 여러분은 영상을 만 개씩 봐야 특정 테마를 익힐 수 있는 것이 아니잖아요.\\n\\n하나만 봐도 익히죠.\\n\\n근데 인공지능은 문제와 정답상 하나 가지고 배울 수가 없고 엄청 많이 봐야 돼요.\\n\\nGPT를 통한 인공지능 변호사 이런 거 만들려면 일단 데이터 장벽부터 있는 거예요.\\n\\n질문과 정답상이 충분히 있냐.\\n\\n그런 것들이 지금은 다 조사가 안 돼 있고 이제야 사람들을 찾아보는 중일 거잖아요.\\n\\n그러니까 저는 당분간은 연구개발 수요는 크겠지만 이게 정말 세상을 바꿀 만큼 여기저기 적용될 건지 아니면 마이크로소프트만 자기들 검색엔진과 오피스에 쓸 건지 이거는 저는 좀 봐야 된다고 생각해요.\\n\\n우리나라의 발표체는 어떻게 쓰일 것인가요? 일단 제일 크게 쓰이는 건 역시 메모리죠.\\n\\n인공신경망의 특징 중 하나는요.\\n\\nCPU용으로 짠 프로그램보다 용량이 엄청나게 크다는 거예요.\\n\\n정말 코드를 잘 짜서 숫자가 5를 넘으면 뭐 안녕하세요 말하는 코드를 쓴다.\\n\\n이거는 용량 진짜로 몇 킬로바이트 안 하거든요.\\n\\n근데 제가 동일한 일을 하려는 걸 인공신경망으로 만들면 용량이 몇백배 커요, 실제로는.\\n\\n그래서 메모리 중에 고용량, 고대역폭 메모리가 중요한 거예요, 지금.\\n\\n일단 한국에서 제일 주요하게 팔리는 것들은 인공지능 쪽에 그 HBM 같은 고용량 고속 메모리들이죠.\\n\\n그쪽에서 확실히 수요가 있다고 봐야죠.\\n\\n그러니까 이런 느낌이에요.\\n\\n예를 들면 제가 CPU 프로그램에다가 1 더하기 1을 계산하게 시키면 프로그램 용량 해봤자 얼마나 하겠어요.\\n\\n근데 저한테 1 더하기 1 물어보고 MRI 찍으면 순식간에 뻘겋뻘겋해졌다가 없어진다고요.\\n\\n되게 비율적이잖아요, 그렇게 보면.\\n\\n용량이 크다니까요, 그렇게.\\n\\n여기 뇌세포 하나하나로 옮겨 놓는 거잖아요.\\n\\n1 더하기 1을 하기 위해서 뇌세포를 거쳐가는 신호의 개수가 뭐 3개겠냐 이거예요.\\n\\n1 더하기 1은 2.\\n\\n3개 들어가면 한 개 답이 나오는 게 아니고 수백억 개가 막 여기서 반응을 하잖아요.\\n\\n그거를 재현해야 되는 거잖아요, 컴퓨터의 내부에 맞춰서.\\n\\n고용량 메모리가 필요할 텐데 당장 물량을 딱 고민해보면 마이크로소프트 엣저이 슈퍼컴퓨터가 엔비디아 V100인가 하는 학습용 GPU를 만 개인가 엮었거든요.\\n\\n근데 이거 만 개 엮으면 이게 메모리 용량이 40만 기가바이트 그래요.\\n\\n엄청 큰 것 같지만 우리 평균 스마트폰에 8기가 들어가잖아요.\\n\\n8기가 들어가면 이거 2만 개 팔아도 스마트폰으로 한 5배? 40이랑 8이니까 5배죠? 그러면 스마트폰 판매량으로는 한 10만 개 정도 되겠네요.\\n\\n근데 스마트폰 1년에 10억 개 팔잖아요, 전 세계에.\\n\\n그러니까 이것만으로는 물량이 엄청 크지 않다는 얘기를 하는 거예요.\\n\\n엣저이 슈퍼컴퓨터 1년에 한 100개씩 팔아도 전체 메모리 물량에서 크진 않죠.\\n\\n물론 메모리 용량된 단가는 크게 쳐주겠지만.\\n\\n그래서 이게 GPT 같은 게 메모리 시장에 예전에는 PC였고, 스마트폰이었고, 지금은 서버인데 제사의 어떤 수요를 만들려면요.\\n\\n지금 연구개발 수요로 안 된다는 이야기를 하는 거예요.\\n\\n연구개발 수요 말고 꾸준히 사용되는 수요가 있어야 되는데 왜냐하면 연구개발하는 건 결국 한 번 사고 잘 안 되면 버릴 거잖아요.', metadata={}),\n",
      " Document(page_content='그래서 이게 GPT 같은 게 메모리 시장에 예전에는 PC였고, 스마트폰이었고, 지금은 서버인데 제사의 어떤 수요를 만들려면요.\\n\\n지금 연구개발 수요로 안 된다는 이야기를 하는 거예요.\\n\\n연구개발 수요 말고 꾸준히 사용되는 수요가 있어야 되는데 왜냐하면 연구개발하는 건 결국 한 번 사고 잘 안 되면 버릴 거잖아요.\\n\\n근데 꾸준히 써야 되면 연구개발용도 계속 사고 상업용으로도 계속 사야 되니까 수요가 꾸준히 늘어나죠.\\n\\n근데 그걸 알려면 사실 메모리 시장이나 엔비디아를 볼 게 아니고 우리가 GPT 같은 걸로 하고 싶은 사업모델 중에 데이터들의 쌍이 잘 갖춰져 있는 곳이 있나 그거를 알아야 답을 할 수 있다는 얘기인 거예요.\\n\\n전 그래서 지금은 그걸로 메모리 시장이 확 바뀔 거다 그렇게까지는 기대하지 않아요.\\n\\n지금 인공지능은요.\\n\\n우리가 좀 이렇게 착각들을 하는 게 인터넷에는 데이터가 무한하니까 그냥 데이터 넣으면 똑똑해지겠네 라고 생각하거나 그렇지가 않아요.\\n\\n예를 들어서 제가 개와 고양이를 구분시켜야 된다고 하면 사진만 넣는 게 아니라 사진에 개라고 써놔야 돼요.\\n\\n고양이 사진 고양이라고 써놔야 되고요.\\n\\n그렇게 질문과 정답 쌍이 있어야 배울 수 있는 거예요.\\n\\n사진은 그래도 좀 쉽죠.\\n\\n이거 뭐 사람 몇 명 쓰면 사진 100만 개 만들 수 있을 거예요.\\n\\n근데 말하는 인공지능은 어떨까요? 이거 질문과 대답 쌍을 만들기 쉬울까요? 우리 인터넷에 글을 그냥 긁으면 질문과 대답 쌍이 충분히 많이 나올까요? 그러니까 그 안에서는 질문과 대답 쌍 자체를 찾는 것도 되게 어렵고요.\\n\\n그리고 그중에 신뢰할 수 있는 말이 있느냐 이것도 되게 중요해요.\\n\\n지금 GPT 같은 게 학습이 잘 될 수밖에 없는 게 요약 같은 거 되게 잘하거든요.\\n\\n해보면 왜 요약이 잘 되냐 하면요.\\n\\n요약은 이미 그 인터넷에 쌍이 많이 있거든요.\\n\\n제가 일일이 GPT에 만들어줄 몇 테라바이트 데이터를 일일이 질문 답변 쓰는 건 수학적으로 말이 안 돼요.\\n\\n왜냐하면 사람이 열심히 쳐봤자 제가 한 만 단어 치는 것도 힘든데 일주일 동안 근데 얘는 수백억 단어가 필요한데 그거 사람 뽑아서 한다고 되겠어요? 그게? 안 되죠.\\n\\n대부분 있는 데이터 중에 좋은 데이터를 정제해서 쓰는 게 중요해요.\\n\\n근데 예를 들면 요약 같은 거는 위키페디아 이런 거 있잖아요.\\n\\n인트로덕션 안에 사실상 요약이에요.\\n\\n그리고 밑에가 본문이잖아요.\\n\\n본문을 주고 이거 요약해줘 한 다음에 정답을 인트로덕션 같은 걸 넣어서 할 수가 있거든요.\\n\\n그런 일들은 잘 되는 거예요.\\n\\n근데 이제 예를 들면 우리가 GPT가 세상을 바꾸려면 그런 식으로 쓸 수 있는 데이터가 있는 곳이어야 적용 가능한 거예요.\\n\\n예를 들면 제가 법조계 쪽으로 GPT를 쓰고 싶고 GPT를 학습시키고 싶잖아요.\\n\\n그러면 그것도 판례랑 답이 있어야 되는데 그것도 이제 얼마나 좋은 판례인지 이런 걸 다 매겨줘야 된다는 거예요.\\n\\n그 양도 많아야 되는 거죠.\\n\\n그리고 그러고 나면 사업성 문제가 생겨요.\\n\\n그렇게 한국에서 이거 학습을 시켰는데 미국에 쓸 수 있어요, 그거? 못 쓰죠.\\n\\n미국법이 아니니까 그건.\\n\\n이거는 상장된 회사는 아닌데 세레브라스 이런 회사들이 있어요.\\n\\n정확하게는 NVIDIA GPU도 완벽한 칩은 아니에요.\\n\\n인공지능 쪽에서는 범용적이고 쓰기 편한 칩이긴 한데 얘도 한계가 있어요.\\n\\n예를 들면 지금 도는 채집 PT 같은 거 말했지만 애저 슈퍼컴퓨터의 그래픽카드 만 개를 엮었다고 했잖아요.\\n\\n근데 그렇게 엮으면 비효율도 크고 비용도 크거든요.\\n\\n그래서 이제 세레브라스 같은 회사는 그만한 GPU를 하나씩 엮을 바에 이따만한 칩을 웨이퍼 하나에 놓고 그 안에 신경망을 한 번에 다 올리자 이런 식으로 얘기를 해요.\\n\\n이거는 단일 GPU 안에 다 안 들어가서 이거를 쪼개서 담기 위한 노력도 많이 하고 그 비효율이 많거든요.\\n\\n근데 이제 그런 거대한 칩에는 신경망이 한 번에 딱 들어가죠.\\n\\n그러면 기존에 이론상으로는 할 수 있지만 GPU의 용량 한 개로 해보기 힘들었던 걸 많이 해볼 수 있어요.\\n\\n그런 칩들을 쓰면.\\n\\n저는 이제 그런 무류의 칩들을 보는 건 나쁘지 않다고 생각해요.\\n\\n정확하게 이제 조건은 두 개 있어요.\\n\\n이런 칩들이 잘 되려면 첫째로 지금 채집 PT와 비슷한데 거대한 언어모델이죠, 이게.\\n\\n내가 하려고 하는 사업 분야에 데이터가 아까 말한 형태의 데이터가 있고요.\\n\\n그런 데이터들이 풍족하고 근데 NVIDIA GPU 쓰면 원가가 좀 안 나오는 애들.\\n\\n이런 애들일 때 가능성이 있는 거예요.\\n\\n예를 들면 제가 비즈니스를 하고 싶은데 이 채집 PT 같은 거 지금 공개된 거는 한 3,000단어 정도만 입력으로 들어갈 수 있어요.\\n\\n제가 채집 PT랑 대화를 주고받는다 그러면 대화 총합이 3,000단어 넘어가면 까먹어요, 얘는.\\n\\n원래 그런 디자인인 거예요.\\n\\n근데 그거를 늘리려면 늘릴 때 데이터도 많이 필요하고요.\\n\\n늘린 다음에 사양도 훨씬 많이 먹어요.\\n\\n이제 기술 발전이 좀 있긴 하겠지만 지금 상황에서는 그 3,000단어를 6,000단어로 늘리면 4배 정도 커져요, 얘가 대충.\\n\\n연산해야 되니까 4배씩 커지게 되니까 제가 이제 사업 모델을 봤더니 아, 3,000단어는 부족하고 뭐 8만 단어까지 하고 싶다.\\n\\n이러면 NVIDIA GPU 지금 1만 개 엮어서 했는데 몇 개 엮어서 할 거예요, 그때? 100만 개 엮어서 할 건가요? 그렇게 할 수 없잖아요.\\n\\n그러면 새로운 반도체 찾는 거죠.\\n\\n그 아파트들의 검폐율을 보면 보통 17%씩 높입니다.\\n\\n땅을 20평만 지어야 돼요.\\n\\n100평 되려면 10층이 돼야 200평 나오잖아요, 그렇죠? 이 시스템만 아시면 아시면 부동산은 제가 장담하고 있는데 반은 이미 안 갑니다.\\n\\n나머지는 디테일입니다.\\n\\n이걸 정확히 모르고 저 땅이 예쁘다, 이런 거 얘기할 필요 없습니다.', metadata={})]\n",
      "전체 토큰수 11098\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m다음 문장을 요약해주세요:\n",
      "\n",
      "인공신경망은 특징이 CPU가 잘하는 일은 아니라는 거예요.\n",
      "\n",
      "숫자가 5를 넘으면 안녕하세요 말하는 코드를 쓴다.\n",
      "\n",
      "이거는 용량 진짜로 몇 킬로바이트 안 하거든요? 근데 제가 동일한 일을 하려는 걸 인공신경망으로 만들면 용량이 몇백배 커요.\n",
      "\n",
      "NVIDIA GPU도 완벽한 칩은 아니에요.\n",
      "\n",
      "예전 슈퍼컴퓨터에 그래픽카드 만 개를 엮었다고 했잖아요.\n",
      "\n",
      "근데 그렇게 엮으면 비효율도 크고 비용도 크거든요.\n",
      "\n",
      "GPT를 통한 인공지능 변호사 이런 거 만들려면 데이터 장벽부터 있는 거예요.\n",
      "\n",
      "예전에는 PC였고 스마트폰이었고 지금은 서버인데 제 사회의 어떤 수요를 만들려면요.\n",
      "\n",
      "안녕하세요.\n",
      "\n",
      "머니인사이드 시청자 여러분 정인성 작가입니다.\n",
      "\n",
      "저는 원래 반도체 회사에서 반도체 관련한 시뮬레이션 일을 하고 있었고요.\n",
      "\n",
      "최근에 인공지능 관련해서도 새로운 책을 쓸 수 있었고요.\n",
      "\n",
      "지금은 이제 동료들이랑 인공지능 개발 쪽으로 와 있습니다.\n",
      "\n",
      "스타릿에서 어떤...\n",
      "\n",
      "반도체들을 완제품을 만들고 나면 이 반도체들을 또 뭉쳐서 그 위에다가 조그마한 컨트롤러를 붙여서 막 동작을 하게 만들어요.\n",
      "\n",
      "쉽게 말하면 원본 반도체가 아니고 반도체들을 결합해서 새로운 가치를 만드는 거죠.\n",
      "\n",
      "이제 그런 것들을 시뮬레이션으로 검증하는 그런 일들을 했죠.\n",
      "\n",
      "인공지능은 용어를 구분할 필요가 있는데 인공지능은 우리 꿈 같은 거예요.\n",
      "\n",
      "그러니까 우리가 하고 싶은 거 쉽게 말하면 이 인공지능이라는 요소가 딱 잘 정의되진 않는데 예를 들면 예전에 있던 그 바둑에 있는 바둑 AI나 그 스타크래프트에서 이제 컴퓨터 상대를 넣었어요.\n",
      "\n",
      "그런 것도 다 인공지능이라고 불러요.\n",
      "\n",
      "실제로는 그렇게 부를 수 있고요.\n",
      "\n",
      "그러니까 인공지능이라는 것 자체가 굉장히 어마어마한 개념이고 그렇진 않은 거예요.\n",
      "\n",
      "근데 이제 우리 일반인들 입장에서는 좀 터미네이터 같은 걸 생각하겠죠.\n",
      "\n",
      "인공지능으로.\n",
      "\n",
      "저 일하는 입장에서 인공지능은 어떤 물건이냐 하면요.\n",
      "\n",
      "스스로 배워요.\n",
      "\n",
      "그러니까 저는 이제 프로그래머를 짜서 뭐 컴파일을 하거나 아니면 뭐 스크립트를 실행하면 얘가 막 돌아가거든요.\n",
      "\n",
      "근데 시킨 대로 돌아가요.\n",
      "\n",
      "얘는.\n",
      "\n",
      "예를 들면 제가 정말 어렵게 엄청 힘든 건데 프로그램을 막 짜서 개랑 고양이 구분하는 프로그램을 짰다고 해볼게요.\n",
      "\n",
      "근데 이 프로그램은요.\n",
      "\n",
      "제가 그 다음에 코끼리를 어떻게 하려고 하면 다시 짜야 돼요.\n",
      "\n",
      "또.\n",
      "\n",
      "코끼리 구분하는 코드를 막 짜야 되죠.\n",
      "\n",
      "근데 이제 저는 사실 어떻게 하고 싶냐.\n",
      "\n",
      "프로그램 하나 만들어 놓고 코끼리 사진만 막 넣으면 코끼리도 구분했으면 좋겠는 거예요.\n",
      "\n",
      "프로그램이.\n",
      "\n",
      "제가 프로그램을 다시 짜는 것과 있는 프로그램 냅두고 사진만 모아서 긁어 넣는 것 중에 뭐가 쉽겠어요.\n",
      "\n",
      "사진만 넣는 게 훨씬 쉽죠.\n",
      "\n",
      "프로그램 짜라 그러면 끼약하겠지만 코끼리 사진을 1,000개 모아오라 하면 아마 즐겁게 모아올 거라고요.\n",
      "\n",
      "그냥.\n",
      "\n",
      "당연히 훨씬 쉽죠.\n",
      "\n",
      "그게.\n",
      "\n",
      "지금 말하는 인공지능에서 중요한 요소들은 그런 거예요.\n",
      "\n",
      "바둑 인공지능도 다 인공지능이고 한데 지금 우리가 중요하게 여기는 요소는 얘가 스스로 배워서 내놓는 결과를 바꾸는 물건이란 거예요.\n",
      "\n",
      "그쪽을 중요하게 봐온 게 그 인공지능인 거예요.\n",
      "\n",
      "그리고 반도체는 그거와 뭐가 관계가 있느냐.\n",
      "\n",
      "지금 제가 말씀드린 건 다 컨셉이죠.\n",
      "\n",
      "어떻게 만드는지에 대한 얘기가 없잖아요.\n",
      "\n",
      "그래서 그런 인공지능을 만드는 아이디어가 여러 개 있었어요.\n",
      "\n",
      "SVM 뭐 이런 방법도 있고 뭐 그냥 코드를 엄청 무식하게 짜보는 방법도 있고요.\n",
      "\n",
      "뭐 IBM 왓슨처럼 막 만드는 방법도 있는데 요거 다 다른 형태의 프로그램이잖아요.\n",
      "\n",
      "요 방법들 중에 제가 A라는 방법을 택하면 예를 들어 CPU가 빨라야 되고 메모리는 적어도 되고 B라는 방법을 쓰면 CPU보다 메모리가 중요하고 요런 식으로 바뀌어요.\n",
      "\n",
      "왜냐하면 프로그램도 그냥 CPU에서 도는 게 아니고요.\n",
      "\n",
      "CPU가 잘하는 일 중심으로 프로그램을 짜야 빠른 거잖아요.\n",
      "\n",
      "그게 반도체랑 인공지능 기술의 핵심인 거예요.\n",
      "\n",
      "우리는 인공지능이라는 추상적인 개념을 만들고 싶고요.\n",
      "\n",
      "그래서 그 추상적인 개념이 돌아가게 하기 위해서 여러 가지 아이디어를 쓰는 거예요.\n",
      "\n",
      "그중에 지금 제일 잘 되는 게 인공신경망이라는 개념이에요.\n",
      "\n",
      "인간의 뇌세포 구조를 좀 따라해서 그 신경망을 이제 우리 학습시킨 방법을 알아냈기 때문에 학습시키면은 우리가 원하던 인공지능 스스로 뭐 배우고 뭐 진짜 의미로 스스로 배우진 않죠 이제.\n",
      "\n",
      "우리가 코드를 다시 짜지 않아도 데이터만 넣어서 다시 학습시키면 원하는 결과 나오고 그런 걸 할 수 있는 게 이제 인공신경망이에요.\n",
      "\n",
      "근데 이 인공신경망은 특징이 CPU가 잘하는 일은 아니라는 거예요 얘가.\n",
      "\n",
      "그러니까 이제 기존에 CPU만 우리 90년대, 2000년대 CPU만 있었는데 지금 NVIDIA GPU를 쓰는 거예요.\n",
      "\n",
      "우리에겐 하고 싶은 일이 있고 그중에 그 일을 제일 잘하는 방법론을 찾아요.\n",
      "\n",
      "어떤 방식으로 프로그램을 만들어야 스스로 잘 배우는 프로그램이 된다.\n",
      "\n",
      "그리고 그 프로그램들은 각자 원하는 반도체가 달라요.\n",
      "\n",
      "그 일을 잘할 수 있는 반도체가 다르죠.\n",
      "\n",
      "그렇게 움직이는 거예요.\n",
      "\n",
      "CPU와 GPU의 큰 차이가? 사실 둘 다 메모리가 아니고 연산용 칩인데 CPU라는 거는 그 조건 파악을 잘해요.\n",
      "\n",
      "예를 들면 제 입장에서 머니인사이드의 시청자가 몇 명 이상이면 참여하고 아니면은 출연하지 마라.\n",
      "\n",
      "이런 식으로 그 조건이 있으면 선택을 하는 거잖아요.\n",
      "\n",
      "이런 식의 일을 되게 잘해요.\n",
      "\n",
      "그게 그 CPU가 잘하는 일이고요.\n",
      "\n",
      "그리고 GPU는 뭘 잘하냐 하면은 숫자 계산을 엄청 잘해요 그냥.\n",
      "\n",
      "0.1 곱하기 0.4 뭐 이런 숫자를 뭐 수만 개 계산하는 걸 엄청 잘해요.\n",
      "\n",
      "근데 우리가 과거에 봤던 수많은 프로그램들은요.\n",
      "\n",
      "앞에 말했던 조건이 중요해요.\n",
      "\n",
      "예를 들면 엑셀이잖아요.\n",
      "\n",
      "제가 엑셀 칸에다가 함수를 넣으면 만약 함수가 sum이면은 더해라.\n",
      "\n",
      "이런 거죠.\n",
      "\n",
      "이렇게 조건이잖아요 다.\n",
      "\n",
      "그래서 그런 걸 잘하게 설계되어 있어요 CPU는.\n",
      "\n",
      "근데 인공신경만 어떻게 돌아가냐 하면 그냥 입력값을 다 소수점으로 바꾼 다음에 소수점 곱셈을 엄청나게 해요.\n",
      "\n",
      "한국어 문장요약 결과:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'인공신경망은 CPU가 잘하는 일을 잘하지 않는 특징이 있으며, 인공지능 개발에는 데이터가 필요하다. 인공신경망은 CPU 대신 NVIDIA GPU를 사용하며, 인공지능 기술의 핵심인 인공신경망은 스스로 학습할 수 있는 능력을 가진다. CPU는 조건 파악을 잘하며, GPU는 대량의 숫자 계산을 잘한다. 프로그램의 조건이 중요한 경우 CPU가 유리하며, 인공신경망의 경우 GPU가 더 효율적이다.'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# refine\n",
    "# https://python.langchain.com/en/latest/reference/modules/text_splitter.html\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain import OpenAI, PromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.docstore.document import Document\n",
    "from pprint import pprint\n",
    "import tiktoken\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "\n",
    "\n",
    "with open('./정인성작가_transcript.txt', 'r', encoding='utf-8') as f:\n",
    "    transcript = f.read()\n",
    "\n",
    "transcript = transcript.replace('. ', '.\\n\\n')\n",
    "enc35 = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "# tokenized_text_chatgpt35 = enc35.encode(transcript)\n",
    "# print(len(tokenized_text_chatgpt35))\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=3000, chunk_overlap=200)\n",
    "texts = text_splitter.split_text(transcript) # 문장 분리 길이 4000 미만 및 chunk_overlap 200\n",
    "docs = [Document(page_content=t) for t in texts]\n",
    "pprint(docs)\n",
    "\n",
    "# 나뉜 문단별 토큰수 계산\n",
    "tmp_tok = 0\n",
    "for doc in docs:\n",
    "    tokenized_text_chatgpt35 = enc35.encode(doc.page_content)\n",
    "    # print(len(tokenized_text_chatgpt35))\n",
    "    tmp_tok += len(tokenized_text_chatgpt35)\n",
    "print('전체 토큰수', tmp_tok)\n",
    "\n",
    "# 템플릿 작성\n",
    "############################################################################################################\n",
    "bullet_point_prompt_template = \"\"\"다음 문장을 요약해주세요:\n",
    "\n",
    "{text}\n",
    "\n",
    "한국어 문장요약 결과:\n",
    "\"\"\"\n",
    "############################################################################################################\n",
    "bullet_point_prompt = PromptTemplate(template=bullet_point_prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "# 모든 데이터에 한번에 엑세스 하므로 전체 토큰이 \n",
    "llmc = ChatOpenAI(temperature=0.9, model_name=\"gpt-3.5-turbo\")\n",
    "chain = load_summarize_chain(llmc, \n",
    "                             chain_type=\"stuff\",  \n",
    "                             prompt=bullet_point_prompt,\n",
    "                             verbose=True)\n",
    "'''\n",
    "스터핑은 가장 간단한 방법으로, 모든 관련 데이터를 프롬프트에 컨텍스트로 채워 언어 모델에 전달하기만 하면 됩니다. 이것은 LangChain에서 StuffDocumentsChain으로 구현됩니다.\n",
    "\n",
    "장점: LLM을 한 번만 호출합니다. 텍스트를 생성할 때 LLM이 모든 데이터에 한 번에 액세스할 수 있습니다.\n",
    "\n",
    "단점: 대부분의 LLM에는 컨텍스트 길이가 있으며, 큰 문서(또는 많은 문서)의 경우 컨텍스트 길이보다 큰 프롬프트가 표시되므로 이 방법은 작동하지 않습니다.\n",
    "\n",
    "이 방법의 가장 큰 단점은 작은 데이터 조각에서만 작동한다는 것입니다. 많은 데이터 조각으로 작업하는 경우에는 이 접근 방식을 더 이상 사용할 수 없습니다. 다음 두 가지 접근 방식은 이러한 문제를 해결하기 위해 고안되었습니다.\n",
    "'''\n",
    " # 이렇게 stuff는 한번에 언어모델이 감당할 수 있는 토큰수를 넘어가면 안되고 한번에 안넘어가는 토큰수에 한해서 넣어줘야함\n",
    "chain.run(docs[:1])\n",
    "\n",
    "# 내가 생각하는 stuff의 장점은 \n",
    "# 한번에 짧은 문단 그치만 다른 주제에 대해서 여러 문단이 있는경우 \n",
    "# Stuff로 한번에 하나씩 요약을 미리 해두는 기능으로 사용하면 될듯\n",
    "# 그리고 그 요약된 문단을 다시 모아서 한번에 요약하는 방식으로 사용하면 좋을듯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" In this speech, the speaker addresses the American people and encourages them to stand with the Ukrainian people in their struggle against Russia's aggression. The speaker emphasizes the courage and determination of the Ukrainian people and the need for dictators to be held accountable for their actions. The speaker calls for the United States to send a signal of support to Ukraine and the world.\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 영어로 요약해보기\n",
    "with open(\"./state_of_the_union.txt\") as f:\n",
    "    state_of_the_union = f.read()\n",
    "stu_text = text_splitter.split_text(state_of_the_union) # list 형태로 split 한다\n",
    "\n",
    "stu_docs = [Document(page_content=t) for t in stu_text[:3]]\n",
    "stu_docs\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "chain = load_summarize_chain(llm, chain_type=\"stuff\")\n",
    "chain.run(stu_docs[:2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# The `map_reduce` Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /autogpt/lib/python3.9/site-packages/langchain/chains/summarize/map_reduce_prompt.py\n",
    "# map_reduce chain 이렇게 생김\n",
    "# flake8: noqa\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"Write a concise summary of the following:\n",
    "\n",
    "\n",
    "\"{text}\"\n",
    "\n",
    "\n",
    "CONCISE SUMMARY:\"\"\"\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='인공신경망은 특징이 CPU가 잘하는 일은 아니라는 거예요.\\n\\n숫자가 5를 넘으면 안녕하세요 말하는 코드를 쓴다.\\n\\n이거는 용량 진짜로 몇 킬로바이트 안 하거든요? 근데 제가 동일한 일을 하려는 걸 인공신경망으로 만들면 용량이 몇백배 커요.\\n\\nNVIDIA GPU도 완벽한 칩은 아니에요.\\n\\n예전 슈퍼컴퓨터에 그래픽카드 만 개를 엮었다고 했잖아요.\\n\\n근데 그렇게 엮으면 비효율도 크고 비용도 크거든요.\\n\\nGPT를 통한 인공지능 변호사 이런 거 만들려면 데이터 장벽부터 있는 거예요.\\n\\n예전에는 PC였고 스마트폰이었고 지금은 서버인데 제 사회의 어떤 수요를 만들려면요.\\n\\n안녕하세요.\\n\\n머니인사이드 시청자 여러분 정인성 작가입니다.\\n\\n저는 원래 반도체 회사에서 반도체 관련한 시뮬레이션 일을 하고 있었고요.\\n\\n최근에 인공지능 관련해서도 새로운 책을 쓸 수 있었고요.\\n\\n지금은 이제 동료들이랑 인공지능 개발 쪽으로 와 있습니다.\\n\\n스타릿에서 어떤...\\n\\n반도체들을 완제품을 만들고 나면 이 반도체들을 또 뭉쳐서 그 위에다가 조그마한 컨트롤러를 붙여서 막 동작을 하게 만들어요.\\n\\n쉽게 말하면 원본 반도체가 아니고 반도체들을 결합해서 새로운 가치를 만드는 거죠.\\n\\n이제 그런 것들을 시뮬레이션으로 검증하는 그런 일들을 했죠.\\n\\n인공지능은 용어를 구분할 필요가 있는데 인공지능은 우리 꿈 같은 거예요.\\n\\n그러니까 우리가 하고 싶은 거 쉽게 말하면 이 인공지능이라는 요소가 딱 잘 정의되진 않는데 예를 들면 예전에 있던 그 바둑에 있는 바둑 AI나 그 스타크래프트에서 이제 컴퓨터 상대를 넣었어요.\\n\\n그런 것도 다 인공지능이라고 불러요.\\n\\n실제로는 그렇게 부를 수 있고요.\\n\\n그러니까 인공지능이라는 것 자체가 굉장히 어마어마한 개념이고 그렇진 않은 거예요.\\n\\n근데 이제 우리 일반인들 입장에서는 좀 터미네이터 같은 걸 생각하겠죠.\\n\\n인공지능으로.\\n\\n저 일하는 입장에서 인공지능은 어떤 물건이냐 하면요.\\n\\n스스로 배워요.\\n\\n그러니까 저는 이제 프로그래머를 짜서 뭐 컴파일을 하거나 아니면 뭐 스크립트를 실행하면 얘가 막 돌아가거든요.\\n\\n근데 시킨 대로 돌아가요.\\n\\n얘는.\\n\\n예를 들면 제가 정말 어렵게 엄청 힘든 건데 프로그램을 막 짜서 개랑 고양이 구분하는 프로그램을 짰다고 해볼게요.\\n\\n근데 이 프로그램은요.\\n\\n제가 그 다음에 코끼리를 어떻게 하려고 하면 다시 짜야 돼요.\\n\\n또.\\n\\n코끼리 구분하는 코드를 막 짜야 되죠.\\n\\n근데 이제 저는 사실 어떻게 하고 싶냐.\\n\\n프로그램 하나 만들어 놓고 코끼리 사진만 막 넣으면 코끼리도 구분했으면 좋겠는 거예요.\\n\\n프로그램이.\\n\\n제가 프로그램을 다시 짜는 것과 있는 프로그램 냅두고 사진만 모아서 긁어 넣는 것 중에 뭐가 쉽겠어요.\\n\\n사진만 넣는 게 훨씬 쉽죠.\\n\\n프로그램 짜라 그러면 끼약하겠지만 코끼리 사진을 1,000개 모아오라 하면 아마 즐겁게 모아올 거라고요.\\n\\n그냥.\\n\\n당연히 훨씬 쉽죠.\\n\\n그게.\\n\\n지금 말하는 인공지능에서 중요한 요소들은 그런 거예요.\\n\\n바둑 인공지능도 다 인공지능이고 한데 지금 우리가 중요하게 여기는 요소는 얘가 스스로 배워서 내놓는 결과를 바꾸는 물건이란 거예요.\\n\\n그쪽을 중요하게 봐온 게 그 인공지능인 거예요.\\n\\n그리고 반도체는 그거와 뭐가 관계가 있느냐.\\n\\n지금 제가 말씀드린 건 다 컨셉이죠.\\n\\n어떻게 만드는지에 대한 얘기가 없잖아요.\\n\\n그래서 그런 인공지능을 만드는 아이디어가 여러 개 있었어요.\\n\\nSVM 뭐 이런 방법도 있고 뭐 그냥 코드를 엄청 무식하게 짜보는 방법도 있고요.\\n\\n뭐 IBM 왓슨처럼 막 만드는 방법도 있는데 요거 다 다른 형태의 프로그램이잖아요.\\n\\n요 방법들 중에 제가 A라는 방법을 택하면 예를 들어 CPU가 빨라야 되고 메모리는 적어도 되고 B라는 방법을 쓰면 CPU보다 메모리가 중요하고 요런 식으로 바뀌어요.\\n\\n왜냐하면 프로그램도 그냥 CPU에서 도는 게 아니고요.\\n\\nCPU가 잘하는 일 중심으로 프로그램을 짜야 빠른 거잖아요.\\n\\n그게 반도체랑 인공지능 기술의 핵심인 거예요.\\n\\n우리는 인공지능이라는 추상적인 개념을 만들고 싶고요.\\n\\n그래서 그 추상적인 개념이 돌아가게 하기 위해서 여러 가지 아이디어를 쓰는 거예요.\\n\\n그중에 지금 제일 잘 되는 게 인공신경망이라는 개념이에요.\\n\\n인간의 뇌세포 구조를 좀 따라해서 그 신경망을 이제 우리 학습시킨 방법을 알아냈기 때문에 학습시키면은 우리가 원하던 인공지능 스스로 뭐 배우고 뭐 진짜 의미로 스스로 배우진 않죠 이제.\\n\\n우리가 코드를 다시 짜지 않아도 데이터만 넣어서 다시 학습시키면 원하는 결과 나오고 그런 걸 할 수 있는 게 이제 인공신경망이에요.\\n\\n근데 이 인공신경망은 특징이 CPU가 잘하는 일은 아니라는 거예요 얘가.\\n\\n그러니까 이제 기존에 CPU만 우리 90년대, 2000년대 CPU만 있었는데 지금 NVIDIA GPU를 쓰는 거예요.\\n\\n우리에겐 하고 싶은 일이 있고 그중에 그 일을 제일 잘하는 방법론을 찾아요.\\n\\n어떤 방식으로 프로그램을 만들어야 스스로 잘 배우는 프로그램이 된다.\\n\\n그리고 그 프로그램들은 각자 원하는 반도체가 달라요.\\n\\n그 일을 잘할 수 있는 반도체가 다르죠.\\n\\n그렇게 움직이는 거예요.\\n\\nCPU와 GPU의 큰 차이가? 사실 둘 다 메모리가 아니고 연산용 칩인데 CPU라는 거는 그 조건 파악을 잘해요.\\n\\n예를 들면 제 입장에서 머니인사이드의 시청자가 몇 명 이상이면 참여하고 아니면은 출연하지 마라.\\n\\n이런 식으로 그 조건이 있으면 선택을 하는 거잖아요.\\n\\n이런 식의 일을 되게 잘해요.\\n\\n그게 그 CPU가 잘하는 일이고요.\\n\\n그리고 GPU는 뭘 잘하냐 하면은 숫자 계산을 엄청 잘해요 그냥.\\n\\n0.1 곱하기 0.4 뭐 이런 숫자를 뭐 수만 개 계산하는 걸 엄청 잘해요.\\n\\n근데 우리가 과거에 봤던 수많은 프로그램들은요.\\n\\n앞에 말했던 조건이 중요해요.\\n\\n예를 들면 엑셀이잖아요.\\n\\n제가 엑셀 칸에다가 함수를 넣으면 만약 함수가 sum이면은 더해라.\\n\\n이런 거죠.\\n\\n이렇게 조건이잖아요 다.\\n\\n그래서 그런 걸 잘하게 설계되어 있어요 CPU는.\\n\\n근데 인공신경만 어떻게 돌아가냐 하면 그냥 입력값을 다 소수점으로 바꾼 다음에 소수점 곱셈을 엄청나게 해요.', metadata={}),\n",
      " Document(page_content='앞에 말했던 조건이 중요해요.\\n\\n예를 들면 엑셀이잖아요.\\n\\n제가 엑셀 칸에다가 함수를 넣으면 만약 함수가 sum이면은 더해라.\\n\\n이런 거죠.\\n\\n이렇게 조건이잖아요 다.\\n\\n그래서 그런 걸 잘하게 설계되어 있어요 CPU는.\\n\\n근데 인공신경만 어떻게 돌아가냐 하면 그냥 입력값을 다 소수점으로 바꾼 다음에 소수점 곱셈을 엄청나게 해요.\\n\\n곱셈, 넛셈을 뭐 수억 번씩 하면 결과가 나오는데 그러면은 결과가 잘 나오는 그런 물건이에요.\\n\\n그러니까 어떻게 보면 인간이 조건을 하나씩 넣어주는 형태 프로그램에서 그냥 모두 다 숫자로 바꿔서 숫자로 와장창 곱하면은 이제 원하는 결과가 튀어나오는 좀 신기한 상황이 된 거죠.\\n\\nQ.\\n\\n인공지능 기술은 어떻게 변화할까요? 어떻게 보면 CPU가 좀 더 똑똑한 칩인데 우리가 지금 보는 인공지능 기술은 좀 무식한 방식으로 좀 더 나은 지성이 구현되어 있는 그런 모습이에요.\\n\\n숫자가 인공지능이 돌아가는 원리? 그러니까 인간 머리가 일단 그런 식으로 돌아가잖아요.\\n\\n왜냐하면 인간 유전자 안에 CPU 설계가 들어있겠어요? 그런 복잡한 설계가 있을까요? 인간 안에? 그 CPU 안에는 그 수십억 개 트랜지스터가 막 연결되어 있는 설계도가 있는데 인간은 그렇지 않잖아요.\\n\\n그래서 뇌세포들은 다 보면은 특정 뇌세포에 자극이 들어오면 인접한 뇌세포에다가 특정 그 역치값을 넘으면 자극을 전달하고 역치를 안 넘으면 자극을 안 전달하고 이렇게 돼 있어요.\\n\\n그 연결관계를 수조개 모아놓으면 지성이 되는 거잖아요.\\n\\n그리고 과거에는 문제가 뭐였냐면은 어 그러면 우리 인간 뇌 모습을 좀 따라해서 이렇게 막 연결하면 지성이 나올 거야.\\n\\n이론상.\\n\\n그 문제는 뭐냐? 이 연결이 예를 들면 A라는 뇌세포랑 B라는 뇌세포 사이 연결을 얼마나 강하게 전달해줘야 돼? 이런 걸 하나도 모르는 거예요.\\n\\n그러니까 우리가 앞에서 말한 프로그래밍이라는 개념은 아까 말한 것처럼 조건문을 쓰는 거였는데 이제는 그 세포와 세포 사이 연결 강도가 0.1이냐 0.3이냐 이런 거를 고민해야 되는 상황이 된 거예요.\\n\\n그 문제가 뭐겠어요? 수십억 개가 있는데 그중에 이거 세포 하나 딱 해서 얘네 둘 사이가 이게 영향을 뭘 주는 거야? 하면 그걸 알아내겠냐는 거예요.\\n\\n그걸 알 수가 없잖아요.\\n\\n그래서 오랫동안 힘들었던 거예요.\\n\\n인공지능, 인간 뇌세포를 따라해보자는 아이디어가 뭐 그렇게 참신한가요 이게? 60년대에 이미 나왔던 아이디어예요.\\n\\n근데 왜 사장 되고 이제야 떠올랐냐? 그때는 어 그래 이렇게 하면 될 것 같은데 정확하게는 뇌세포와 뇌세포의 연결관계를 어떻게 해줘야 얘가 잘 돌아가는지를 몰랐던 거야.\\n\\n그러니까 몇십 년을 쉰 거죠.\\n\\n이제 몇십 년 동안 그래서 아무도 못 해보고 있다가 캐나다 쪽에서 이제 그거 학습시키는 방법을 알아낸 거예요 그때.\\n\\n아 여기 데이터를 넣고 결과 값에서 어떤 식으로 계산을 해주면 인공신경망이 서서히 정답률이 올라가게 만들 수 있다.\\n\\n요거를 알아냈어요 그때.\\n\\n그 방법을 써보니까 GPU를 써야 빨라요.\\n\\n그렇게 해서 지금의 상황이 된 거예요 이건.\\n\\n쉽게 말하면 프로그램 쓰는 방법이 바뀌어버린 거예요.\\n\\n기존에는 프로그램 쓸 때 제가 순서도를 놓고 이 순서도를 잘못 자면 버그고 그랬는데요.\\n\\n지금은 인공신경망을 크게 구성을 해놓고 그 안에서 값이 정답을 낼 수 있는 형태로 그 수많은 소수점을 바꿔가야 되는 거예요.\\n\\n그래서 GPU가 필요한 거죠.\\n\\nQ.\\n\\n인공신경망을 어떻게 만들어야 할까요? 원래 옛날 게임들은 화면에 표시하는 거랑 게임의 움직임들 표시하는 걸 전부 CPU가 했어요.\\n\\n근데 이제 컴퓨터라는 게 PC라는 게 나오고 계속 유행하다 보니까 사람들이 점점 더 높은 그래픽을 원해요.\\n\\n점점 더 그래픽 좋은 게임도 하고 싶고 영화도 만들고 싶고 이런 거예요.\\n\\n근데 말씀드렸지만 CPU는 분기 처리를 잘해요.\\n\\n조건 처리를 잘하죠.\\n\\n근데 고급 그래픽을 계속 해보니까 이게 CPU에 잘 맞지 않았던 거예요.\\n\\n그래서 CPU에 잘 맞지 않으니까 VGA라고 부르는 그래픽 전용 칩을 만들어서 쉽게 말하면 이런 거예요.\\n\\n제가 여기 인테리어를 해야 되는데 인테리어 디자인도 하고 벽지도 붙이고 청소도 다 했는데 이제는 CPU가 GPU라고 부르는 협력사를 데려와서 저는 여기는 도배하고 여기는 청소하고 시켜놓으면 이걸 하고 가게 하는 거예요.\\n\\n그리고 저는 이제 앉아서 계속 다음번 도배해야 될 거 찾고 있고요.\\n\\nGPU라는 녀석이 와서 도배 같은 일을 해주는 거예요.\\n\\n이 GPU는 제가 하는 일은 잘 못하지만 제가 잘 못하는 걸 잘하는 거죠.\\n\\n결국은 CPU라는 칩이 모든 일을 잘하기에는 한계가 있었던 거예요.\\n\\n왜냐하면 CPU가 아까 말한 조건문 처리를 잘하려면 그쪽에다 소자를 써야 되는데 거기에 소자를 쓰면은 다른 쪽에 쓸 소자가 없잖아요, 제조할 때.\\n\\n그러니까 모든 걸 잘할 수 없으니까 생겨난 일이죠.\\n\\n다행스럽게도 엔비디아가 의도한 바는 아니겠죠, 아마.\\n\\n인공지능 기술을 해내기 위해서 여러 연구를 하는데 제일 잘 되는 기술이 그래픽이랑 비슷한 연산을 요구했던 거예요.\\n\\n제가 그래픽 돌아가는 거...\\n\\n예, 왜냐하면 그래픽도 결국 소수점 많이 곱하고 더하고 하는 거예요.\\n\\n살짝 얻어걸린 느낌도 있죠, 이거는.\\n\\n그래픽을 했는데 회사가 계속 커야 되니까 CPU는 못하고 GPU는 잘하는 일을 계속 찾아다녔어요, 이 회사가.\\n\\n어, 이게 잘 될 거야 라는 그런 느낌으로 바로 가서 2006년, 2007년에 막 질른 게 아니고 전 세계 사람들이 좀 GPU를 쓰기 편하게 이제 CUDA 이런 걸 만들어놨어요.\\n\\n그러니까 엔비디아 생각이 이런 거예요.\\n\\n아, 이게 그래픽에만 쓰진 않겠지.\\n\\n뭐 슈퍼컴퓨터나 시뮬레이션에도 쓸 수 있고 그래서 그 물리연산하는 회사를 인수하기도 하고 그랬어요.\\n\\n근데 이제 그런 걸 그냥 만들어놓고 칩 쓰세요 라고 하면은 쓰는 법을 몰라요, 사람들이.\\n\\n왜냐하면 제가 CPU용으로 프로그램 짜던 사람이 GPU용으로 프로그램 짜려고 하면 진입장벽이 꽤 높거든요.', metadata={}),\n",
      " Document(page_content='아, 이게 그래픽에만 쓰진 않겠지.\\n\\n뭐 슈퍼컴퓨터나 시뮬레이션에도 쓸 수 있고 그래서 그 물리연산하는 회사를 인수하기도 하고 그랬어요.\\n\\n근데 이제 그런 걸 그냥 만들어놓고 칩 쓰세요 라고 하면은 쓰는 법을 몰라요, 사람들이.\\n\\n왜냐하면 제가 CPU용으로 프로그램 짜던 사람이 GPU용으로 프로그램 짜려고 하면 진입장벽이 꽤 높거든요.\\n\\n그래서 엔비디아는 그걸 조금이나마 좀 편하게 해주려고 CUDA 이런 것들을 마련을 해놓은 거죠.\\n\\n근데 그걸 마련해놓은 상황이 이거 쉽게 말하면 캐나다에서 집어다 써본 거에 가까워요.\\n\\n어, 그랬더니 연산속도가 5배 빨라졌어요.\\n\\n뭐 이런 식으로 결과가 나오니까 이제 옆방 대학원생이 이걸로 한 달에 하나 쓰던 논문을 한 달에 5개씩 쓰고 있으면 그러면 나도 써야 되고 그럼 그 옆방 대학원생도 쓰고 할 거잖아요, 당연히.\\n\\n근데 이게 굉장히 반도체 비즈니스에서 사실은 중요한 요소예요.\\n\\n옆사람이 썼는데 안 되던 게 됐잖아요.\\n\\n그러면 그걸 본 옆사람이 쓰죠.\\n\\n그러면 이제 이걸 잘 쓴 사람이 논문 찍어내면서 유명해지죠.\\n\\n그러면 어느 순간 그게 거대한 프로그래머 집단으로 변해요.\\n\\n그러면 이제 지금 2023년 상황에서 제가 대학원 갓 졸업하고 논문 써야 되는데 인공지능으로 논문을 써야 되겠는데 그러면 컴퓨터를 마련하는데 뭘 마련할 거냐 이거예요.\\n\\n전 지금 하나도 안 해봤으니까 일단 남들 하는 걸 다 모방해야 된다니까요.\\n\\n남들 쓰는 컴퓨터 사고 그럼 당연히 엔비디아 GPU 들어가요.\\n\\n그리고 인공지능 한 번도 안 돌려봤으니까 인터넷에 돈을 오픈소스를 받아다가 인공지능을 돌려봐야 돼요.\\n\\n그 오픈소스는 뭘로 쓰여 있겠어요.\\n\\n이것도 엔비디아 GPU를 전제하고 써놨다고요 코드를.\\n\\n그러니까 AMD가 못하는 거예요.\\n\\n이거를 AMD 그래픽 카드로 이제 뭔가 해보려고 실제 실험은 하지도 못하는 거예요.\\n\\n제가 근데 엔비디아 거 쓰면 물어보면 되잖아요.\\n\\n야 넌 어떻게 했니? 이렇게.\\n\\n그게 그 반도체 비즈니스에서 되게 중요한 거예요.\\n\\n생태계예요 이게.\\n\\n어떻게 보면 메모리 같은 건 그런 생태계가 좀 약하고요.\\n\\n인텔의 CPU 같은 것도 그런 생태계를 가지고 있잖아요.\\n\\n그러니까 한참 동안 인텔 CPU가 지금도 그렇게 힘들어해도 살아있는 거예요.\\n\\n여기에 맞춰진 프로그램이 많으니까.\\n\\n반도체 시장은 이제 당분간은 거대 신경망 특히 자연화 신경망이 잘 된다고 했으니까 아마 그쪽 연구개발 수요는 올라갈 거예요.\\n\\n근데 연구개발 이상으로 이제 꾸준한 수요를 만들어내려면 많은 부분에서는 연구를 해봐야 된다고 생각해요.\\n\\n왜냐하면 지금 신경망 학습시키는 게 장점만 있는 건 아니에요.\\n\\n단점은 얘가 인간이랑 제일 큰 차이점이 데이터 한 두 개 보고 학습이 안 된다는 거예요.\\n\\n예를 들면 여기 버닝사이드 시청자 여러분은 영상을 만 개씩 봐야 특정 테마를 익힐 수 있는 것이 아니잖아요.\\n\\n하나만 봐도 익히죠.\\n\\n근데 인공지능은 문제와 정답상 하나 가지고 배울 수가 없고 엄청 많이 봐야 돼요.\\n\\nGPT를 통한 인공지능 변호사 이런 거 만들려면 일단 데이터 장벽부터 있는 거예요.\\n\\n질문과 정답상이 충분히 있냐.\\n\\n그런 것들이 지금은 다 조사가 안 돼 있고 이제야 사람들을 찾아보는 중일 거잖아요.\\n\\n그러니까 저는 당분간은 연구개발 수요는 크겠지만 이게 정말 세상을 바꿀 만큼 여기저기 적용될 건지 아니면 마이크로소프트만 자기들 검색엔진과 오피스에 쓸 건지 이거는 저는 좀 봐야 된다고 생각해요.\\n\\n우리나라의 발표체는 어떻게 쓰일 것인가요? 일단 제일 크게 쓰이는 건 역시 메모리죠.\\n\\n인공신경망의 특징 중 하나는요.\\n\\nCPU용으로 짠 프로그램보다 용량이 엄청나게 크다는 거예요.\\n\\n정말 코드를 잘 짜서 숫자가 5를 넘으면 뭐 안녕하세요 말하는 코드를 쓴다.\\n\\n이거는 용량 진짜로 몇 킬로바이트 안 하거든요.\\n\\n근데 제가 동일한 일을 하려는 걸 인공신경망으로 만들면 용량이 몇백배 커요, 실제로는.\\n\\n그래서 메모리 중에 고용량, 고대역폭 메모리가 중요한 거예요, 지금.\\n\\n일단 한국에서 제일 주요하게 팔리는 것들은 인공지능 쪽에 그 HBM 같은 고용량 고속 메모리들이죠.\\n\\n그쪽에서 확실히 수요가 있다고 봐야죠.\\n\\n그러니까 이런 느낌이에요.\\n\\n예를 들면 제가 CPU 프로그램에다가 1 더하기 1을 계산하게 시키면 프로그램 용량 해봤자 얼마나 하겠어요.\\n\\n근데 저한테 1 더하기 1 물어보고 MRI 찍으면 순식간에 뻘겋뻘겋해졌다가 없어진다고요.\\n\\n되게 비율적이잖아요, 그렇게 보면.\\n\\n용량이 크다니까요, 그렇게.\\n\\n여기 뇌세포 하나하나로 옮겨 놓는 거잖아요.\\n\\n1 더하기 1을 하기 위해서 뇌세포를 거쳐가는 신호의 개수가 뭐 3개겠냐 이거예요.\\n\\n1 더하기 1은 2.\\n\\n3개 들어가면 한 개 답이 나오는 게 아니고 수백억 개가 막 여기서 반응을 하잖아요.\\n\\n그거를 재현해야 되는 거잖아요, 컴퓨터의 내부에 맞춰서.\\n\\n고용량 메모리가 필요할 텐데 당장 물량을 딱 고민해보면 마이크로소프트 엣저이 슈퍼컴퓨터가 엔비디아 V100인가 하는 학습용 GPU를 만 개인가 엮었거든요.\\n\\n근데 이거 만 개 엮으면 이게 메모리 용량이 40만 기가바이트 그래요.\\n\\n엄청 큰 것 같지만 우리 평균 스마트폰에 8기가 들어가잖아요.\\n\\n8기가 들어가면 이거 2만 개 팔아도 스마트폰으로 한 5배? 40이랑 8이니까 5배죠? 그러면 스마트폰 판매량으로는 한 10만 개 정도 되겠네요.\\n\\n근데 스마트폰 1년에 10억 개 팔잖아요, 전 세계에.\\n\\n그러니까 이것만으로는 물량이 엄청 크지 않다는 얘기를 하는 거예요.\\n\\n엣저이 슈퍼컴퓨터 1년에 한 100개씩 팔아도 전체 메모리 물량에서 크진 않죠.\\n\\n물론 메모리 용량된 단가는 크게 쳐주겠지만.\\n\\n그래서 이게 GPT 같은 게 메모리 시장에 예전에는 PC였고, 스마트폰이었고, 지금은 서버인데 제사의 어떤 수요를 만들려면요.\\n\\n지금 연구개발 수요로 안 된다는 이야기를 하는 거예요.\\n\\n연구개발 수요 말고 꾸준히 사용되는 수요가 있어야 되는데 왜냐하면 연구개발하는 건 결국 한 번 사고 잘 안 되면 버릴 거잖아요.', metadata={}),\n",
      " Document(page_content='그래서 이게 GPT 같은 게 메모리 시장에 예전에는 PC였고, 스마트폰이었고, 지금은 서버인데 제사의 어떤 수요를 만들려면요.\\n\\n지금 연구개발 수요로 안 된다는 이야기를 하는 거예요.\\n\\n연구개발 수요 말고 꾸준히 사용되는 수요가 있어야 되는데 왜냐하면 연구개발하는 건 결국 한 번 사고 잘 안 되면 버릴 거잖아요.\\n\\n근데 꾸준히 써야 되면 연구개발용도 계속 사고 상업용으로도 계속 사야 되니까 수요가 꾸준히 늘어나죠.\\n\\n근데 그걸 알려면 사실 메모리 시장이나 엔비디아를 볼 게 아니고 우리가 GPT 같은 걸로 하고 싶은 사업모델 중에 데이터들의 쌍이 잘 갖춰져 있는 곳이 있나 그거를 알아야 답을 할 수 있다는 얘기인 거예요.\\n\\n전 그래서 지금은 그걸로 메모리 시장이 확 바뀔 거다 그렇게까지는 기대하지 않아요.\\n\\n지금 인공지능은요.\\n\\n우리가 좀 이렇게 착각들을 하는 게 인터넷에는 데이터가 무한하니까 그냥 데이터 넣으면 똑똑해지겠네 라고 생각하거나 그렇지가 않아요.\\n\\n예를 들어서 제가 개와 고양이를 구분시켜야 된다고 하면 사진만 넣는 게 아니라 사진에 개라고 써놔야 돼요.\\n\\n고양이 사진 고양이라고 써놔야 되고요.\\n\\n그렇게 질문과 정답 쌍이 있어야 배울 수 있는 거예요.\\n\\n사진은 그래도 좀 쉽죠.\\n\\n이거 뭐 사람 몇 명 쓰면 사진 100만 개 만들 수 있을 거예요.\\n\\n근데 말하는 인공지능은 어떨까요? 이거 질문과 대답 쌍을 만들기 쉬울까요? 우리 인터넷에 글을 그냥 긁으면 질문과 대답 쌍이 충분히 많이 나올까요? 그러니까 그 안에서는 질문과 대답 쌍 자체를 찾는 것도 되게 어렵고요.\\n\\n그리고 그중에 신뢰할 수 있는 말이 있느냐 이것도 되게 중요해요.\\n\\n지금 GPT 같은 게 학습이 잘 될 수밖에 없는 게 요약 같은 거 되게 잘하거든요.\\n\\n해보면 왜 요약이 잘 되냐 하면요.\\n\\n요약은 이미 그 인터넷에 쌍이 많이 있거든요.\\n\\n제가 일일이 GPT에 만들어줄 몇 테라바이트 데이터를 일일이 질문 답변 쓰는 건 수학적으로 말이 안 돼요.\\n\\n왜냐하면 사람이 열심히 쳐봤자 제가 한 만 단어 치는 것도 힘든데 일주일 동안 근데 얘는 수백억 단어가 필요한데 그거 사람 뽑아서 한다고 되겠어요? 그게? 안 되죠.\\n\\n대부분 있는 데이터 중에 좋은 데이터를 정제해서 쓰는 게 중요해요.\\n\\n근데 예를 들면 요약 같은 거는 위키페디아 이런 거 있잖아요.\\n\\n인트로덕션 안에 사실상 요약이에요.\\n\\n그리고 밑에가 본문이잖아요.\\n\\n본문을 주고 이거 요약해줘 한 다음에 정답을 인트로덕션 같은 걸 넣어서 할 수가 있거든요.\\n\\n그런 일들은 잘 되는 거예요.\\n\\n근데 이제 예를 들면 우리가 GPT가 세상을 바꾸려면 그런 식으로 쓸 수 있는 데이터가 있는 곳이어야 적용 가능한 거예요.\\n\\n예를 들면 제가 법조계 쪽으로 GPT를 쓰고 싶고 GPT를 학습시키고 싶잖아요.\\n\\n그러면 그것도 판례랑 답이 있어야 되는데 그것도 이제 얼마나 좋은 판례인지 이런 걸 다 매겨줘야 된다는 거예요.\\n\\n그 양도 많아야 되는 거죠.\\n\\n그리고 그러고 나면 사업성 문제가 생겨요.\\n\\n그렇게 한국에서 이거 학습을 시켰는데 미국에 쓸 수 있어요, 그거? 못 쓰죠.\\n\\n미국법이 아니니까 그건.\\n\\n이거는 상장된 회사는 아닌데 세레브라스 이런 회사들이 있어요.\\n\\n정확하게는 NVIDIA GPU도 완벽한 칩은 아니에요.\\n\\n인공지능 쪽에서는 범용적이고 쓰기 편한 칩이긴 한데 얘도 한계가 있어요.\\n\\n예를 들면 지금 도는 채집 PT 같은 거 말했지만 애저 슈퍼컴퓨터의 그래픽카드 만 개를 엮었다고 했잖아요.\\n\\n근데 그렇게 엮으면 비효율도 크고 비용도 크거든요.\\n\\n그래서 이제 세레브라스 같은 회사는 그만한 GPU를 하나씩 엮을 바에 이따만한 칩을 웨이퍼 하나에 놓고 그 안에 신경망을 한 번에 다 올리자 이런 식으로 얘기를 해요.\\n\\n이거는 단일 GPU 안에 다 안 들어가서 이거를 쪼개서 담기 위한 노력도 많이 하고 그 비효율이 많거든요.\\n\\n근데 이제 그런 거대한 칩에는 신경망이 한 번에 딱 들어가죠.\\n\\n그러면 기존에 이론상으로는 할 수 있지만 GPU의 용량 한 개로 해보기 힘들었던 걸 많이 해볼 수 있어요.\\n\\n그런 칩들을 쓰면.\\n\\n저는 이제 그런 무류의 칩들을 보는 건 나쁘지 않다고 생각해요.\\n\\n정확하게 이제 조건은 두 개 있어요.\\n\\n이런 칩들이 잘 되려면 첫째로 지금 채집 PT와 비슷한데 거대한 언어모델이죠, 이게.\\n\\n내가 하려고 하는 사업 분야에 데이터가 아까 말한 형태의 데이터가 있고요.\\n\\n그런 데이터들이 풍족하고 근데 NVIDIA GPU 쓰면 원가가 좀 안 나오는 애들.\\n\\n이런 애들일 때 가능성이 있는 거예요.\\n\\n예를 들면 제가 비즈니스를 하고 싶은데 이 채집 PT 같은 거 지금 공개된 거는 한 3,000단어 정도만 입력으로 들어갈 수 있어요.\\n\\n제가 채집 PT랑 대화를 주고받는다 그러면 대화 총합이 3,000단어 넘어가면 까먹어요, 얘는.\\n\\n원래 그런 디자인인 거예요.\\n\\n근데 그거를 늘리려면 늘릴 때 데이터도 많이 필요하고요.\\n\\n늘린 다음에 사양도 훨씬 많이 먹어요.\\n\\n이제 기술 발전이 좀 있긴 하겠지만 지금 상황에서는 그 3,000단어를 6,000단어로 늘리면 4배 정도 커져요, 얘가 대충.\\n\\n연산해야 되니까 4배씩 커지게 되니까 제가 이제 사업 모델을 봤더니 아, 3,000단어는 부족하고 뭐 8만 단어까지 하고 싶다.\\n\\n이러면 NVIDIA GPU 지금 1만 개 엮어서 했는데 몇 개 엮어서 할 거예요, 그때? 100만 개 엮어서 할 건가요? 그렇게 할 수 없잖아요.\\n\\n그러면 새로운 반도체 찾는 거죠.\\n\\n그 아파트들의 검폐율을 보면 보통 17%씩 높입니다.\\n\\n땅을 20평만 지어야 돼요.\\n\\n100평 되려면 10층이 돼야 200평 나오잖아요, 그렇죠? 이 시스템만 아시면 아시면 부동산은 제가 장담하고 있는데 반은 이미 안 갑니다.\\n\\n나머지는 디테일입니다.\\n\\n이걸 정확히 모르고 저 땅이 예쁘다, 이런 거 얘기할 필요 없습니다.', metadata={})]\n",
      "전체 토큰수 11098\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new MapReduceDocumentsChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m다음 문장을 요약해주세요:\n",
      "\n",
      "인공신경망은 특징이 CPU가 잘하는 일은 아니라는 거예요.\n",
      "\n",
      "숫자가 5를 넘으면 안녕하세요 말하는 코드를 쓴다.\n",
      "\n",
      "이거는 용량 진짜로 몇 킬로바이트 안 하거든요? 근데 제가 동일한 일을 하려는 걸 인공신경망으로 만들면 용량이 몇백배 커요.\n",
      "\n",
      "NVIDIA GPU도 완벽한 칩은 아니에요.\n",
      "\n",
      "예전 슈퍼컴퓨터에 그래픽카드 만 개를 엮었다고 했잖아요.\n",
      "\n",
      "근데 그렇게 엮으면 비효율도 크고 비용도 크거든요.\n",
      "\n",
      "GPT를 통한 인공지능 변호사 이런 거 만들려면 데이터 장벽부터 있는 거예요.\n",
      "\n",
      "예전에는 PC였고 스마트폰이었고 지금은 서버인데 제 사회의 어떤 수요를 만들려면요.\n",
      "\n",
      "안녕하세요.\n",
      "\n",
      "머니인사이드 시청자 여러분 정인성 작가입니다.\n",
      "\n",
      "저는 원래 반도체 회사에서 반도체 관련한 시뮬레이션 일을 하고 있었고요.\n",
      "\n",
      "최근에 인공지능 관련해서도 새로운 책을 쓸 수 있었고요.\n",
      "\n",
      "지금은 이제 동료들이랑 인공지능 개발 쪽으로 와 있습니다.\n",
      "\n",
      "스타릿에서 어떤...\n",
      "\n",
      "반도체들을 완제품을 만들고 나면 이 반도체들을 또 뭉쳐서 그 위에다가 조그마한 컨트롤러를 붙여서 막 동작을 하게 만들어요.\n",
      "\n",
      "쉽게 말하면 원본 반도체가 아니고 반도체들을 결합해서 새로운 가치를 만드는 거죠.\n",
      "\n",
      "이제 그런 것들을 시뮬레이션으로 검증하는 그런 일들을 했죠.\n",
      "\n",
      "인공지능은 용어를 구분할 필요가 있는데 인공지능은 우리 꿈 같은 거예요.\n",
      "\n",
      "그러니까 우리가 하고 싶은 거 쉽게 말하면 이 인공지능이라는 요소가 딱 잘 정의되진 않는데 예를 들면 예전에 있던 그 바둑에 있는 바둑 AI나 그 스타크래프트에서 이제 컴퓨터 상대를 넣었어요.\n",
      "\n",
      "그런 것도 다 인공지능이라고 불러요.\n",
      "\n",
      "실제로는 그렇게 부를 수 있고요.\n",
      "\n",
      "그러니까 인공지능이라는 것 자체가 굉장히 어마어마한 개념이고 그렇진 않은 거예요.\n",
      "\n",
      "근데 이제 우리 일반인들 입장에서는 좀 터미네이터 같은 걸 생각하겠죠.\n",
      "\n",
      "인공지능으로.\n",
      "\n",
      "저 일하는 입장에서 인공지능은 어떤 물건이냐 하면요.\n",
      "\n",
      "스스로 배워요.\n",
      "\n",
      "그러니까 저는 이제 프로그래머를 짜서 뭐 컴파일을 하거나 아니면 뭐 스크립트를 실행하면 얘가 막 돌아가거든요.\n",
      "\n",
      "근데 시킨 대로 돌아가요.\n",
      "\n",
      "얘는.\n",
      "\n",
      "예를 들면 제가 정말 어렵게 엄청 힘든 건데 프로그램을 막 짜서 개랑 고양이 구분하는 프로그램을 짰다고 해볼게요.\n",
      "\n",
      "근데 이 프로그램은요.\n",
      "\n",
      "제가 그 다음에 코끼리를 어떻게 하려고 하면 다시 짜야 돼요.\n",
      "\n",
      "또.\n",
      "\n",
      "코끼리 구분하는 코드를 막 짜야 되죠.\n",
      "\n",
      "근데 이제 저는 사실 어떻게 하고 싶냐.\n",
      "\n",
      "프로그램 하나 만들어 놓고 코끼리 사진만 막 넣으면 코끼리도 구분했으면 좋겠는 거예요.\n",
      "\n",
      "프로그램이.\n",
      "\n",
      "제가 프로그램을 다시 짜는 것과 있는 프로그램 냅두고 사진만 모아서 긁어 넣는 것 중에 뭐가 쉽겠어요.\n",
      "\n",
      "사진만 넣는 게 훨씬 쉽죠.\n",
      "\n",
      "프로그램 짜라 그러면 끼약하겠지만 코끼리 사진을 1,000개 모아오라 하면 아마 즐겁게 모아올 거라고요.\n",
      "\n",
      "그냥.\n",
      "\n",
      "당연히 훨씬 쉽죠.\n",
      "\n",
      "그게.\n",
      "\n",
      "지금 말하는 인공지능에서 중요한 요소들은 그런 거예요.\n",
      "\n",
      "바둑 인공지능도 다 인공지능이고 한데 지금 우리가 중요하게 여기는 요소는 얘가 스스로 배워서 내놓는 결과를 바꾸는 물건이란 거예요.\n",
      "\n",
      "그쪽을 중요하게 봐온 게 그 인공지능인 거예요.\n",
      "\n",
      "그리고 반도체는 그거와 뭐가 관계가 있느냐.\n",
      "\n",
      "지금 제가 말씀드린 건 다 컨셉이죠.\n",
      "\n",
      "어떻게 만드는지에 대한 얘기가 없잖아요.\n",
      "\n",
      "그래서 그런 인공지능을 만드는 아이디어가 여러 개 있었어요.\n",
      "\n",
      "SVM 뭐 이런 방법도 있고 뭐 그냥 코드를 엄청 무식하게 짜보는 방법도 있고요.\n",
      "\n",
      "뭐 IBM 왓슨처럼 막 만드는 방법도 있는데 요거 다 다른 형태의 프로그램이잖아요.\n",
      "\n",
      "요 방법들 중에 제가 A라는 방법을 택하면 예를 들어 CPU가 빨라야 되고 메모리는 적어도 되고 B라는 방법을 쓰면 CPU보다 메모리가 중요하고 요런 식으로 바뀌어요.\n",
      "\n",
      "왜냐하면 프로그램도 그냥 CPU에서 도는 게 아니고요.\n",
      "\n",
      "CPU가 잘하는 일 중심으로 프로그램을 짜야 빠른 거잖아요.\n",
      "\n",
      "그게 반도체랑 인공지능 기술의 핵심인 거예요.\n",
      "\n",
      "우리는 인공지능이라는 추상적인 개념을 만들고 싶고요.\n",
      "\n",
      "그래서 그 추상적인 개념이 돌아가게 하기 위해서 여러 가지 아이디어를 쓰는 거예요.\n",
      "\n",
      "그중에 지금 제일 잘 되는 게 인공신경망이라는 개념이에요.\n",
      "\n",
      "인간의 뇌세포 구조를 좀 따라해서 그 신경망을 이제 우리 학습시킨 방법을 알아냈기 때문에 학습시키면은 우리가 원하던 인공지능 스스로 뭐 배우고 뭐 진짜 의미로 스스로 배우진 않죠 이제.\n",
      "\n",
      "우리가 코드를 다시 짜지 않아도 데이터만 넣어서 다시 학습시키면 원하는 결과 나오고 그런 걸 할 수 있는 게 이제 인공신경망이에요.\n",
      "\n",
      "근데 이 인공신경망은 특징이 CPU가 잘하는 일은 아니라는 거예요 얘가.\n",
      "\n",
      "그러니까 이제 기존에 CPU만 우리 90년대, 2000년대 CPU만 있었는데 지금 NVIDIA GPU를 쓰는 거예요.\n",
      "\n",
      "우리에겐 하고 싶은 일이 있고 그중에 그 일을 제일 잘하는 방법론을 찾아요.\n",
      "\n",
      "어떤 방식으로 프로그램을 만들어야 스스로 잘 배우는 프로그램이 된다.\n",
      "\n",
      "그리고 그 프로그램들은 각자 원하는 반도체가 달라요.\n",
      "\n",
      "그 일을 잘할 수 있는 반도체가 다르죠.\n",
      "\n",
      "그렇게 움직이는 거예요.\n",
      "\n",
      "CPU와 GPU의 큰 차이가? 사실 둘 다 메모리가 아니고 연산용 칩인데 CPU라는 거는 그 조건 파악을 잘해요.\n",
      "\n",
      "예를 들면 제 입장에서 머니인사이드의 시청자가 몇 명 이상이면 참여하고 아니면은 출연하지 마라.\n",
      "\n",
      "이런 식으로 그 조건이 있으면 선택을 하는 거잖아요.\n",
      "\n",
      "이런 식의 일을 되게 잘해요.\n",
      "\n",
      "그게 그 CPU가 잘하는 일이고요.\n",
      "\n",
      "그리고 GPU는 뭘 잘하냐 하면은 숫자 계산을 엄청 잘해요 그냥.\n",
      "\n",
      "0.1 곱하기 0.4 뭐 이런 숫자를 뭐 수만 개 계산하는 걸 엄청 잘해요.\n",
      "\n",
      "근데 우리가 과거에 봤던 수많은 프로그램들은요.\n",
      "\n",
      "앞에 말했던 조건이 중요해요.\n",
      "\n",
      "예를 들면 엑셀이잖아요.\n",
      "\n",
      "제가 엑셀 칸에다가 함수를 넣으면 만약 함수가 sum이면은 더해라.\n",
      "\n",
      "이런 거죠.\n",
      "\n",
      "이렇게 조건이잖아요 다.\n",
      "\n",
      "그래서 그런 걸 잘하게 설계되어 있어요 CPU는.\n",
      "\n",
      "근데 인공신경만 어떻게 돌아가냐 하면 그냥 입력값을 다 소수점으로 바꾼 다음에 소수점 곱셈을 엄청나게 해요.\n",
      "\n",
      "한국어 문장요약 결과:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m다음 문장을 요약해주세요:\n",
      "\n",
      "앞에 말했던 조건이 중요해요.\n",
      "\n",
      "예를 들면 엑셀이잖아요.\n",
      "\n",
      "제가 엑셀 칸에다가 함수를 넣으면 만약 함수가 sum이면은 더해라.\n",
      "\n",
      "이런 거죠.\n",
      "\n",
      "이렇게 조건이잖아요 다.\n",
      "\n",
      "그래서 그런 걸 잘하게 설계되어 있어요 CPU는.\n",
      "\n",
      "근데 인공신경만 어떻게 돌아가냐 하면 그냥 입력값을 다 소수점으로 바꾼 다음에 소수점 곱셈을 엄청나게 해요.\n",
      "\n",
      "곱셈, 넛셈을 뭐 수억 번씩 하면 결과가 나오는데 그러면은 결과가 잘 나오는 그런 물건이에요.\n",
      "\n",
      "그러니까 어떻게 보면 인간이 조건을 하나씩 넣어주는 형태 프로그램에서 그냥 모두 다 숫자로 바꿔서 숫자로 와장창 곱하면은 이제 원하는 결과가 튀어나오는 좀 신기한 상황이 된 거죠.\n",
      "\n",
      "Q.\n",
      "\n",
      "인공지능 기술은 어떻게 변화할까요? 어떻게 보면 CPU가 좀 더 똑똑한 칩인데 우리가 지금 보는 인공지능 기술은 좀 무식한 방식으로 좀 더 나은 지성이 구현되어 있는 그런 모습이에요.\n",
      "\n",
      "숫자가 인공지능이 돌아가는 원리? 그러니까 인간 머리가 일단 그런 식으로 돌아가잖아요.\n",
      "\n",
      "왜냐하면 인간 유전자 안에 CPU 설계가 들어있겠어요? 그런 복잡한 설계가 있을까요? 인간 안에? 그 CPU 안에는 그 수십억 개 트랜지스터가 막 연결되어 있는 설계도가 있는데 인간은 그렇지 않잖아요.\n",
      "\n",
      "그래서 뇌세포들은 다 보면은 특정 뇌세포에 자극이 들어오면 인접한 뇌세포에다가 특정 그 역치값을 넘으면 자극을 전달하고 역치를 안 넘으면 자극을 안 전달하고 이렇게 돼 있어요.\n",
      "\n",
      "그 연결관계를 수조개 모아놓으면 지성이 되는 거잖아요.\n",
      "\n",
      "그리고 과거에는 문제가 뭐였냐면은 어 그러면 우리 인간 뇌 모습을 좀 따라해서 이렇게 막 연결하면 지성이 나올 거야.\n",
      "\n",
      "이론상.\n",
      "\n",
      "그 문제는 뭐냐? 이 연결이 예를 들면 A라는 뇌세포랑 B라는 뇌세포 사이 연결을 얼마나 강하게 전달해줘야 돼? 이런 걸 하나도 모르는 거예요.\n",
      "\n",
      "그러니까 우리가 앞에서 말한 프로그래밍이라는 개념은 아까 말한 것처럼 조건문을 쓰는 거였는데 이제는 그 세포와 세포 사이 연결 강도가 0.1이냐 0.3이냐 이런 거를 고민해야 되는 상황이 된 거예요.\n",
      "\n",
      "그 문제가 뭐겠어요? 수십억 개가 있는데 그중에 이거 세포 하나 딱 해서 얘네 둘 사이가 이게 영향을 뭘 주는 거야? 하면 그걸 알아내겠냐는 거예요.\n",
      "\n",
      "그걸 알 수가 없잖아요.\n",
      "\n",
      "그래서 오랫동안 힘들었던 거예요.\n",
      "\n",
      "인공지능, 인간 뇌세포를 따라해보자는 아이디어가 뭐 그렇게 참신한가요 이게? 60년대에 이미 나왔던 아이디어예요.\n",
      "\n",
      "근데 왜 사장 되고 이제야 떠올랐냐? 그때는 어 그래 이렇게 하면 될 것 같은데 정확하게는 뇌세포와 뇌세포의 연결관계를 어떻게 해줘야 얘가 잘 돌아가는지를 몰랐던 거야.\n",
      "\n",
      "그러니까 몇십 년을 쉰 거죠.\n",
      "\n",
      "이제 몇십 년 동안 그래서 아무도 못 해보고 있다가 캐나다 쪽에서 이제 그거 학습시키는 방법을 알아낸 거예요 그때.\n",
      "\n",
      "아 여기 데이터를 넣고 결과 값에서 어떤 식으로 계산을 해주면 인공신경망이 서서히 정답률이 올라가게 만들 수 있다.\n",
      "\n",
      "요거를 알아냈어요 그때.\n",
      "\n",
      "그 방법을 써보니까 GPU를 써야 빨라요.\n",
      "\n",
      "그렇게 해서 지금의 상황이 된 거예요 이건.\n",
      "\n",
      "쉽게 말하면 프로그램 쓰는 방법이 바뀌어버린 거예요.\n",
      "\n",
      "기존에는 프로그램 쓸 때 제가 순서도를 놓고 이 순서도를 잘못 자면 버그고 그랬는데요.\n",
      "\n",
      "지금은 인공신경망을 크게 구성을 해놓고 그 안에서 값이 정답을 낼 수 있는 형태로 그 수많은 소수점을 바꿔가야 되는 거예요.\n",
      "\n",
      "그래서 GPU가 필요한 거죠.\n",
      "\n",
      "Q.\n",
      "\n",
      "인공신경망을 어떻게 만들어야 할까요? 원래 옛날 게임들은 화면에 표시하는 거랑 게임의 움직임들 표시하는 걸 전부 CPU가 했어요.\n",
      "\n",
      "근데 이제 컴퓨터라는 게 PC라는 게 나오고 계속 유행하다 보니까 사람들이 점점 더 높은 그래픽을 원해요.\n",
      "\n",
      "점점 더 그래픽 좋은 게임도 하고 싶고 영화도 만들고 싶고 이런 거예요.\n",
      "\n",
      "근데 말씀드렸지만 CPU는 분기 처리를 잘해요.\n",
      "\n",
      "조건 처리를 잘하죠.\n",
      "\n",
      "근데 고급 그래픽을 계속 해보니까 이게 CPU에 잘 맞지 않았던 거예요.\n",
      "\n",
      "그래서 CPU에 잘 맞지 않으니까 VGA라고 부르는 그래픽 전용 칩을 만들어서 쉽게 말하면 이런 거예요.\n",
      "\n",
      "제가 여기 인테리어를 해야 되는데 인테리어 디자인도 하고 벽지도 붙이고 청소도 다 했는데 이제는 CPU가 GPU라고 부르는 협력사를 데려와서 저는 여기는 도배하고 여기는 청소하고 시켜놓으면 이걸 하고 가게 하는 거예요.\n",
      "\n",
      "그리고 저는 이제 앉아서 계속 다음번 도배해야 될 거 찾고 있고요.\n",
      "\n",
      "GPU라는 녀석이 와서 도배 같은 일을 해주는 거예요.\n",
      "\n",
      "이 GPU는 제가 하는 일은 잘 못하지만 제가 잘 못하는 걸 잘하는 거죠.\n",
      "\n",
      "결국은 CPU라는 칩이 모든 일을 잘하기에는 한계가 있었던 거예요.\n",
      "\n",
      "왜냐하면 CPU가 아까 말한 조건문 처리를 잘하려면 그쪽에다 소자를 써야 되는데 거기에 소자를 쓰면은 다른 쪽에 쓸 소자가 없잖아요, 제조할 때.\n",
      "\n",
      "그러니까 모든 걸 잘할 수 없으니까 생겨난 일이죠.\n",
      "\n",
      "다행스럽게도 엔비디아가 의도한 바는 아니겠죠, 아마.\n",
      "\n",
      "인공지능 기술을 해내기 위해서 여러 연구를 하는데 제일 잘 되는 기술이 그래픽이랑 비슷한 연산을 요구했던 거예요.\n",
      "\n",
      "제가 그래픽 돌아가는 거...\n",
      "\n",
      "예, 왜냐하면 그래픽도 결국 소수점 많이 곱하고 더하고 하는 거예요.\n",
      "\n",
      "살짝 얻어걸린 느낌도 있죠, 이거는.\n",
      "\n",
      "그래픽을 했는데 회사가 계속 커야 되니까 CPU는 못하고 GPU는 잘하는 일을 계속 찾아다녔어요, 이 회사가.\n",
      "\n",
      "어, 이게 잘 될 거야 라는 그런 느낌으로 바로 가서 2006년, 2007년에 막 질른 게 아니고 전 세계 사람들이 좀 GPU를 쓰기 편하게 이제 CUDA 이런 걸 만들어놨어요.\n",
      "\n",
      "그러니까 엔비디아 생각이 이런 거예요.\n",
      "\n",
      "아, 이게 그래픽에만 쓰진 않겠지.\n",
      "\n",
      "뭐 슈퍼컴퓨터나 시뮬레이션에도 쓸 수 있고 그래서 그 물리연산하는 회사를 인수하기도 하고 그랬어요.\n",
      "\n",
      "근데 이제 그런 걸 그냥 만들어놓고 칩 쓰세요 라고 하면은 쓰는 법을 몰라요, 사람들이.\n",
      "\n",
      "왜냐하면 제가 CPU용으로 프로그램 짜던 사람이 GPU용으로 프로그램 짜려고 하면 진입장벽이 꽤 높거든요.\n",
      "\n",
      "한국어 문장요약 결과:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m다음 문장을 요약해주세요:\n",
      "\n",
      "아, 이게 그래픽에만 쓰진 않겠지.\n",
      "\n",
      "뭐 슈퍼컴퓨터나 시뮬레이션에도 쓸 수 있고 그래서 그 물리연산하는 회사를 인수하기도 하고 그랬어요.\n",
      "\n",
      "근데 이제 그런 걸 그냥 만들어놓고 칩 쓰세요 라고 하면은 쓰는 법을 몰라요, 사람들이.\n",
      "\n",
      "왜냐하면 제가 CPU용으로 프로그램 짜던 사람이 GPU용으로 프로그램 짜려고 하면 진입장벽이 꽤 높거든요.\n",
      "\n",
      "그래서 엔비디아는 그걸 조금이나마 좀 편하게 해주려고 CUDA 이런 것들을 마련을 해놓은 거죠.\n",
      "\n",
      "근데 그걸 마련해놓은 상황이 이거 쉽게 말하면 캐나다에서 집어다 써본 거에 가까워요.\n",
      "\n",
      "어, 그랬더니 연산속도가 5배 빨라졌어요.\n",
      "\n",
      "뭐 이런 식으로 결과가 나오니까 이제 옆방 대학원생이 이걸로 한 달에 하나 쓰던 논문을 한 달에 5개씩 쓰고 있으면 그러면 나도 써야 되고 그럼 그 옆방 대학원생도 쓰고 할 거잖아요, 당연히.\n",
      "\n",
      "근데 이게 굉장히 반도체 비즈니스에서 사실은 중요한 요소예요.\n",
      "\n",
      "옆사람이 썼는데 안 되던 게 됐잖아요.\n",
      "\n",
      "그러면 그걸 본 옆사람이 쓰죠.\n",
      "\n",
      "그러면 이제 이걸 잘 쓴 사람이 논문 찍어내면서 유명해지죠.\n",
      "\n",
      "그러면 어느 순간 그게 거대한 프로그래머 집단으로 변해요.\n",
      "\n",
      "그러면 이제 지금 2023년 상황에서 제가 대학원 갓 졸업하고 논문 써야 되는데 인공지능으로 논문을 써야 되겠는데 그러면 컴퓨터를 마련하는데 뭘 마련할 거냐 이거예요.\n",
      "\n",
      "전 지금 하나도 안 해봤으니까 일단 남들 하는 걸 다 모방해야 된다니까요.\n",
      "\n",
      "남들 쓰는 컴퓨터 사고 그럼 당연히 엔비디아 GPU 들어가요.\n",
      "\n",
      "그리고 인공지능 한 번도 안 돌려봤으니까 인터넷에 돈을 오픈소스를 받아다가 인공지능을 돌려봐야 돼요.\n",
      "\n",
      "그 오픈소스는 뭘로 쓰여 있겠어요.\n",
      "\n",
      "이것도 엔비디아 GPU를 전제하고 써놨다고요 코드를.\n",
      "\n",
      "그러니까 AMD가 못하는 거예요.\n",
      "\n",
      "이거를 AMD 그래픽 카드로 이제 뭔가 해보려고 실제 실험은 하지도 못하는 거예요.\n",
      "\n",
      "제가 근데 엔비디아 거 쓰면 물어보면 되잖아요.\n",
      "\n",
      "야 넌 어떻게 했니? 이렇게.\n",
      "\n",
      "그게 그 반도체 비즈니스에서 되게 중요한 거예요.\n",
      "\n",
      "생태계예요 이게.\n",
      "\n",
      "어떻게 보면 메모리 같은 건 그런 생태계가 좀 약하고요.\n",
      "\n",
      "인텔의 CPU 같은 것도 그런 생태계를 가지고 있잖아요.\n",
      "\n",
      "그러니까 한참 동안 인텔 CPU가 지금도 그렇게 힘들어해도 살아있는 거예요.\n",
      "\n",
      "여기에 맞춰진 프로그램이 많으니까.\n",
      "\n",
      "반도체 시장은 이제 당분간은 거대 신경망 특히 자연화 신경망이 잘 된다고 했으니까 아마 그쪽 연구개발 수요는 올라갈 거예요.\n",
      "\n",
      "근데 연구개발 이상으로 이제 꾸준한 수요를 만들어내려면 많은 부분에서는 연구를 해봐야 된다고 생각해요.\n",
      "\n",
      "왜냐하면 지금 신경망 학습시키는 게 장점만 있는 건 아니에요.\n",
      "\n",
      "단점은 얘가 인간이랑 제일 큰 차이점이 데이터 한 두 개 보고 학습이 안 된다는 거예요.\n",
      "\n",
      "예를 들면 여기 버닝사이드 시청자 여러분은 영상을 만 개씩 봐야 특정 테마를 익힐 수 있는 것이 아니잖아요.\n",
      "\n",
      "하나만 봐도 익히죠.\n",
      "\n",
      "근데 인공지능은 문제와 정답상 하나 가지고 배울 수가 없고 엄청 많이 봐야 돼요.\n",
      "\n",
      "GPT를 통한 인공지능 변호사 이런 거 만들려면 일단 데이터 장벽부터 있는 거예요.\n",
      "\n",
      "질문과 정답상이 충분히 있냐.\n",
      "\n",
      "그런 것들이 지금은 다 조사가 안 돼 있고 이제야 사람들을 찾아보는 중일 거잖아요.\n",
      "\n",
      "그러니까 저는 당분간은 연구개발 수요는 크겠지만 이게 정말 세상을 바꿀 만큼 여기저기 적용될 건지 아니면 마이크로소프트만 자기들 검색엔진과 오피스에 쓸 건지 이거는 저는 좀 봐야 된다고 생각해요.\n",
      "\n",
      "우리나라의 발표체는 어떻게 쓰일 것인가요? 일단 제일 크게 쓰이는 건 역시 메모리죠.\n",
      "\n",
      "인공신경망의 특징 중 하나는요.\n",
      "\n",
      "CPU용으로 짠 프로그램보다 용량이 엄청나게 크다는 거예요.\n",
      "\n",
      "정말 코드를 잘 짜서 숫자가 5를 넘으면 뭐 안녕하세요 말하는 코드를 쓴다.\n",
      "\n",
      "이거는 용량 진짜로 몇 킬로바이트 안 하거든요.\n",
      "\n",
      "근데 제가 동일한 일을 하려는 걸 인공신경망으로 만들면 용량이 몇백배 커요, 실제로는.\n",
      "\n",
      "그래서 메모리 중에 고용량, 고대역폭 메모리가 중요한 거예요, 지금.\n",
      "\n",
      "일단 한국에서 제일 주요하게 팔리는 것들은 인공지능 쪽에 그 HBM 같은 고용량 고속 메모리들이죠.\n",
      "\n",
      "그쪽에서 확실히 수요가 있다고 봐야죠.\n",
      "\n",
      "그러니까 이런 느낌이에요.\n",
      "\n",
      "예를 들면 제가 CPU 프로그램에다가 1 더하기 1을 계산하게 시키면 프로그램 용량 해봤자 얼마나 하겠어요.\n",
      "\n",
      "근데 저한테 1 더하기 1 물어보고 MRI 찍으면 순식간에 뻘겋뻘겋해졌다가 없어진다고요.\n",
      "\n",
      "되게 비율적이잖아요, 그렇게 보면.\n",
      "\n",
      "용량이 크다니까요, 그렇게.\n",
      "\n",
      "여기 뇌세포 하나하나로 옮겨 놓는 거잖아요.\n",
      "\n",
      "1 더하기 1을 하기 위해서 뇌세포를 거쳐가는 신호의 개수가 뭐 3개겠냐 이거예요.\n",
      "\n",
      "1 더하기 1은 2.\n",
      "\n",
      "3개 들어가면 한 개 답이 나오는 게 아니고 수백억 개가 막 여기서 반응을 하잖아요.\n",
      "\n",
      "그거를 재현해야 되는 거잖아요, 컴퓨터의 내부에 맞춰서.\n",
      "\n",
      "고용량 메모리가 필요할 텐데 당장 물량을 딱 고민해보면 마이크로소프트 엣저이 슈퍼컴퓨터가 엔비디아 V100인가 하는 학습용 GPU를 만 개인가 엮었거든요.\n",
      "\n",
      "근데 이거 만 개 엮으면 이게 메모리 용량이 40만 기가바이트 그래요.\n",
      "\n",
      "엄청 큰 것 같지만 우리 평균 스마트폰에 8기가 들어가잖아요.\n",
      "\n",
      "8기가 들어가면 이거 2만 개 팔아도 스마트폰으로 한 5배? 40이랑 8이니까 5배죠? 그러면 스마트폰 판매량으로는 한 10만 개 정도 되겠네요.\n",
      "\n",
      "근데 스마트폰 1년에 10억 개 팔잖아요, 전 세계에.\n",
      "\n",
      "그러니까 이것만으로는 물량이 엄청 크지 않다는 얘기를 하는 거예요.\n",
      "\n",
      "엣저이 슈퍼컴퓨터 1년에 한 100개씩 팔아도 전체 메모리 물량에서 크진 않죠.\n",
      "\n",
      "물론 메모리 용량된 단가는 크게 쳐주겠지만.\n",
      "\n",
      "그래서 이게 GPT 같은 게 메모리 시장에 예전에는 PC였고, 스마트폰이었고, 지금은 서버인데 제사의 어떤 수요를 만들려면요.\n",
      "\n",
      "지금 연구개발 수요로 안 된다는 이야기를 하는 거예요.\n",
      "\n",
      "연구개발 수요 말고 꾸준히 사용되는 수요가 있어야 되는데 왜냐하면 연구개발하는 건 결국 한 번 사고 잘 안 되면 버릴 거잖아요.\n",
      "\n",
      "한국어 문장요약 결과:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m다음 문장을 요약해주세요:\n",
      "\n",
      "그래서 이게 GPT 같은 게 메모리 시장에 예전에는 PC였고, 스마트폰이었고, 지금은 서버인데 제사의 어떤 수요를 만들려면요.\n",
      "\n",
      "지금 연구개발 수요로 안 된다는 이야기를 하는 거예요.\n",
      "\n",
      "연구개발 수요 말고 꾸준히 사용되는 수요가 있어야 되는데 왜냐하면 연구개발하는 건 결국 한 번 사고 잘 안 되면 버릴 거잖아요.\n",
      "\n",
      "근데 꾸준히 써야 되면 연구개발용도 계속 사고 상업용으로도 계속 사야 되니까 수요가 꾸준히 늘어나죠.\n",
      "\n",
      "근데 그걸 알려면 사실 메모리 시장이나 엔비디아를 볼 게 아니고 우리가 GPT 같은 걸로 하고 싶은 사업모델 중에 데이터들의 쌍이 잘 갖춰져 있는 곳이 있나 그거를 알아야 답을 할 수 있다는 얘기인 거예요.\n",
      "\n",
      "전 그래서 지금은 그걸로 메모리 시장이 확 바뀔 거다 그렇게까지는 기대하지 않아요.\n",
      "\n",
      "지금 인공지능은요.\n",
      "\n",
      "우리가 좀 이렇게 착각들을 하는 게 인터넷에는 데이터가 무한하니까 그냥 데이터 넣으면 똑똑해지겠네 라고 생각하거나 그렇지가 않아요.\n",
      "\n",
      "예를 들어서 제가 개와 고양이를 구분시켜야 된다고 하면 사진만 넣는 게 아니라 사진에 개라고 써놔야 돼요.\n",
      "\n",
      "고양이 사진 고양이라고 써놔야 되고요.\n",
      "\n",
      "그렇게 질문과 정답 쌍이 있어야 배울 수 있는 거예요.\n",
      "\n",
      "사진은 그래도 좀 쉽죠.\n",
      "\n",
      "이거 뭐 사람 몇 명 쓰면 사진 100만 개 만들 수 있을 거예요.\n",
      "\n",
      "근데 말하는 인공지능은 어떨까요? 이거 질문과 대답 쌍을 만들기 쉬울까요? 우리 인터넷에 글을 그냥 긁으면 질문과 대답 쌍이 충분히 많이 나올까요? 그러니까 그 안에서는 질문과 대답 쌍 자체를 찾는 것도 되게 어렵고요.\n",
      "\n",
      "그리고 그중에 신뢰할 수 있는 말이 있느냐 이것도 되게 중요해요.\n",
      "\n",
      "지금 GPT 같은 게 학습이 잘 될 수밖에 없는 게 요약 같은 거 되게 잘하거든요.\n",
      "\n",
      "해보면 왜 요약이 잘 되냐 하면요.\n",
      "\n",
      "요약은 이미 그 인터넷에 쌍이 많이 있거든요.\n",
      "\n",
      "제가 일일이 GPT에 만들어줄 몇 테라바이트 데이터를 일일이 질문 답변 쓰는 건 수학적으로 말이 안 돼요.\n",
      "\n",
      "왜냐하면 사람이 열심히 쳐봤자 제가 한 만 단어 치는 것도 힘든데 일주일 동안 근데 얘는 수백억 단어가 필요한데 그거 사람 뽑아서 한다고 되겠어요? 그게? 안 되죠.\n",
      "\n",
      "대부분 있는 데이터 중에 좋은 데이터를 정제해서 쓰는 게 중요해요.\n",
      "\n",
      "근데 예를 들면 요약 같은 거는 위키페디아 이런 거 있잖아요.\n",
      "\n",
      "인트로덕션 안에 사실상 요약이에요.\n",
      "\n",
      "그리고 밑에가 본문이잖아요.\n",
      "\n",
      "본문을 주고 이거 요약해줘 한 다음에 정답을 인트로덕션 같은 걸 넣어서 할 수가 있거든요.\n",
      "\n",
      "그런 일들은 잘 되는 거예요.\n",
      "\n",
      "근데 이제 예를 들면 우리가 GPT가 세상을 바꾸려면 그런 식으로 쓸 수 있는 데이터가 있는 곳이어야 적용 가능한 거예요.\n",
      "\n",
      "예를 들면 제가 법조계 쪽으로 GPT를 쓰고 싶고 GPT를 학습시키고 싶잖아요.\n",
      "\n",
      "그러면 그것도 판례랑 답이 있어야 되는데 그것도 이제 얼마나 좋은 판례인지 이런 걸 다 매겨줘야 된다는 거예요.\n",
      "\n",
      "그 양도 많아야 되는 거죠.\n",
      "\n",
      "그리고 그러고 나면 사업성 문제가 생겨요.\n",
      "\n",
      "그렇게 한국에서 이거 학습을 시켰는데 미국에 쓸 수 있어요, 그거? 못 쓰죠.\n",
      "\n",
      "미국법이 아니니까 그건.\n",
      "\n",
      "이거는 상장된 회사는 아닌데 세레브라스 이런 회사들이 있어요.\n",
      "\n",
      "정확하게는 NVIDIA GPU도 완벽한 칩은 아니에요.\n",
      "\n",
      "인공지능 쪽에서는 범용적이고 쓰기 편한 칩이긴 한데 얘도 한계가 있어요.\n",
      "\n",
      "예를 들면 지금 도는 채집 PT 같은 거 말했지만 애저 슈퍼컴퓨터의 그래픽카드 만 개를 엮었다고 했잖아요.\n",
      "\n",
      "근데 그렇게 엮으면 비효율도 크고 비용도 크거든요.\n",
      "\n",
      "그래서 이제 세레브라스 같은 회사는 그만한 GPU를 하나씩 엮을 바에 이따만한 칩을 웨이퍼 하나에 놓고 그 안에 신경망을 한 번에 다 올리자 이런 식으로 얘기를 해요.\n",
      "\n",
      "이거는 단일 GPU 안에 다 안 들어가서 이거를 쪼개서 담기 위한 노력도 많이 하고 그 비효율이 많거든요.\n",
      "\n",
      "근데 이제 그런 거대한 칩에는 신경망이 한 번에 딱 들어가죠.\n",
      "\n",
      "그러면 기존에 이론상으로는 할 수 있지만 GPU의 용량 한 개로 해보기 힘들었던 걸 많이 해볼 수 있어요.\n",
      "\n",
      "그런 칩들을 쓰면.\n",
      "\n",
      "저는 이제 그런 무류의 칩들을 보는 건 나쁘지 않다고 생각해요.\n",
      "\n",
      "정확하게 이제 조건은 두 개 있어요.\n",
      "\n",
      "이런 칩들이 잘 되려면 첫째로 지금 채집 PT와 비슷한데 거대한 언어모델이죠, 이게.\n",
      "\n",
      "내가 하려고 하는 사업 분야에 데이터가 아까 말한 형태의 데이터가 있고요.\n",
      "\n",
      "그런 데이터들이 풍족하고 근데 NVIDIA GPU 쓰면 원가가 좀 안 나오는 애들.\n",
      "\n",
      "이런 애들일 때 가능성이 있는 거예요.\n",
      "\n",
      "예를 들면 제가 비즈니스를 하고 싶은데 이 채집 PT 같은 거 지금 공개된 거는 한 3,000단어 정도만 입력으로 들어갈 수 있어요.\n",
      "\n",
      "제가 채집 PT랑 대화를 주고받는다 그러면 대화 총합이 3,000단어 넘어가면 까먹어요, 얘는.\n",
      "\n",
      "원래 그런 디자인인 거예요.\n",
      "\n",
      "근데 그거를 늘리려면 늘릴 때 데이터도 많이 필요하고요.\n",
      "\n",
      "늘린 다음에 사양도 훨씬 많이 먹어요.\n",
      "\n",
      "이제 기술 발전이 좀 있긴 하겠지만 지금 상황에서는 그 3,000단어를 6,000단어로 늘리면 4배 정도 커져요, 얘가 대충.\n",
      "\n",
      "연산해야 되니까 4배씩 커지게 되니까 제가 이제 사업 모델을 봤더니 아, 3,000단어는 부족하고 뭐 8만 단어까지 하고 싶다.\n",
      "\n",
      "이러면 NVIDIA GPU 지금 1만 개 엮어서 했는데 몇 개 엮어서 할 거예요, 그때? 100만 개 엮어서 할 건가요? 그렇게 할 수 없잖아요.\n",
      "\n",
      "그러면 새로운 반도체 찾는 거죠.\n",
      "\n",
      "그 아파트들의 검폐율을 보면 보통 17%씩 높입니다.\n",
      "\n",
      "땅을 20평만 지어야 돼요.\n",
      "\n",
      "100평 되려면 10층이 돼야 200평 나오잖아요, 그렇죠? 이 시스템만 아시면 아시면 부동산은 제가 장담하고 있는데 반은 이미 안 갑니다.\n",
      "\n",
      "나머지는 디테일입니다.\n",
      "\n",
      "이걸 정확히 모르고 저 땅이 예쁘다, 이런 거 얘기할 필요 없습니다.\n",
      "\n",
      "한국어 문장요약 결과:\n",
      "\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m다음 문장을 요약해주세요:\n",
      "\n",
      "인공신경망은 CPU가 잘하는 일이 아니며, 인공지능 개발에는 데이터가 필요하다. 인공신경망은 용량이 크고, NVIDIA GPU도 완벽한 칩은 아니며, 인공지능을 만들기 위해서는 여러 가지 아이디어를 사용한다. 인공신경망은 CPU보다는 GPU를 사용하며, 인공신경망은 입력값을 소수점으로 바꾼 다음 소수점 곱셈을 엄청나게 한다.\n",
      "\n",
      "인공지능 기술은 CPU가 더 똑똑한 칩인데, 현재 인공지능 기술은 무식한 방식으로 구현되어 있다. 인공신경망을 만들기 위해서는 뇌세포와 뇌세포의 연결관계를 어떻게 해줘야 하는지를 알아내야 하며, GPU를 사용하여 그래픽과 비슷한 연산을 요구하는 인공지능 기술을 구현하고 있다. 하지만 GPU를 사용하는 방법을 모르는 사람들이 많아서 진입장벽이 높다.\n",
      "\n",
      "엔비디아의 그래픽 카드는 슈퍼컴퓨터나 시뮬레이션 등 물리 연산에도 사용되며, CUDA 등의 기술로 GPU용 프로그램 개발을 지원한다. 이를 활용한 인공지능 연구개발 수요는 크겠지만, 꾸준한 사용 수요를 만들기 위해서는 연구가 필요하다. 메모리 중 고용량 고속 메모리가 인공신경망에서 중요하게 사용되며, 한국에서는 이에 대한 수요가 크다. 하지만 메모리 용량이 크기 때문에 물량은 많지 않다. 이에 대한 해결책으로는 GPT 등의 기술이 있다.\n",
      "\n",
      "GPT와 같은 기술은 꾸준한 사용 수요가 있어야 하며, 데이터 쌍이 잘 갖춰진 곳에서 적용 가능하다. 인공지능 학습에는 질문과 대답 쌍이 필요하며, 이를 위해서는 데이터 정제가 필요하다. 세레브라스와 같은 회사는 대용량 칩을 사용하여 인공지능 학습을 가능하게 하고 있다. 하지만 이를 위해서는 데이터가 풍부하고 NVIDIA GPU를 사용하면 원가가 적은 분야여야 한다. GPT와 같은 기술은 한계가 있으며, 새로운 반도체를 찾아야 한다.\n",
      "\n",
      "한국어 문장요약 결과:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# refine\n",
    "# https://python.langchain.com/en/latest/reference/modules/text_splitter.html\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain import OpenAI, PromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.docstore.document import Document\n",
    "from pprint import pprint\n",
    "import tiktoken\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "\n",
    "\n",
    "with open('./정인성작가_transcript.txt', 'r', encoding='utf-8') as f:\n",
    "    transcript = f.read()\n",
    "\n",
    "transcript = transcript.replace('. ', '.\\n\\n')\n",
    "enc35 = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "# tokenized_text_chatgpt35 = enc35.encode(transcript)\n",
    "# print(len(tokenized_text_chatgpt35))\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=3000, chunk_overlap=200)\n",
    "texts = text_splitter.split_text(transcript) # 문장 분리 길이 4000 미만 및 chunk_overlap 200\n",
    "docs = [Document(page_content=t) for t in texts]\n",
    "pprint(docs)\n",
    "\n",
    "# 나뉜 문단별 토큰수 계산\n",
    "tmp_tok = 0\n",
    "for doc in docs:\n",
    "    tokenized_text_chatgpt35 = enc35.encode(doc.page_content)\n",
    "    # print(len(tokenized_text_chatgpt35))\n",
    "    tmp_tok += len(tokenized_text_chatgpt35)\n",
    "print('전체 토큰수', tmp_tok)\n",
    "\n",
    "# 템플릿 작성\n",
    "############################################################################################################\n",
    "prompt_template = \"\"\"다음 문장을 요약해주세요:\n",
    "\n",
    "{text}\n",
    "\n",
    "한국어 문장요약 결과:\n",
    "\"\"\"\n",
    "############################################################################################################\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "# 모든 데이터에 한번에 엑세스 하므로 전체 토큰이 \n",
    "llmc = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\") # chatgpt 3.5 model\n",
    "chain = load_summarize_chain(llmc, \n",
    "                             chain_type=\"map_reduce\",  # map_reduce 방식 각각의 chunk에 대해 요약을 먼저 진행하고 그 결과를 다시 요약하는 방식 -> 각각의 요약에대해 병렬처리함\n",
    "                             return_intermediate_steps=True,\n",
    "                             map_prompt=PROMPT,\n",
    "                             combine_prompt=PROMPT,\n",
    "                             verbose=True)\n",
    "'''\n",
    "map_reduce 방법은 각 데이터 청크에 대해 초기 프롬프트를 실행하는 것입니다\n",
    "(요약 작업의 경우 해당 청크에 대한 요약이 될 수 있고, 질문 답변 작업의 경우 해당 청크에만 기반한 답변이 될 수 있습니다).\n",
    "\n",
    "그런 다음 다른 프롬프트가 실행되어 모든 초기 출력을 결합합니다. 이것은 LangChain에서 MapReduceDocumentsChain으로 구현됩니다.\n",
    "\n",
    "장점: StuffDocumentsChain보다 더 큰 문서(및 더 많은 문서)로 확장할 수 있습니다.\n",
    "     개별 문서에서 LLM에 대한 호출은 독립적이므로 병렬화할 수 있습니다.\n",
    "\n",
    "단점: StuffDocumentsChain보다 훨씬 더 많은 LLM 호출이 필요합니다. 최종 결합 호출 중에 일부 정보가 손실됩니다.\n",
    "'''\n",
    "# chain.run(docs[:])\n",
    "res = chain({\"input_documents\": docs}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intermediate_steps': ['인공신경망은 CPU가 잘하는 일이 아니며, 인공지능 개발에는 데이터가 필요하다. 인공신경망은 '\n",
      "                        '용량이 크고, NVIDIA GPU도 완벽한 칩은 아니며, 인공지능을 만들기 위해서는 여러 가지 '\n",
      "                        '아이디어를 사용한다. 인공신경망은 CPU보다는 GPU를 사용하며, 인공신경망은 입력값을 '\n",
      "                        '소수점으로 바꾼 다음 소수점 곱셈을 엄청나게 한다.',\n",
      "                        '인공지능 기술은 CPU가 더 똑똑한 칩인데, 현재 인공지능 기술은 무식한 방식으로 구현되어 '\n",
      "                        '있다. 인공신경망을 만들기 위해서는 뇌세포와 뇌세포의 연결관계를 어떻게 해줘야 하는지를 알아내야 '\n",
      "                        '하며, GPU를 사용하여 그래픽과 비슷한 연산을 요구하는 인공지능 기술을 구현하고 있다. 하지만 '\n",
      "                        'GPU를 사용하는 방법을 모르는 사람들이 많아서 진입장벽이 높다.',\n",
      "                        '엔비디아의 그래픽 카드는 슈퍼컴퓨터나 시뮬레이션 등 물리 연산에도 사용되며, CUDA 등의 '\n",
      "                        '기술로 GPU용 프로그램 개발을 지원한다. 이를 활용한 인공지능 연구개발 수요는 크겠지만, '\n",
      "                        '꾸준한 사용 수요를 만들기 위해서는 연구가 필요하다. 메모리 중 고용량 고속 메모리가 '\n",
      "                        '인공신경망에서 중요하게 사용되며, 한국에서는 이에 대한 수요가 크다. 하지만 메모리 용량이 크기 '\n",
      "                        '때문에 물량은 많지 않다. 이에 대한 해결책으로는 GPT 등의 기술이 있다.',\n",
      "                        'GPT와 같은 기술은 꾸준한 사용 수요가 있어야 하며, 데이터 쌍이 잘 갖춰진 곳에서 적용 '\n",
      "                        '가능하다. 인공지능 학습에는 질문과 대답 쌍이 필요하며, 이를 위해서는 데이터 정제가 필요하다. '\n",
      "                        '세레브라스와 같은 회사는 대용량 칩을 사용하여 인공지능 학습을 가능하게 하고 있다. 하지만 이를 '\n",
      "                        '위해서는 데이터가 풍부하고 NVIDIA GPU를 사용하면 원가가 적은 분야여야 한다. GPT와 '\n",
      "                        '같은 기술은 한계가 있으며, 새로운 반도체를 찾아야 한다.'],\n",
      " 'output_text': '인공신경망은 CPU보다는 GPU를 사용하며, 인공지능 개발에는 데이터가 필요하다. GPU를 사용하는 방법을 '\n",
      "                '모르는 사람들이 많아서 진입장벽이 높다. GPT와 같은 기술은 데이터 쌍이 잘 갖춰진 곳에서 적용 가능하며, '\n",
      "                '세레브라스와 같은 회사는 대용량 칩을 사용하여 인공지능 학습을 가능하게 하고 있다. 하지만 이를 위해서는 '\n",
      "                '데이터가 풍부하고 NVIDIA GPU를 사용하면 원가가 적은 분야여야 한다.'}\n"
     ]
    }
   ],
   "source": [
    "pprint(res)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# The `refine` Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refine chain 이렇게 생김\n",
    "# 프롬프트 하나 때리고 나서 refine 프롬프트를 또 때림\n",
    "\n",
    "# /autogpt/lib/python3.9/site-packages/langchain/chains/summarize/refine_prompts.py\n",
    "# flake8: noqa\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "REFINE_PROMPT_TMPL = (\n",
    "    \"Your job is to produce a final summary\\n\"\n",
    "    \"We have provided an existing summary up to a certain point: {existing_answer}\\n\"\n",
    "    \"We have the opportunity to refine the existing summary\"\n",
    "    \"(only if needed) with some more context below.\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"{text}\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"Given the new context, refine the original summary\"\n",
    "    \"If the context isn't useful, return the original summary.\"\n",
    ")\n",
    "REFINE_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"existing_answer\", \"text\"],\n",
    "    template=REFINE_PROMPT_TMPL,\n",
    ")\n",
    "\n",
    "\n",
    "prompt_template = \"\"\"Write a concise summary of the following:\n",
    "\n",
    "\n",
    "\"{text}\"\n",
    "\n",
    "\n",
    "CONCISE SUMMARY:\"\"\"\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='인공신경망은 특징이 CPU가 잘하는 일은 아니라는 거예요.\\n\\n숫자가 5를 넘으면 안녕하세요 말하는 코드를 쓴다.\\n\\n이거는 용량 진짜로 몇 킬로바이트 안 하거든요? 근데 제가 동일한 일을 하려는 걸 인공신경망으로 만들면 용량이 몇백배 커요.\\n\\nNVIDIA GPU도 완벽한 칩은 아니에요.\\n\\n예전 슈퍼컴퓨터에 그래픽카드 만 개를 엮었다고 했잖아요.\\n\\n근데 그렇게 엮으면 비효율도 크고 비용도 크거든요.\\n\\nGPT를 통한 인공지능 변호사 이런 거 만들려면 데이터 장벽부터 있는 거예요.\\n\\n예전에는 PC였고 스마트폰이었고 지금은 서버인데 제 사회의 어떤 수요를 만들려면요.\\n\\n안녕하세요.\\n\\n머니인사이드 시청자 여러분 정인성 작가입니다.\\n\\n저는 원래 반도체 회사에서 반도체 관련한 시뮬레이션 일을 하고 있었고요.\\n\\n최근에 인공지능 관련해서도 새로운 책을 쓸 수 있었고요.\\n\\n지금은 이제 동료들이랑 인공지능 개발 쪽으로 와 있습니다.\\n\\n스타릿에서 어떤...\\n\\n반도체들을 완제품을 만들고 나면 이 반도체들을 또 뭉쳐서 그 위에다가 조그마한 컨트롤러를 붙여서 막 동작을 하게 만들어요.\\n\\n쉽게 말하면 원본 반도체가 아니고 반도체들을 결합해서 새로운 가치를 만드는 거죠.\\n\\n이제 그런 것들을 시뮬레이션으로 검증하는 그런 일들을 했죠.\\n\\n인공지능은 용어를 구분할 필요가 있는데 인공지능은 우리 꿈 같은 거예요.\\n\\n그러니까 우리가 하고 싶은 거 쉽게 말하면 이 인공지능이라는 요소가 딱 잘 정의되진 않는데 예를 들면 예전에 있던 그 바둑에 있는 바둑 AI나 그 스타크래프트에서 이제 컴퓨터 상대를 넣었어요.\\n\\n그런 것도 다 인공지능이라고 불러요.\\n\\n실제로는 그렇게 부를 수 있고요.\\n\\n그러니까 인공지능이라는 것 자체가 굉장히 어마어마한 개념이고 그렇진 않은 거예요.\\n\\n근데 이제 우리 일반인들 입장에서는 좀 터미네이터 같은 걸 생각하겠죠.\\n\\n인공지능으로.\\n\\n저 일하는 입장에서 인공지능은 어떤 물건이냐 하면요.\\n\\n스스로 배워요.\\n\\n그러니까 저는 이제 프로그래머를 짜서 뭐 컴파일을 하거나 아니면 뭐 스크립트를 실행하면 얘가 막 돌아가거든요.\\n\\n근데 시킨 대로 돌아가요.\\n\\n얘는.\\n\\n예를 들면 제가 정말 어렵게 엄청 힘든 건데 프로그램을 막 짜서 개랑 고양이 구분하는 프로그램을 짰다고 해볼게요.\\n\\n근데 이 프로그램은요.\\n\\n제가 그 다음에 코끼리를 어떻게 하려고 하면 다시 짜야 돼요.\\n\\n또.\\n\\n코끼리 구분하는 코드를 막 짜야 되죠.\\n\\n근데 이제 저는 사실 어떻게 하고 싶냐.\\n\\n프로그램 하나 만들어 놓고 코끼리 사진만 막 넣으면 코끼리도 구분했으면 좋겠는 거예요.\\n\\n프로그램이.\\n\\n제가 프로그램을 다시 짜는 것과 있는 프로그램 냅두고 사진만 모아서 긁어 넣는 것 중에 뭐가 쉽겠어요.\\n\\n사진만 넣는 게 훨씬 쉽죠.\\n\\n프로그램 짜라 그러면 끼약하겠지만 코끼리 사진을 1,000개 모아오라 하면 아마 즐겁게 모아올 거라고요.\\n\\n그냥.\\n\\n당연히 훨씬 쉽죠.\\n\\n그게.\\n\\n지금 말하는 인공지능에서 중요한 요소들은 그런 거예요.\\n\\n바둑 인공지능도 다 인공지능이고 한데 지금 우리가 중요하게 여기는 요소는 얘가 스스로 배워서 내놓는 결과를 바꾸는 물건이란 거예요.\\n\\n그쪽을 중요하게 봐온 게 그 인공지능인 거예요.\\n\\n그리고 반도체는 그거와 뭐가 관계가 있느냐.\\n\\n지금 제가 말씀드린 건 다 컨셉이죠.\\n\\n어떻게 만드는지에 대한 얘기가 없잖아요.\\n\\n그래서 그런 인공지능을 만드는 아이디어가 여러 개 있었어요.\\n\\nSVM 뭐 이런 방법도 있고 뭐 그냥 코드를 엄청 무식하게 짜보는 방법도 있고요.\\n\\n뭐 IBM 왓슨처럼 막 만드는 방법도 있는데 요거 다 다른 형태의 프로그램이잖아요.\\n\\n요 방법들 중에 제가 A라는 방법을 택하면 예를 들어 CPU가 빨라야 되고 메모리는 적어도 되고 B라는 방법을 쓰면 CPU보다 메모리가 중요하고 요런 식으로 바뀌어요.\\n\\n왜냐하면 프로그램도 그냥 CPU에서 도는 게 아니고요.\\n\\nCPU가 잘하는 일 중심으로 프로그램을 짜야 빠른 거잖아요.\\n\\n그게 반도체랑 인공지능 기술의 핵심인 거예요.\\n\\n우리는 인공지능이라는 추상적인 개념을 만들고 싶고요.\\n\\n그래서 그 추상적인 개념이 돌아가게 하기 위해서 여러 가지 아이디어를 쓰는 거예요.\\n\\n그중에 지금 제일 잘 되는 게 인공신경망이라는 개념이에요.\\n\\n인간의 뇌세포 구조를 좀 따라해서 그 신경망을 이제 우리 학습시킨 방법을 알아냈기 때문에 학습시키면은 우리가 원하던 인공지능 스스로 뭐 배우고 뭐 진짜 의미로 스스로 배우진 않죠 이제.\\n\\n우리가 코드를 다시 짜지 않아도 데이터만 넣어서 다시 학습시키면 원하는 결과 나오고 그런 걸 할 수 있는 게 이제 인공신경망이에요.\\n\\n근데 이 인공신경망은 특징이 CPU가 잘하는 일은 아니라는 거예요 얘가.\\n\\n그러니까 이제 기존에 CPU만 우리 90년대, 2000년대 CPU만 있었는데 지금 NVIDIA GPU를 쓰는 거예요.\\n\\n우리에겐 하고 싶은 일이 있고 그중에 그 일을 제일 잘하는 방법론을 찾아요.\\n\\n어떤 방식으로 프로그램을 만들어야 스스로 잘 배우는 프로그램이 된다.\\n\\n그리고 그 프로그램들은 각자 원하는 반도체가 달라요.\\n\\n그 일을 잘할 수 있는 반도체가 다르죠.\\n\\n그렇게 움직이는 거예요.\\n\\nCPU와 GPU의 큰 차이가? 사실 둘 다 메모리가 아니고 연산용 칩인데 CPU라는 거는 그 조건 파악을 잘해요.\\n\\n예를 들면 제 입장에서 머니인사이드의 시청자가 몇 명 이상이면 참여하고 아니면은 출연하지 마라.\\n\\n이런 식으로 그 조건이 있으면 선택을 하는 거잖아요.\\n\\n이런 식의 일을 되게 잘해요.\\n\\n그게 그 CPU가 잘하는 일이고요.\\n\\n그리고 GPU는 뭘 잘하냐 하면은 숫자 계산을 엄청 잘해요 그냥.\\n\\n0.1 곱하기 0.4 뭐 이런 숫자를 뭐 수만 개 계산하는 걸 엄청 잘해요.\\n\\n근데 우리가 과거에 봤던 수많은 프로그램들은요.\\n\\n앞에 말했던 조건이 중요해요.\\n\\n예를 들면 엑셀이잖아요.\\n\\n제가 엑셀 칸에다가 함수를 넣으면 만약 함수가 sum이면은 더해라.\\n\\n이런 거죠.\\n\\n이렇게 조건이잖아요 다.\\n\\n그래서 그런 걸 잘하게 설계되어 있어요 CPU는.\\n\\n근데 인공신경만 어떻게 돌아가냐 하면 그냥 입력값을 다 소수점으로 바꾼 다음에 소수점 곱셈을 엄청나게 해요.', metadata={}),\n",
      " Document(page_content='앞에 말했던 조건이 중요해요.\\n\\n예를 들면 엑셀이잖아요.\\n\\n제가 엑셀 칸에다가 함수를 넣으면 만약 함수가 sum이면은 더해라.\\n\\n이런 거죠.\\n\\n이렇게 조건이잖아요 다.\\n\\n그래서 그런 걸 잘하게 설계되어 있어요 CPU는.\\n\\n근데 인공신경만 어떻게 돌아가냐 하면 그냥 입력값을 다 소수점으로 바꾼 다음에 소수점 곱셈을 엄청나게 해요.\\n\\n곱셈, 넛셈을 뭐 수억 번씩 하면 결과가 나오는데 그러면은 결과가 잘 나오는 그런 물건이에요.\\n\\n그러니까 어떻게 보면 인간이 조건을 하나씩 넣어주는 형태 프로그램에서 그냥 모두 다 숫자로 바꿔서 숫자로 와장창 곱하면은 이제 원하는 결과가 튀어나오는 좀 신기한 상황이 된 거죠.\\n\\nQ.\\n\\n인공지능 기술은 어떻게 변화할까요? 어떻게 보면 CPU가 좀 더 똑똑한 칩인데 우리가 지금 보는 인공지능 기술은 좀 무식한 방식으로 좀 더 나은 지성이 구현되어 있는 그런 모습이에요.\\n\\n숫자가 인공지능이 돌아가는 원리? 그러니까 인간 머리가 일단 그런 식으로 돌아가잖아요.\\n\\n왜냐하면 인간 유전자 안에 CPU 설계가 들어있겠어요? 그런 복잡한 설계가 있을까요? 인간 안에? 그 CPU 안에는 그 수십억 개 트랜지스터가 막 연결되어 있는 설계도가 있는데 인간은 그렇지 않잖아요.\\n\\n그래서 뇌세포들은 다 보면은 특정 뇌세포에 자극이 들어오면 인접한 뇌세포에다가 특정 그 역치값을 넘으면 자극을 전달하고 역치를 안 넘으면 자극을 안 전달하고 이렇게 돼 있어요.\\n\\n그 연결관계를 수조개 모아놓으면 지성이 되는 거잖아요.\\n\\n그리고 과거에는 문제가 뭐였냐면은 어 그러면 우리 인간 뇌 모습을 좀 따라해서 이렇게 막 연결하면 지성이 나올 거야.\\n\\n이론상.\\n\\n그 문제는 뭐냐? 이 연결이 예를 들면 A라는 뇌세포랑 B라는 뇌세포 사이 연결을 얼마나 강하게 전달해줘야 돼? 이런 걸 하나도 모르는 거예요.\\n\\n그러니까 우리가 앞에서 말한 프로그래밍이라는 개념은 아까 말한 것처럼 조건문을 쓰는 거였는데 이제는 그 세포와 세포 사이 연결 강도가 0.1이냐 0.3이냐 이런 거를 고민해야 되는 상황이 된 거예요.\\n\\n그 문제가 뭐겠어요? 수십억 개가 있는데 그중에 이거 세포 하나 딱 해서 얘네 둘 사이가 이게 영향을 뭘 주는 거야? 하면 그걸 알아내겠냐는 거예요.\\n\\n그걸 알 수가 없잖아요.\\n\\n그래서 오랫동안 힘들었던 거예요.\\n\\n인공지능, 인간 뇌세포를 따라해보자는 아이디어가 뭐 그렇게 참신한가요 이게? 60년대에 이미 나왔던 아이디어예요.\\n\\n근데 왜 사장 되고 이제야 떠올랐냐? 그때는 어 그래 이렇게 하면 될 것 같은데 정확하게는 뇌세포와 뇌세포의 연결관계를 어떻게 해줘야 얘가 잘 돌아가는지를 몰랐던 거야.\\n\\n그러니까 몇십 년을 쉰 거죠.\\n\\n이제 몇십 년 동안 그래서 아무도 못 해보고 있다가 캐나다 쪽에서 이제 그거 학습시키는 방법을 알아낸 거예요 그때.\\n\\n아 여기 데이터를 넣고 결과 값에서 어떤 식으로 계산을 해주면 인공신경망이 서서히 정답률이 올라가게 만들 수 있다.\\n\\n요거를 알아냈어요 그때.\\n\\n그 방법을 써보니까 GPU를 써야 빨라요.\\n\\n그렇게 해서 지금의 상황이 된 거예요 이건.\\n\\n쉽게 말하면 프로그램 쓰는 방법이 바뀌어버린 거예요.\\n\\n기존에는 프로그램 쓸 때 제가 순서도를 놓고 이 순서도를 잘못 자면 버그고 그랬는데요.\\n\\n지금은 인공신경망을 크게 구성을 해놓고 그 안에서 값이 정답을 낼 수 있는 형태로 그 수많은 소수점을 바꿔가야 되는 거예요.\\n\\n그래서 GPU가 필요한 거죠.\\n\\nQ.\\n\\n인공신경망을 어떻게 만들어야 할까요? 원래 옛날 게임들은 화면에 표시하는 거랑 게임의 움직임들 표시하는 걸 전부 CPU가 했어요.\\n\\n근데 이제 컴퓨터라는 게 PC라는 게 나오고 계속 유행하다 보니까 사람들이 점점 더 높은 그래픽을 원해요.\\n\\n점점 더 그래픽 좋은 게임도 하고 싶고 영화도 만들고 싶고 이런 거예요.\\n\\n근데 말씀드렸지만 CPU는 분기 처리를 잘해요.\\n\\n조건 처리를 잘하죠.\\n\\n근데 고급 그래픽을 계속 해보니까 이게 CPU에 잘 맞지 않았던 거예요.\\n\\n그래서 CPU에 잘 맞지 않으니까 VGA라고 부르는 그래픽 전용 칩을 만들어서 쉽게 말하면 이런 거예요.\\n\\n제가 여기 인테리어를 해야 되는데 인테리어 디자인도 하고 벽지도 붙이고 청소도 다 했는데 이제는 CPU가 GPU라고 부르는 협력사를 데려와서 저는 여기는 도배하고 여기는 청소하고 시켜놓으면 이걸 하고 가게 하는 거예요.\\n\\n그리고 저는 이제 앉아서 계속 다음번 도배해야 될 거 찾고 있고요.\\n\\nGPU라는 녀석이 와서 도배 같은 일을 해주는 거예요.\\n\\n이 GPU는 제가 하는 일은 잘 못하지만 제가 잘 못하는 걸 잘하는 거죠.\\n\\n결국은 CPU라는 칩이 모든 일을 잘하기에는 한계가 있었던 거예요.\\n\\n왜냐하면 CPU가 아까 말한 조건문 처리를 잘하려면 그쪽에다 소자를 써야 되는데 거기에 소자를 쓰면은 다른 쪽에 쓸 소자가 없잖아요, 제조할 때.\\n\\n그러니까 모든 걸 잘할 수 없으니까 생겨난 일이죠.\\n\\n다행스럽게도 엔비디아가 의도한 바는 아니겠죠, 아마.\\n\\n인공지능 기술을 해내기 위해서 여러 연구를 하는데 제일 잘 되는 기술이 그래픽이랑 비슷한 연산을 요구했던 거예요.\\n\\n제가 그래픽 돌아가는 거...\\n\\n예, 왜냐하면 그래픽도 결국 소수점 많이 곱하고 더하고 하는 거예요.\\n\\n살짝 얻어걸린 느낌도 있죠, 이거는.\\n\\n그래픽을 했는데 회사가 계속 커야 되니까 CPU는 못하고 GPU는 잘하는 일을 계속 찾아다녔어요, 이 회사가.\\n\\n어, 이게 잘 될 거야 라는 그런 느낌으로 바로 가서 2006년, 2007년에 막 질른 게 아니고 전 세계 사람들이 좀 GPU를 쓰기 편하게 이제 CUDA 이런 걸 만들어놨어요.\\n\\n그러니까 엔비디아 생각이 이런 거예요.\\n\\n아, 이게 그래픽에만 쓰진 않겠지.\\n\\n뭐 슈퍼컴퓨터나 시뮬레이션에도 쓸 수 있고 그래서 그 물리연산하는 회사를 인수하기도 하고 그랬어요.\\n\\n근데 이제 그런 걸 그냥 만들어놓고 칩 쓰세요 라고 하면은 쓰는 법을 몰라요, 사람들이.\\n\\n왜냐하면 제가 CPU용으로 프로그램 짜던 사람이 GPU용으로 프로그램 짜려고 하면 진입장벽이 꽤 높거든요.', metadata={}),\n",
      " Document(page_content='아, 이게 그래픽에만 쓰진 않겠지.\\n\\n뭐 슈퍼컴퓨터나 시뮬레이션에도 쓸 수 있고 그래서 그 물리연산하는 회사를 인수하기도 하고 그랬어요.\\n\\n근데 이제 그런 걸 그냥 만들어놓고 칩 쓰세요 라고 하면은 쓰는 법을 몰라요, 사람들이.\\n\\n왜냐하면 제가 CPU용으로 프로그램 짜던 사람이 GPU용으로 프로그램 짜려고 하면 진입장벽이 꽤 높거든요.\\n\\n그래서 엔비디아는 그걸 조금이나마 좀 편하게 해주려고 CUDA 이런 것들을 마련을 해놓은 거죠.\\n\\n근데 그걸 마련해놓은 상황이 이거 쉽게 말하면 캐나다에서 집어다 써본 거에 가까워요.\\n\\n어, 그랬더니 연산속도가 5배 빨라졌어요.\\n\\n뭐 이런 식으로 결과가 나오니까 이제 옆방 대학원생이 이걸로 한 달에 하나 쓰던 논문을 한 달에 5개씩 쓰고 있으면 그러면 나도 써야 되고 그럼 그 옆방 대학원생도 쓰고 할 거잖아요, 당연히.\\n\\n근데 이게 굉장히 반도체 비즈니스에서 사실은 중요한 요소예요.\\n\\n옆사람이 썼는데 안 되던 게 됐잖아요.\\n\\n그러면 그걸 본 옆사람이 쓰죠.\\n\\n그러면 이제 이걸 잘 쓴 사람이 논문 찍어내면서 유명해지죠.\\n\\n그러면 어느 순간 그게 거대한 프로그래머 집단으로 변해요.\\n\\n그러면 이제 지금 2023년 상황에서 제가 대학원 갓 졸업하고 논문 써야 되는데 인공지능으로 논문을 써야 되겠는데 그러면 컴퓨터를 마련하는데 뭘 마련할 거냐 이거예요.\\n\\n전 지금 하나도 안 해봤으니까 일단 남들 하는 걸 다 모방해야 된다니까요.\\n\\n남들 쓰는 컴퓨터 사고 그럼 당연히 엔비디아 GPU 들어가요.\\n\\n그리고 인공지능 한 번도 안 돌려봤으니까 인터넷에 돈을 오픈소스를 받아다가 인공지능을 돌려봐야 돼요.\\n\\n그 오픈소스는 뭘로 쓰여 있겠어요.\\n\\n이것도 엔비디아 GPU를 전제하고 써놨다고요 코드를.\\n\\n그러니까 AMD가 못하는 거예요.\\n\\n이거를 AMD 그래픽 카드로 이제 뭔가 해보려고 실제 실험은 하지도 못하는 거예요.\\n\\n제가 근데 엔비디아 거 쓰면 물어보면 되잖아요.\\n\\n야 넌 어떻게 했니? 이렇게.\\n\\n그게 그 반도체 비즈니스에서 되게 중요한 거예요.\\n\\n생태계예요 이게.\\n\\n어떻게 보면 메모리 같은 건 그런 생태계가 좀 약하고요.\\n\\n인텔의 CPU 같은 것도 그런 생태계를 가지고 있잖아요.\\n\\n그러니까 한참 동안 인텔 CPU가 지금도 그렇게 힘들어해도 살아있는 거예요.\\n\\n여기에 맞춰진 프로그램이 많으니까.\\n\\n반도체 시장은 이제 당분간은 거대 신경망 특히 자연화 신경망이 잘 된다고 했으니까 아마 그쪽 연구개발 수요는 올라갈 거예요.\\n\\n근데 연구개발 이상으로 이제 꾸준한 수요를 만들어내려면 많은 부분에서는 연구를 해봐야 된다고 생각해요.\\n\\n왜냐하면 지금 신경망 학습시키는 게 장점만 있는 건 아니에요.\\n\\n단점은 얘가 인간이랑 제일 큰 차이점이 데이터 한 두 개 보고 학습이 안 된다는 거예요.\\n\\n예를 들면 여기 버닝사이드 시청자 여러분은 영상을 만 개씩 봐야 특정 테마를 익힐 수 있는 것이 아니잖아요.\\n\\n하나만 봐도 익히죠.\\n\\n근데 인공지능은 문제와 정답상 하나 가지고 배울 수가 없고 엄청 많이 봐야 돼요.\\n\\nGPT를 통한 인공지능 변호사 이런 거 만들려면 일단 데이터 장벽부터 있는 거예요.\\n\\n질문과 정답상이 충분히 있냐.\\n\\n그런 것들이 지금은 다 조사가 안 돼 있고 이제야 사람들을 찾아보는 중일 거잖아요.\\n\\n그러니까 저는 당분간은 연구개발 수요는 크겠지만 이게 정말 세상을 바꿀 만큼 여기저기 적용될 건지 아니면 마이크로소프트만 자기들 검색엔진과 오피스에 쓸 건지 이거는 저는 좀 봐야 된다고 생각해요.\\n\\n우리나라의 발표체는 어떻게 쓰일 것인가요? 일단 제일 크게 쓰이는 건 역시 메모리죠.\\n\\n인공신경망의 특징 중 하나는요.\\n\\nCPU용으로 짠 프로그램보다 용량이 엄청나게 크다는 거예요.\\n\\n정말 코드를 잘 짜서 숫자가 5를 넘으면 뭐 안녕하세요 말하는 코드를 쓴다.\\n\\n이거는 용량 진짜로 몇 킬로바이트 안 하거든요.\\n\\n근데 제가 동일한 일을 하려는 걸 인공신경망으로 만들면 용량이 몇백배 커요, 실제로는.\\n\\n그래서 메모리 중에 고용량, 고대역폭 메모리가 중요한 거예요, 지금.\\n\\n일단 한국에서 제일 주요하게 팔리는 것들은 인공지능 쪽에 그 HBM 같은 고용량 고속 메모리들이죠.\\n\\n그쪽에서 확실히 수요가 있다고 봐야죠.\\n\\n그러니까 이런 느낌이에요.\\n\\n예를 들면 제가 CPU 프로그램에다가 1 더하기 1을 계산하게 시키면 프로그램 용량 해봤자 얼마나 하겠어요.\\n\\n근데 저한테 1 더하기 1 물어보고 MRI 찍으면 순식간에 뻘겋뻘겋해졌다가 없어진다고요.\\n\\n되게 비율적이잖아요, 그렇게 보면.\\n\\n용량이 크다니까요, 그렇게.\\n\\n여기 뇌세포 하나하나로 옮겨 놓는 거잖아요.\\n\\n1 더하기 1을 하기 위해서 뇌세포를 거쳐가는 신호의 개수가 뭐 3개겠냐 이거예요.\\n\\n1 더하기 1은 2.\\n\\n3개 들어가면 한 개 답이 나오는 게 아니고 수백억 개가 막 여기서 반응을 하잖아요.\\n\\n그거를 재현해야 되는 거잖아요, 컴퓨터의 내부에 맞춰서.\\n\\n고용량 메모리가 필요할 텐데 당장 물량을 딱 고민해보면 마이크로소프트 엣저이 슈퍼컴퓨터가 엔비디아 V100인가 하는 학습용 GPU를 만 개인가 엮었거든요.\\n\\n근데 이거 만 개 엮으면 이게 메모리 용량이 40만 기가바이트 그래요.\\n\\n엄청 큰 것 같지만 우리 평균 스마트폰에 8기가 들어가잖아요.\\n\\n8기가 들어가면 이거 2만 개 팔아도 스마트폰으로 한 5배? 40이랑 8이니까 5배죠? 그러면 스마트폰 판매량으로는 한 10만 개 정도 되겠네요.\\n\\n근데 스마트폰 1년에 10억 개 팔잖아요, 전 세계에.\\n\\n그러니까 이것만으로는 물량이 엄청 크지 않다는 얘기를 하는 거예요.\\n\\n엣저이 슈퍼컴퓨터 1년에 한 100개씩 팔아도 전체 메모리 물량에서 크진 않죠.\\n\\n물론 메모리 용량된 단가는 크게 쳐주겠지만.\\n\\n그래서 이게 GPT 같은 게 메모리 시장에 예전에는 PC였고, 스마트폰이었고, 지금은 서버인데 제사의 어떤 수요를 만들려면요.\\n\\n지금 연구개발 수요로 안 된다는 이야기를 하는 거예요.\\n\\n연구개발 수요 말고 꾸준히 사용되는 수요가 있어야 되는데 왜냐하면 연구개발하는 건 결국 한 번 사고 잘 안 되면 버릴 거잖아요.', metadata={}),\n",
      " Document(page_content='그래서 이게 GPT 같은 게 메모리 시장에 예전에는 PC였고, 스마트폰이었고, 지금은 서버인데 제사의 어떤 수요를 만들려면요.\\n\\n지금 연구개발 수요로 안 된다는 이야기를 하는 거예요.\\n\\n연구개발 수요 말고 꾸준히 사용되는 수요가 있어야 되는데 왜냐하면 연구개발하는 건 결국 한 번 사고 잘 안 되면 버릴 거잖아요.\\n\\n근데 꾸준히 써야 되면 연구개발용도 계속 사고 상업용으로도 계속 사야 되니까 수요가 꾸준히 늘어나죠.\\n\\n근데 그걸 알려면 사실 메모리 시장이나 엔비디아를 볼 게 아니고 우리가 GPT 같은 걸로 하고 싶은 사업모델 중에 데이터들의 쌍이 잘 갖춰져 있는 곳이 있나 그거를 알아야 답을 할 수 있다는 얘기인 거예요.\\n\\n전 그래서 지금은 그걸로 메모리 시장이 확 바뀔 거다 그렇게까지는 기대하지 않아요.\\n\\n지금 인공지능은요.\\n\\n우리가 좀 이렇게 착각들을 하는 게 인터넷에는 데이터가 무한하니까 그냥 데이터 넣으면 똑똑해지겠네 라고 생각하거나 그렇지가 않아요.\\n\\n예를 들어서 제가 개와 고양이를 구분시켜야 된다고 하면 사진만 넣는 게 아니라 사진에 개라고 써놔야 돼요.\\n\\n고양이 사진 고양이라고 써놔야 되고요.\\n\\n그렇게 질문과 정답 쌍이 있어야 배울 수 있는 거예요.\\n\\n사진은 그래도 좀 쉽죠.\\n\\n이거 뭐 사람 몇 명 쓰면 사진 100만 개 만들 수 있을 거예요.\\n\\n근데 말하는 인공지능은 어떨까요? 이거 질문과 대답 쌍을 만들기 쉬울까요? 우리 인터넷에 글을 그냥 긁으면 질문과 대답 쌍이 충분히 많이 나올까요? 그러니까 그 안에서는 질문과 대답 쌍 자체를 찾는 것도 되게 어렵고요.\\n\\n그리고 그중에 신뢰할 수 있는 말이 있느냐 이것도 되게 중요해요.\\n\\n지금 GPT 같은 게 학습이 잘 될 수밖에 없는 게 요약 같은 거 되게 잘하거든요.\\n\\n해보면 왜 요약이 잘 되냐 하면요.\\n\\n요약은 이미 그 인터넷에 쌍이 많이 있거든요.\\n\\n제가 일일이 GPT에 만들어줄 몇 테라바이트 데이터를 일일이 질문 답변 쓰는 건 수학적으로 말이 안 돼요.\\n\\n왜냐하면 사람이 열심히 쳐봤자 제가 한 만 단어 치는 것도 힘든데 일주일 동안 근데 얘는 수백억 단어가 필요한데 그거 사람 뽑아서 한다고 되겠어요? 그게? 안 되죠.\\n\\n대부분 있는 데이터 중에 좋은 데이터를 정제해서 쓰는 게 중요해요.\\n\\n근데 예를 들면 요약 같은 거는 위키페디아 이런 거 있잖아요.\\n\\n인트로덕션 안에 사실상 요약이에요.\\n\\n그리고 밑에가 본문이잖아요.\\n\\n본문을 주고 이거 요약해줘 한 다음에 정답을 인트로덕션 같은 걸 넣어서 할 수가 있거든요.\\n\\n그런 일들은 잘 되는 거예요.\\n\\n근데 이제 예를 들면 우리가 GPT가 세상을 바꾸려면 그런 식으로 쓸 수 있는 데이터가 있는 곳이어야 적용 가능한 거예요.\\n\\n예를 들면 제가 법조계 쪽으로 GPT를 쓰고 싶고 GPT를 학습시키고 싶잖아요.\\n\\n그러면 그것도 판례랑 답이 있어야 되는데 그것도 이제 얼마나 좋은 판례인지 이런 걸 다 매겨줘야 된다는 거예요.\\n\\n그 양도 많아야 되는 거죠.\\n\\n그리고 그러고 나면 사업성 문제가 생겨요.\\n\\n그렇게 한국에서 이거 학습을 시켰는데 미국에 쓸 수 있어요, 그거? 못 쓰죠.\\n\\n미국법이 아니니까 그건.\\n\\n이거는 상장된 회사는 아닌데 세레브라스 이런 회사들이 있어요.\\n\\n정확하게는 NVIDIA GPU도 완벽한 칩은 아니에요.\\n\\n인공지능 쪽에서는 범용적이고 쓰기 편한 칩이긴 한데 얘도 한계가 있어요.\\n\\n예를 들면 지금 도는 채집 PT 같은 거 말했지만 애저 슈퍼컴퓨터의 그래픽카드 만 개를 엮었다고 했잖아요.\\n\\n근데 그렇게 엮으면 비효율도 크고 비용도 크거든요.\\n\\n그래서 이제 세레브라스 같은 회사는 그만한 GPU를 하나씩 엮을 바에 이따만한 칩을 웨이퍼 하나에 놓고 그 안에 신경망을 한 번에 다 올리자 이런 식으로 얘기를 해요.\\n\\n이거는 단일 GPU 안에 다 안 들어가서 이거를 쪼개서 담기 위한 노력도 많이 하고 그 비효율이 많거든요.\\n\\n근데 이제 그런 거대한 칩에는 신경망이 한 번에 딱 들어가죠.\\n\\n그러면 기존에 이론상으로는 할 수 있지만 GPU의 용량 한 개로 해보기 힘들었던 걸 많이 해볼 수 있어요.\\n\\n그런 칩들을 쓰면.\\n\\n저는 이제 그런 무류의 칩들을 보는 건 나쁘지 않다고 생각해요.\\n\\n정확하게 이제 조건은 두 개 있어요.\\n\\n이런 칩들이 잘 되려면 첫째로 지금 채집 PT와 비슷한데 거대한 언어모델이죠, 이게.\\n\\n내가 하려고 하는 사업 분야에 데이터가 아까 말한 형태의 데이터가 있고요.\\n\\n그런 데이터들이 풍족하고 근데 NVIDIA GPU 쓰면 원가가 좀 안 나오는 애들.\\n\\n이런 애들일 때 가능성이 있는 거예요.\\n\\n예를 들면 제가 비즈니스를 하고 싶은데 이 채집 PT 같은 거 지금 공개된 거는 한 3,000단어 정도만 입력으로 들어갈 수 있어요.\\n\\n제가 채집 PT랑 대화를 주고받는다 그러면 대화 총합이 3,000단어 넘어가면 까먹어요, 얘는.\\n\\n원래 그런 디자인인 거예요.\\n\\n근데 그거를 늘리려면 늘릴 때 데이터도 많이 필요하고요.\\n\\n늘린 다음에 사양도 훨씬 많이 먹어요.\\n\\n이제 기술 발전이 좀 있긴 하겠지만 지금 상황에서는 그 3,000단어를 6,000단어로 늘리면 4배 정도 커져요, 얘가 대충.\\n\\n연산해야 되니까 4배씩 커지게 되니까 제가 이제 사업 모델을 봤더니 아, 3,000단어는 부족하고 뭐 8만 단어까지 하고 싶다.\\n\\n이러면 NVIDIA GPU 지금 1만 개 엮어서 했는데 몇 개 엮어서 할 거예요, 그때? 100만 개 엮어서 할 건가요? 그렇게 할 수 없잖아요.\\n\\n그러면 새로운 반도체 찾는 거죠.\\n\\n그 아파트들의 검폐율을 보면 보통 17%씩 높입니다.\\n\\n땅을 20평만 지어야 돼요.\\n\\n100평 되려면 10층이 돼야 200평 나오잖아요, 그렇죠? 이 시스템만 아시면 아시면 부동산은 제가 장담하고 있는데 반은 이미 안 갑니다.\\n\\n나머지는 디테일입니다.\\n\\n이걸 정확히 모르고 저 땅이 예쁘다, 이런 거 얘기할 필요 없습니다.', metadata={})]\n",
      "전체 토큰수 11098\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RefineDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m다음 문장을 요약해주세요:\n",
      "\n",
      "인공신경망은 특징이 CPU가 잘하는 일은 아니라는 거예요.\n",
      "\n",
      "숫자가 5를 넘으면 안녕하세요 말하는 코드를 쓴다.\n",
      "\n",
      "이거는 용량 진짜로 몇 킬로바이트 안 하거든요? 근데 제가 동일한 일을 하려는 걸 인공신경망으로 만들면 용량이 몇백배 커요.\n",
      "\n",
      "NVIDIA GPU도 완벽한 칩은 아니에요.\n",
      "\n",
      "예전 슈퍼컴퓨터에 그래픽카드 만 개를 엮었다고 했잖아요.\n",
      "\n",
      "근데 그렇게 엮으면 비효율도 크고 비용도 크거든요.\n",
      "\n",
      "GPT를 통한 인공지능 변호사 이런 거 만들려면 데이터 장벽부터 있는 거예요.\n",
      "\n",
      "예전에는 PC였고 스마트폰이었고 지금은 서버인데 제 사회의 어떤 수요를 만들려면요.\n",
      "\n",
      "안녕하세요.\n",
      "\n",
      "머니인사이드 시청자 여러분 정인성 작가입니다.\n",
      "\n",
      "저는 원래 반도체 회사에서 반도체 관련한 시뮬레이션 일을 하고 있었고요.\n",
      "\n",
      "최근에 인공지능 관련해서도 새로운 책을 쓸 수 있었고요.\n",
      "\n",
      "지금은 이제 동료들이랑 인공지능 개발 쪽으로 와 있습니다.\n",
      "\n",
      "스타릿에서 어떤...\n",
      "\n",
      "반도체들을 완제품을 만들고 나면 이 반도체들을 또 뭉쳐서 그 위에다가 조그마한 컨트롤러를 붙여서 막 동작을 하게 만들어요.\n",
      "\n",
      "쉽게 말하면 원본 반도체가 아니고 반도체들을 결합해서 새로운 가치를 만드는 거죠.\n",
      "\n",
      "이제 그런 것들을 시뮬레이션으로 검증하는 그런 일들을 했죠.\n",
      "\n",
      "인공지능은 용어를 구분할 필요가 있는데 인공지능은 우리 꿈 같은 거예요.\n",
      "\n",
      "그러니까 우리가 하고 싶은 거 쉽게 말하면 이 인공지능이라는 요소가 딱 잘 정의되진 않는데 예를 들면 예전에 있던 그 바둑에 있는 바둑 AI나 그 스타크래프트에서 이제 컴퓨터 상대를 넣었어요.\n",
      "\n",
      "그런 것도 다 인공지능이라고 불러요.\n",
      "\n",
      "실제로는 그렇게 부를 수 있고요.\n",
      "\n",
      "그러니까 인공지능이라는 것 자체가 굉장히 어마어마한 개념이고 그렇진 않은 거예요.\n",
      "\n",
      "근데 이제 우리 일반인들 입장에서는 좀 터미네이터 같은 걸 생각하겠죠.\n",
      "\n",
      "인공지능으로.\n",
      "\n",
      "저 일하는 입장에서 인공지능은 어떤 물건이냐 하면요.\n",
      "\n",
      "스스로 배워요.\n",
      "\n",
      "그러니까 저는 이제 프로그래머를 짜서 뭐 컴파일을 하거나 아니면 뭐 스크립트를 실행하면 얘가 막 돌아가거든요.\n",
      "\n",
      "근데 시킨 대로 돌아가요.\n",
      "\n",
      "얘는.\n",
      "\n",
      "예를 들면 제가 정말 어렵게 엄청 힘든 건데 프로그램을 막 짜서 개랑 고양이 구분하는 프로그램을 짰다고 해볼게요.\n",
      "\n",
      "근데 이 프로그램은요.\n",
      "\n",
      "제가 그 다음에 코끼리를 어떻게 하려고 하면 다시 짜야 돼요.\n",
      "\n",
      "또.\n",
      "\n",
      "코끼리 구분하는 코드를 막 짜야 되죠.\n",
      "\n",
      "근데 이제 저는 사실 어떻게 하고 싶냐.\n",
      "\n",
      "프로그램 하나 만들어 놓고 코끼리 사진만 막 넣으면 코끼리도 구분했으면 좋겠는 거예요.\n",
      "\n",
      "프로그램이.\n",
      "\n",
      "제가 프로그램을 다시 짜는 것과 있는 프로그램 냅두고 사진만 모아서 긁어 넣는 것 중에 뭐가 쉽겠어요.\n",
      "\n",
      "사진만 넣는 게 훨씬 쉽죠.\n",
      "\n",
      "프로그램 짜라 그러면 끼약하겠지만 코끼리 사진을 1,000개 모아오라 하면 아마 즐겁게 모아올 거라고요.\n",
      "\n",
      "그냥.\n",
      "\n",
      "당연히 훨씬 쉽죠.\n",
      "\n",
      "그게.\n",
      "\n",
      "지금 말하는 인공지능에서 중요한 요소들은 그런 거예요.\n",
      "\n",
      "바둑 인공지능도 다 인공지능이고 한데 지금 우리가 중요하게 여기는 요소는 얘가 스스로 배워서 내놓는 결과를 바꾸는 물건이란 거예요.\n",
      "\n",
      "그쪽을 중요하게 봐온 게 그 인공지능인 거예요.\n",
      "\n",
      "그리고 반도체는 그거와 뭐가 관계가 있느냐.\n",
      "\n",
      "지금 제가 말씀드린 건 다 컨셉이죠.\n",
      "\n",
      "어떻게 만드는지에 대한 얘기가 없잖아요.\n",
      "\n",
      "그래서 그런 인공지능을 만드는 아이디어가 여러 개 있었어요.\n",
      "\n",
      "SVM 뭐 이런 방법도 있고 뭐 그냥 코드를 엄청 무식하게 짜보는 방법도 있고요.\n",
      "\n",
      "뭐 IBM 왓슨처럼 막 만드는 방법도 있는데 요거 다 다른 형태의 프로그램이잖아요.\n",
      "\n",
      "요 방법들 중에 제가 A라는 방법을 택하면 예를 들어 CPU가 빨라야 되고 메모리는 적어도 되고 B라는 방법을 쓰면 CPU보다 메모리가 중요하고 요런 식으로 바뀌어요.\n",
      "\n",
      "왜냐하면 프로그램도 그냥 CPU에서 도는 게 아니고요.\n",
      "\n",
      "CPU가 잘하는 일 중심으로 프로그램을 짜야 빠른 거잖아요.\n",
      "\n",
      "그게 반도체랑 인공지능 기술의 핵심인 거예요.\n",
      "\n",
      "우리는 인공지능이라는 추상적인 개념을 만들고 싶고요.\n",
      "\n",
      "그래서 그 추상적인 개념이 돌아가게 하기 위해서 여러 가지 아이디어를 쓰는 거예요.\n",
      "\n",
      "그중에 지금 제일 잘 되는 게 인공신경망이라는 개념이에요.\n",
      "\n",
      "인간의 뇌세포 구조를 좀 따라해서 그 신경망을 이제 우리 학습시킨 방법을 알아냈기 때문에 학습시키면은 우리가 원하던 인공지능 스스로 뭐 배우고 뭐 진짜 의미로 스스로 배우진 않죠 이제.\n",
      "\n",
      "우리가 코드를 다시 짜지 않아도 데이터만 넣어서 다시 학습시키면 원하는 결과 나오고 그런 걸 할 수 있는 게 이제 인공신경망이에요.\n",
      "\n",
      "근데 이 인공신경망은 특징이 CPU가 잘하는 일은 아니라는 거예요 얘가.\n",
      "\n",
      "그러니까 이제 기존에 CPU만 우리 90년대, 2000년대 CPU만 있었는데 지금 NVIDIA GPU를 쓰는 거예요.\n",
      "\n",
      "우리에겐 하고 싶은 일이 있고 그중에 그 일을 제일 잘하는 방법론을 찾아요.\n",
      "\n",
      "어떤 방식으로 프로그램을 만들어야 스스로 잘 배우는 프로그램이 된다.\n",
      "\n",
      "그리고 그 프로그램들은 각자 원하는 반도체가 달라요.\n",
      "\n",
      "그 일을 잘할 수 있는 반도체가 다르죠.\n",
      "\n",
      "그렇게 움직이는 거예요.\n",
      "\n",
      "CPU와 GPU의 큰 차이가? 사실 둘 다 메모리가 아니고 연산용 칩인데 CPU라는 거는 그 조건 파악을 잘해요.\n",
      "\n",
      "예를 들면 제 입장에서 머니인사이드의 시청자가 몇 명 이상이면 참여하고 아니면은 출연하지 마라.\n",
      "\n",
      "이런 식으로 그 조건이 있으면 선택을 하는 거잖아요.\n",
      "\n",
      "이런 식의 일을 되게 잘해요.\n",
      "\n",
      "그게 그 CPU가 잘하는 일이고요.\n",
      "\n",
      "그리고 GPU는 뭘 잘하냐 하면은 숫자 계산을 엄청 잘해요 그냥.\n",
      "\n",
      "0.1 곱하기 0.4 뭐 이런 숫자를 뭐 수만 개 계산하는 걸 엄청 잘해요.\n",
      "\n",
      "근데 우리가 과거에 봤던 수많은 프로그램들은요.\n",
      "\n",
      "앞에 말했던 조건이 중요해요.\n",
      "\n",
      "예를 들면 엑셀이잖아요.\n",
      "\n",
      "제가 엑셀 칸에다가 함수를 넣으면 만약 함수가 sum이면은 더해라.\n",
      "\n",
      "이런 거죠.\n",
      "\n",
      "이렇게 조건이잖아요 다.\n",
      "\n",
      "그래서 그런 걸 잘하게 설계되어 있어요 CPU는.\n",
      "\n",
      "근데 인공신경만 어떻게 돌아가냐 하면 그냥 입력값을 다 소수점으로 바꾼 다음에 소수점 곱셈을 엄청나게 해요.\n",
      "\n",
      "한국어 문장요약 결과:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m당신의 임무는 최종 요약을 작성하는 것입니다\n",
      "특정 지점까지 기존 요약을 제공했습니다: 인공신경망은 CPU가 잘하는 일이 아니며, 인공지능 개발에는 데이터가 필요하다. 인공신경망은 용량이 크고, NVIDIA GPU도 완벽한 칩은 아니며, 인공지능을 만들기 위해서는 여러 가지 아이디어를 사용한다. 인공신경망은 CPU보다는 GPU를 사용하며, 인공신경망은 입력값을 소수점으로 바꾼 다음 소수점 곱셈을 많이 사용한다.\n",
      "기존 요약을 다듬을 기회가 있습니다.(필요한 경우에만) 아래에 더 많은 컨텍스트를 추가할 수 있습니다.\n",
      "------------\n",
      "앞에 말했던 조건이 중요해요.\n",
      "\n",
      "예를 들면 엑셀이잖아요.\n",
      "\n",
      "제가 엑셀 칸에다가 함수를 넣으면 만약 함수가 sum이면은 더해라.\n",
      "\n",
      "이런 거죠.\n",
      "\n",
      "이렇게 조건이잖아요 다.\n",
      "\n",
      "그래서 그런 걸 잘하게 설계되어 있어요 CPU는.\n",
      "\n",
      "근데 인공신경만 어떻게 돌아가냐 하면 그냥 입력값을 다 소수점으로 바꾼 다음에 소수점 곱셈을 엄청나게 해요.\n",
      "\n",
      "곱셈, 넛셈을 뭐 수억 번씩 하면 결과가 나오는데 그러면은 결과가 잘 나오는 그런 물건이에요.\n",
      "\n",
      "그러니까 어떻게 보면 인간이 조건을 하나씩 넣어주는 형태 프로그램에서 그냥 모두 다 숫자로 바꿔서 숫자로 와장창 곱하면은 이제 원하는 결과가 튀어나오는 좀 신기한 상황이 된 거죠.\n",
      "\n",
      "Q.\n",
      "\n",
      "인공지능 기술은 어떻게 변화할까요? 어떻게 보면 CPU가 좀 더 똑똑한 칩인데 우리가 지금 보는 인공지능 기술은 좀 무식한 방식으로 좀 더 나은 지성이 구현되어 있는 그런 모습이에요.\n",
      "\n",
      "숫자가 인공지능이 돌아가는 원리? 그러니까 인간 머리가 일단 그런 식으로 돌아가잖아요.\n",
      "\n",
      "왜냐하면 인간 유전자 안에 CPU 설계가 들어있겠어요? 그런 복잡한 설계가 있을까요? 인간 안에? 그 CPU 안에는 그 수십억 개 트랜지스터가 막 연결되어 있는 설계도가 있는데 인간은 그렇지 않잖아요.\n",
      "\n",
      "그래서 뇌세포들은 다 보면은 특정 뇌세포에 자극이 들어오면 인접한 뇌세포에다가 특정 그 역치값을 넘으면 자극을 전달하고 역치를 안 넘으면 자극을 안 전달하고 이렇게 돼 있어요.\n",
      "\n",
      "그 연결관계를 수조개 모아놓으면 지성이 되는 거잖아요.\n",
      "\n",
      "그리고 과거에는 문제가 뭐였냐면은 어 그러면 우리 인간 뇌 모습을 좀 따라해서 이렇게 막 연결하면 지성이 나올 거야.\n",
      "\n",
      "이론상.\n",
      "\n",
      "그 문제는 뭐냐? 이 연결이 예를 들면 A라는 뇌세포랑 B라는 뇌세포 사이 연결을 얼마나 강하게 전달해줘야 돼? 이런 걸 하나도 모르는 거예요.\n",
      "\n",
      "그러니까 우리가 앞에서 말한 프로그래밍이라는 개념은 아까 말한 것처럼 조건문을 쓰는 거였는데 이제는 그 세포와 세포 사이 연결 강도가 0.1이냐 0.3이냐 이런 거를 고민해야 되는 상황이 된 거예요.\n",
      "\n",
      "그 문제가 뭐겠어요? 수십억 개가 있는데 그중에 이거 세포 하나 딱 해서 얘네 둘 사이가 이게 영향을 뭘 주는 거야? 하면 그걸 알아내겠냐는 거예요.\n",
      "\n",
      "그걸 알 수가 없잖아요.\n",
      "\n",
      "그래서 오랫동안 힘들었던 거예요.\n",
      "\n",
      "인공지능, 인간 뇌세포를 따라해보자는 아이디어가 뭐 그렇게 참신한가요 이게? 60년대에 이미 나왔던 아이디어예요.\n",
      "\n",
      "근데 왜 사장 되고 이제야 떠올랐냐? 그때는 어 그래 이렇게 하면 될 것 같은데 정확하게는 뇌세포와 뇌세포의 연결관계를 어떻게 해줘야 얘가 잘 돌아가는지를 몰랐던 거야.\n",
      "\n",
      "그러니까 몇십 년을 쉰 거죠.\n",
      "\n",
      "이제 몇십 년 동안 그래서 아무도 못 해보고 있다가 캐나다 쪽에서 이제 그거 학습시키는 방법을 알아낸 거예요 그때.\n",
      "\n",
      "아 여기 데이터를 넣고 결과 값에서 어떤 식으로 계산을 해주면 인공신경망이 서서히 정답률이 올라가게 만들 수 있다.\n",
      "\n",
      "요거를 알아냈어요 그때.\n",
      "\n",
      "그 방법을 써보니까 GPU를 써야 빨라요.\n",
      "\n",
      "그렇게 해서 지금의 상황이 된 거예요 이건.\n",
      "\n",
      "쉽게 말하면 프로그램 쓰는 방법이 바뀌어버린 거예요.\n",
      "\n",
      "기존에는 프로그램 쓸 때 제가 순서도를 놓고 이 순서도를 잘못 자면 버그고 그랬는데요.\n",
      "\n",
      "지금은 인공신경망을 크게 구성을 해놓고 그 안에서 값이 정답을 낼 수 있는 형태로 그 수많은 소수점을 바꿔가야 되는 거예요.\n",
      "\n",
      "그래서 GPU가 필요한 거죠.\n",
      "\n",
      "Q.\n",
      "\n",
      "인공신경망을 어떻게 만들어야 할까요? 원래 옛날 게임들은 화면에 표시하는 거랑 게임의 움직임들 표시하는 걸 전부 CPU가 했어요.\n",
      "\n",
      "근데 이제 컴퓨터라는 게 PC라는 게 나오고 계속 유행하다 보니까 사람들이 점점 더 높은 그래픽을 원해요.\n",
      "\n",
      "점점 더 그래픽 좋은 게임도 하고 싶고 영화도 만들고 싶고 이런 거예요.\n",
      "\n",
      "근데 말씀드렸지만 CPU는 분기 처리를 잘해요.\n",
      "\n",
      "조건 처리를 잘하죠.\n",
      "\n",
      "근데 고급 그래픽을 계속 해보니까 이게 CPU에 잘 맞지 않았던 거예요.\n",
      "\n",
      "그래서 CPU에 잘 맞지 않으니까 VGA라고 부르는 그래픽 전용 칩을 만들어서 쉽게 말하면 이런 거예요.\n",
      "\n",
      "제가 여기 인테리어를 해야 되는데 인테리어 디자인도 하고 벽지도 붙이고 청소도 다 했는데 이제는 CPU가 GPU라고 부르는 협력사를 데려와서 저는 여기는 도배하고 여기는 청소하고 시켜놓으면 이걸 하고 가게 하는 거예요.\n",
      "\n",
      "그리고 저는 이제 앉아서 계속 다음번 도배해야 될 거 찾고 있고요.\n",
      "\n",
      "GPU라는 녀석이 와서 도배 같은 일을 해주는 거예요.\n",
      "\n",
      "이 GPU는 제가 하는 일은 잘 못하지만 제가 잘 못하는 걸 잘하는 거죠.\n",
      "\n",
      "결국은 CPU라는 칩이 모든 일을 잘하기에는 한계가 있었던 거예요.\n",
      "\n",
      "왜냐하면 CPU가 아까 말한 조건문 처리를 잘하려면 그쪽에다 소자를 써야 되는데 거기에 소자를 쓰면은 다른 쪽에 쓸 소자가 없잖아요, 제조할 때.\n",
      "\n",
      "그러니까 모든 걸 잘할 수 없으니까 생겨난 일이죠.\n",
      "\n",
      "다행스럽게도 엔비디아가 의도한 바는 아니겠죠, 아마.\n",
      "\n",
      "인공지능 기술을 해내기 위해서 여러 연구를 하는데 제일 잘 되는 기술이 그래픽이랑 비슷한 연산을 요구했던 거예요.\n",
      "\n",
      "제가 그래픽 돌아가는 거...\n",
      "\n",
      "예, 왜냐하면 그래픽도 결국 소수점 많이 곱하고 더하고 하는 거예요.\n",
      "\n",
      "살짝 얻어걸린 느낌도 있죠, 이거는.\n",
      "\n",
      "그래픽을 했는데 회사가 계속 커야 되니까 CPU는 못하고 GPU는 잘하는 일을 계속 찾아다녔어요, 이 회사가.\n",
      "\n",
      "어, 이게 잘 될 거야 라는 그런 느낌으로 바로 가서 2006년, 2007년에 막 질른 게 아니고 전 세계 사람들이 좀 GPU를 쓰기 편하게 이제 CUDA 이런 걸 만들어놨어요.\n",
      "\n",
      "그러니까 엔비디아 생각이 이런 거예요.\n",
      "\n",
      "아, 이게 그래픽에만 쓰진 않겠지.\n",
      "\n",
      "뭐 슈퍼컴퓨터나 시뮬레이션에도 쓸 수 있고 그래서 그 물리연산하는 회사를 인수하기도 하고 그랬어요.\n",
      "\n",
      "근데 이제 그런 걸 그냥 만들어놓고 칩 쓰세요 라고 하면은 쓰는 법을 몰라요, 사람들이.\n",
      "\n",
      "왜냐하면 제가 CPU용으로 프로그램 짜던 사람이 GPU용으로 프로그램 짜려고 하면 진입장벽이 꽤 높거든요.\n",
      "------------\n",
      "새로운 문맥이 주어지면, 원래 요약을 한국어로 수정하세요.문맥이 유용하지 않은 경우 원래 요약을 반환합니다.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m당신의 임무는 최종 요약을 작성하는 것입니다\n",
      "특정 지점까지 기존 요약을 제공했습니다: 인공신경망은 CPU보다는 GPU를 사용하며, 입력값을 소수점으로 바꾼 다음 소수점 곱셈을 많이 사용한다. 인공지능 개발에는 데이터가 필요하며, 인공신경망은 용량이 크고 NVIDIA GPU도 완벽한 칩은 아니다. 인공지능을 만들기 위해서는 여러 가지 아이디어를 사용한다. 인공신경망은 CPU가 잘하는 일이 아니며, 인공지능 기술은 CPU가 아닌 GPU와 같은 칩을 사용해야 한다. 인공신경망은 인간 뇌세포를 모방한 것이며, 연결관계를 수조개 모아놓으면 지성이 된다. 인공신경망을 만들기 위해서는 GPU를 사용하는 것이 좋으며, GPU를 사용하는 방법을 익히는 것이 중요하다.\n",
      "기존 요약을 다듬을 기회가 있습니다.(필요한 경우에만) 아래에 더 많은 컨텍스트를 추가할 수 있습니다.\n",
      "------------\n",
      "아, 이게 그래픽에만 쓰진 않겠지.\n",
      "\n",
      "뭐 슈퍼컴퓨터나 시뮬레이션에도 쓸 수 있고 그래서 그 물리연산하는 회사를 인수하기도 하고 그랬어요.\n",
      "\n",
      "근데 이제 그런 걸 그냥 만들어놓고 칩 쓰세요 라고 하면은 쓰는 법을 몰라요, 사람들이.\n",
      "\n",
      "왜냐하면 제가 CPU용으로 프로그램 짜던 사람이 GPU용으로 프로그램 짜려고 하면 진입장벽이 꽤 높거든요.\n",
      "\n",
      "그래서 엔비디아는 그걸 조금이나마 좀 편하게 해주려고 CUDA 이런 것들을 마련을 해놓은 거죠.\n",
      "\n",
      "근데 그걸 마련해놓은 상황이 이거 쉽게 말하면 캐나다에서 집어다 써본 거에 가까워요.\n",
      "\n",
      "어, 그랬더니 연산속도가 5배 빨라졌어요.\n",
      "\n",
      "뭐 이런 식으로 결과가 나오니까 이제 옆방 대학원생이 이걸로 한 달에 하나 쓰던 논문을 한 달에 5개씩 쓰고 있으면 그러면 나도 써야 되고 그럼 그 옆방 대학원생도 쓰고 할 거잖아요, 당연히.\n",
      "\n",
      "근데 이게 굉장히 반도체 비즈니스에서 사실은 중요한 요소예요.\n",
      "\n",
      "옆사람이 썼는데 안 되던 게 됐잖아요.\n",
      "\n",
      "그러면 그걸 본 옆사람이 쓰죠.\n",
      "\n",
      "그러면 이제 이걸 잘 쓴 사람이 논문 찍어내면서 유명해지죠.\n",
      "\n",
      "그러면 어느 순간 그게 거대한 프로그래머 집단으로 변해요.\n",
      "\n",
      "그러면 이제 지금 2023년 상황에서 제가 대학원 갓 졸업하고 논문 써야 되는데 인공지능으로 논문을 써야 되겠는데 그러면 컴퓨터를 마련하는데 뭘 마련할 거냐 이거예요.\n",
      "\n",
      "전 지금 하나도 안 해봤으니까 일단 남들 하는 걸 다 모방해야 된다니까요.\n",
      "\n",
      "남들 쓰는 컴퓨터 사고 그럼 당연히 엔비디아 GPU 들어가요.\n",
      "\n",
      "그리고 인공지능 한 번도 안 돌려봤으니까 인터넷에 돈을 오픈소스를 받아다가 인공지능을 돌려봐야 돼요.\n",
      "\n",
      "그 오픈소스는 뭘로 쓰여 있겠어요.\n",
      "\n",
      "이것도 엔비디아 GPU를 전제하고 써놨다고요 코드를.\n",
      "\n",
      "그러니까 AMD가 못하는 거예요.\n",
      "\n",
      "이거를 AMD 그래픽 카드로 이제 뭔가 해보려고 실제 실험은 하지도 못하는 거예요.\n",
      "\n",
      "제가 근데 엔비디아 거 쓰면 물어보면 되잖아요.\n",
      "\n",
      "야 넌 어떻게 했니? 이렇게.\n",
      "\n",
      "그게 그 반도체 비즈니스에서 되게 중요한 거예요.\n",
      "\n",
      "생태계예요 이게.\n",
      "\n",
      "어떻게 보면 메모리 같은 건 그런 생태계가 좀 약하고요.\n",
      "\n",
      "인텔의 CPU 같은 것도 그런 생태계를 가지고 있잖아요.\n",
      "\n",
      "그러니까 한참 동안 인텔 CPU가 지금도 그렇게 힘들어해도 살아있는 거예요.\n",
      "\n",
      "여기에 맞춰진 프로그램이 많으니까.\n",
      "\n",
      "반도체 시장은 이제 당분간은 거대 신경망 특히 자연화 신경망이 잘 된다고 했으니까 아마 그쪽 연구개발 수요는 올라갈 거예요.\n",
      "\n",
      "근데 연구개발 이상으로 이제 꾸준한 수요를 만들어내려면 많은 부분에서는 연구를 해봐야 된다고 생각해요.\n",
      "\n",
      "왜냐하면 지금 신경망 학습시키는 게 장점만 있는 건 아니에요.\n",
      "\n",
      "단점은 얘가 인간이랑 제일 큰 차이점이 데이터 한 두 개 보고 학습이 안 된다는 거예요.\n",
      "\n",
      "예를 들면 여기 버닝사이드 시청자 여러분은 영상을 만 개씩 봐야 특정 테마를 익힐 수 있는 것이 아니잖아요.\n",
      "\n",
      "하나만 봐도 익히죠.\n",
      "\n",
      "근데 인공지능은 문제와 정답상 하나 가지고 배울 수가 없고 엄청 많이 봐야 돼요.\n",
      "\n",
      "GPT를 통한 인공지능 변호사 이런 거 만들려면 일단 데이터 장벽부터 있는 거예요.\n",
      "\n",
      "질문과 정답상이 충분히 있냐.\n",
      "\n",
      "그런 것들이 지금은 다 조사가 안 돼 있고 이제야 사람들을 찾아보는 중일 거잖아요.\n",
      "\n",
      "그러니까 저는 당분간은 연구개발 수요는 크겠지만 이게 정말 세상을 바꿀 만큼 여기저기 적용될 건지 아니면 마이크로소프트만 자기들 검색엔진과 오피스에 쓸 건지 이거는 저는 좀 봐야 된다고 생각해요.\n",
      "\n",
      "우리나라의 발표체는 어떻게 쓰일 것인가요? 일단 제일 크게 쓰이는 건 역시 메모리죠.\n",
      "\n",
      "인공신경망의 특징 중 하나는요.\n",
      "\n",
      "CPU용으로 짠 프로그램보다 용량이 엄청나게 크다는 거예요.\n",
      "\n",
      "정말 코드를 잘 짜서 숫자가 5를 넘으면 뭐 안녕하세요 말하는 코드를 쓴다.\n",
      "\n",
      "이거는 용량 진짜로 몇 킬로바이트 안 하거든요.\n",
      "\n",
      "근데 제가 동일한 일을 하려는 걸 인공신경망으로 만들면 용량이 몇백배 커요, 실제로는.\n",
      "\n",
      "그래서 메모리 중에 고용량, 고대역폭 메모리가 중요한 거예요, 지금.\n",
      "\n",
      "일단 한국에서 제일 주요하게 팔리는 것들은 인공지능 쪽에 그 HBM 같은 고용량 고속 메모리들이죠.\n",
      "\n",
      "그쪽에서 확실히 수요가 있다고 봐야죠.\n",
      "\n",
      "그러니까 이런 느낌이에요.\n",
      "\n",
      "예를 들면 제가 CPU 프로그램에다가 1 더하기 1을 계산하게 시키면 프로그램 용량 해봤자 얼마나 하겠어요.\n",
      "\n",
      "근데 저한테 1 더하기 1 물어보고 MRI 찍으면 순식간에 뻘겋뻘겋해졌다가 없어진다고요.\n",
      "\n",
      "되게 비율적이잖아요, 그렇게 보면.\n",
      "\n",
      "용량이 크다니까요, 그렇게.\n",
      "\n",
      "여기 뇌세포 하나하나로 옮겨 놓는 거잖아요.\n",
      "\n",
      "1 더하기 1을 하기 위해서 뇌세포를 거쳐가는 신호의 개수가 뭐 3개겠냐 이거예요.\n",
      "\n",
      "1 더하기 1은 2.\n",
      "\n",
      "3개 들어가면 한 개 답이 나오는 게 아니고 수백억 개가 막 여기서 반응을 하잖아요.\n",
      "\n",
      "그거를 재현해야 되는 거잖아요, 컴퓨터의 내부에 맞춰서.\n",
      "\n",
      "고용량 메모리가 필요할 텐데 당장 물량을 딱 고민해보면 마이크로소프트 엣저이 슈퍼컴퓨터가 엔비디아 V100인가 하는 학습용 GPU를 만 개인가 엮었거든요.\n",
      "\n",
      "근데 이거 만 개 엮으면 이게 메모리 용량이 40만 기가바이트 그래요.\n",
      "\n",
      "엄청 큰 것 같지만 우리 평균 스마트폰에 8기가 들어가잖아요.\n",
      "\n",
      "8기가 들어가면 이거 2만 개 팔아도 스마트폰으로 한 5배? 40이랑 8이니까 5배죠? 그러면 스마트폰 판매량으로는 한 10만 개 정도 되겠네요.\n",
      "\n",
      "근데 스마트폰 1년에 10억 개 팔잖아요, 전 세계에.\n",
      "\n",
      "그러니까 이것만으로는 물량이 엄청 크지 않다는 얘기를 하는 거예요.\n",
      "\n",
      "엣저이 슈퍼컴퓨터 1년에 한 100개씩 팔아도 전체 메모리 물량에서 크진 않죠.\n",
      "\n",
      "물론 메모리 용량된 단가는 크게 쳐주겠지만.\n",
      "\n",
      "그래서 이게 GPT 같은 게 메모리 시장에 예전에는 PC였고, 스마트폰이었고, 지금은 서버인데 제사의 어떤 수요를 만들려면요.\n",
      "\n",
      "지금 연구개발 수요로 안 된다는 이야기를 하는 거예요.\n",
      "\n",
      "연구개발 수요 말고 꾸준히 사용되는 수요가 있어야 되는데 왜냐하면 연구개발하는 건 결국 한 번 사고 잘 안 되면 버릴 거잖아요.\n",
      "------------\n",
      "새로운 문맥이 주어지면, 원래 요약을 한국어로 수정하세요.문맥이 유용하지 않은 경우 원래 요약을 반환합니다.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m당신의 임무는 최종 요약을 작성하는 것입니다\n",
      "특정 지점까지 기존 요약을 제공했습니다: 인공신경망은 CPU보다는 GPU를 사용하며, 입력값을 소수점으로 바꾼 다음 소수점 곱셈을 많이 사용한다는 것이 기존 요약이었다. 인공지능 개발에는 데이터가 필요하며, 인공신경망은 용량이 크고 NVIDIA GPU도 완벽한 칩은 아니다. 인공신경망은 인간 뇌세포를 모방한 것이며, 연결관계를 수조개 모아놓으면 지성이 된다. 인공신경망을 만들기 위해서는 GPU를 사용하는 것이 좋으며, GPU를 사용하는 방법을 익히는 것이 중요하다는 것이다. 추가적으로, 인공지능을 만들기 위해서는 여러 가지 아이디어를 사용하며, 인공신경망은 CPU가 잘하는 일이 아니며, 인공지능 기술은 CPU가 아닌 GPU와 같은 칩을 사용해야 한다는 것이다. 또한, 메모리 중에 고용량, 고대역폭 메모리가 중요하며, 인공신경망의 용량이 크기 때문에 메모리 용량이 큰 것이 필요하다는 것이다.\n",
      "기존 요약을 다듬을 기회가 있습니다.(필요한 경우에만) 아래에 더 많은 컨텍스트를 추가할 수 있습니다.\n",
      "------------\n",
      "그래서 이게 GPT 같은 게 메모리 시장에 예전에는 PC였고, 스마트폰이었고, 지금은 서버인데 제사의 어떤 수요를 만들려면요.\n",
      "\n",
      "지금 연구개발 수요로 안 된다는 이야기를 하는 거예요.\n",
      "\n",
      "연구개발 수요 말고 꾸준히 사용되는 수요가 있어야 되는데 왜냐하면 연구개발하는 건 결국 한 번 사고 잘 안 되면 버릴 거잖아요.\n",
      "\n",
      "근데 꾸준히 써야 되면 연구개발용도 계속 사고 상업용으로도 계속 사야 되니까 수요가 꾸준히 늘어나죠.\n",
      "\n",
      "근데 그걸 알려면 사실 메모리 시장이나 엔비디아를 볼 게 아니고 우리가 GPT 같은 걸로 하고 싶은 사업모델 중에 데이터들의 쌍이 잘 갖춰져 있는 곳이 있나 그거를 알아야 답을 할 수 있다는 얘기인 거예요.\n",
      "\n",
      "전 그래서 지금은 그걸로 메모리 시장이 확 바뀔 거다 그렇게까지는 기대하지 않아요.\n",
      "\n",
      "지금 인공지능은요.\n",
      "\n",
      "우리가 좀 이렇게 착각들을 하는 게 인터넷에는 데이터가 무한하니까 그냥 데이터 넣으면 똑똑해지겠네 라고 생각하거나 그렇지가 않아요.\n",
      "\n",
      "예를 들어서 제가 개와 고양이를 구분시켜야 된다고 하면 사진만 넣는 게 아니라 사진에 개라고 써놔야 돼요.\n",
      "\n",
      "고양이 사진 고양이라고 써놔야 되고요.\n",
      "\n",
      "그렇게 질문과 정답 쌍이 있어야 배울 수 있는 거예요.\n",
      "\n",
      "사진은 그래도 좀 쉽죠.\n",
      "\n",
      "이거 뭐 사람 몇 명 쓰면 사진 100만 개 만들 수 있을 거예요.\n",
      "\n",
      "근데 말하는 인공지능은 어떨까요? 이거 질문과 대답 쌍을 만들기 쉬울까요? 우리 인터넷에 글을 그냥 긁으면 질문과 대답 쌍이 충분히 많이 나올까요? 그러니까 그 안에서는 질문과 대답 쌍 자체를 찾는 것도 되게 어렵고요.\n",
      "\n",
      "그리고 그중에 신뢰할 수 있는 말이 있느냐 이것도 되게 중요해요.\n",
      "\n",
      "지금 GPT 같은 게 학습이 잘 될 수밖에 없는 게 요약 같은 거 되게 잘하거든요.\n",
      "\n",
      "해보면 왜 요약이 잘 되냐 하면요.\n",
      "\n",
      "요약은 이미 그 인터넷에 쌍이 많이 있거든요.\n",
      "\n",
      "제가 일일이 GPT에 만들어줄 몇 테라바이트 데이터를 일일이 질문 답변 쓰는 건 수학적으로 말이 안 돼요.\n",
      "\n",
      "왜냐하면 사람이 열심히 쳐봤자 제가 한 만 단어 치는 것도 힘든데 일주일 동안 근데 얘는 수백억 단어가 필요한데 그거 사람 뽑아서 한다고 되겠어요? 그게? 안 되죠.\n",
      "\n",
      "대부분 있는 데이터 중에 좋은 데이터를 정제해서 쓰는 게 중요해요.\n",
      "\n",
      "근데 예를 들면 요약 같은 거는 위키페디아 이런 거 있잖아요.\n",
      "\n",
      "인트로덕션 안에 사실상 요약이에요.\n",
      "\n",
      "그리고 밑에가 본문이잖아요.\n",
      "\n",
      "본문을 주고 이거 요약해줘 한 다음에 정답을 인트로덕션 같은 걸 넣어서 할 수가 있거든요.\n",
      "\n",
      "그런 일들은 잘 되는 거예요.\n",
      "\n",
      "근데 이제 예를 들면 우리가 GPT가 세상을 바꾸려면 그런 식으로 쓸 수 있는 데이터가 있는 곳이어야 적용 가능한 거예요.\n",
      "\n",
      "예를 들면 제가 법조계 쪽으로 GPT를 쓰고 싶고 GPT를 학습시키고 싶잖아요.\n",
      "\n",
      "그러면 그것도 판례랑 답이 있어야 되는데 그것도 이제 얼마나 좋은 판례인지 이런 걸 다 매겨줘야 된다는 거예요.\n",
      "\n",
      "그 양도 많아야 되는 거죠.\n",
      "\n",
      "그리고 그러고 나면 사업성 문제가 생겨요.\n",
      "\n",
      "그렇게 한국에서 이거 학습을 시켰는데 미국에 쓸 수 있어요, 그거? 못 쓰죠.\n",
      "\n",
      "미국법이 아니니까 그건.\n",
      "\n",
      "이거는 상장된 회사는 아닌데 세레브라스 이런 회사들이 있어요.\n",
      "\n",
      "정확하게는 NVIDIA GPU도 완벽한 칩은 아니에요.\n",
      "\n",
      "인공지능 쪽에서는 범용적이고 쓰기 편한 칩이긴 한데 얘도 한계가 있어요.\n",
      "\n",
      "예를 들면 지금 도는 채집 PT 같은 거 말했지만 애저 슈퍼컴퓨터의 그래픽카드 만 개를 엮었다고 했잖아요.\n",
      "\n",
      "근데 그렇게 엮으면 비효율도 크고 비용도 크거든요.\n",
      "\n",
      "그래서 이제 세레브라스 같은 회사는 그만한 GPU를 하나씩 엮을 바에 이따만한 칩을 웨이퍼 하나에 놓고 그 안에 신경망을 한 번에 다 올리자 이런 식으로 얘기를 해요.\n",
      "\n",
      "이거는 단일 GPU 안에 다 안 들어가서 이거를 쪼개서 담기 위한 노력도 많이 하고 그 비효율이 많거든요.\n",
      "\n",
      "근데 이제 그런 거대한 칩에는 신경망이 한 번에 딱 들어가죠.\n",
      "\n",
      "그러면 기존에 이론상으로는 할 수 있지만 GPU의 용량 한 개로 해보기 힘들었던 걸 많이 해볼 수 있어요.\n",
      "\n",
      "그런 칩들을 쓰면.\n",
      "\n",
      "저는 이제 그런 무류의 칩들을 보는 건 나쁘지 않다고 생각해요.\n",
      "\n",
      "정확하게 이제 조건은 두 개 있어요.\n",
      "\n",
      "이런 칩들이 잘 되려면 첫째로 지금 채집 PT와 비슷한데 거대한 언어모델이죠, 이게.\n",
      "\n",
      "내가 하려고 하는 사업 분야에 데이터가 아까 말한 형태의 데이터가 있고요.\n",
      "\n",
      "그런 데이터들이 풍족하고 근데 NVIDIA GPU 쓰면 원가가 좀 안 나오는 애들.\n",
      "\n",
      "이런 애들일 때 가능성이 있는 거예요.\n",
      "\n",
      "예를 들면 제가 비즈니스를 하고 싶은데 이 채집 PT 같은 거 지금 공개된 거는 한 3,000단어 정도만 입력으로 들어갈 수 있어요.\n",
      "\n",
      "제가 채집 PT랑 대화를 주고받는다 그러면 대화 총합이 3,000단어 넘어가면 까먹어요, 얘는.\n",
      "\n",
      "원래 그런 디자인인 거예요.\n",
      "\n",
      "근데 그거를 늘리려면 늘릴 때 데이터도 많이 필요하고요.\n",
      "\n",
      "늘린 다음에 사양도 훨씬 많이 먹어요.\n",
      "\n",
      "이제 기술 발전이 좀 있긴 하겠지만 지금 상황에서는 그 3,000단어를 6,000단어로 늘리면 4배 정도 커져요, 얘가 대충.\n",
      "\n",
      "연산해야 되니까 4배씩 커지게 되니까 제가 이제 사업 모델을 봤더니 아, 3,000단어는 부족하고 뭐 8만 단어까지 하고 싶다.\n",
      "\n",
      "이러면 NVIDIA GPU 지금 1만 개 엮어서 했는데 몇 개 엮어서 할 거예요, 그때? 100만 개 엮어서 할 건가요? 그렇게 할 수 없잖아요.\n",
      "\n",
      "그러면 새로운 반도체 찾는 거죠.\n",
      "\n",
      "그 아파트들의 검폐율을 보면 보통 17%씩 높입니다.\n",
      "\n",
      "땅을 20평만 지어야 돼요.\n",
      "\n",
      "100평 되려면 10층이 돼야 200평 나오잖아요, 그렇죠? 이 시스템만 아시면 아시면 부동산은 제가 장담하고 있는데 반은 이미 안 갑니다.\n",
      "\n",
      "나머지는 디테일입니다.\n",
      "\n",
      "이걸 정확히 모르고 저 땅이 예쁘다, 이런 거 얘기할 필요 없습니다.\n",
      "------------\n",
      "새로운 문맥이 주어지면, 원래 요약을 한국어로 수정하세요.문맥이 유용하지 않은 경우 원래 요약을 반환합니다.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# refine\n",
    "# https://python.langchain.com/en/latest/reference/modules/text_splitter.html\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain import OpenAI, PromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.docstore.document import Document\n",
    "from pprint import pprint\n",
    "import tiktoken\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "\n",
    "\n",
    "with open('./정인성작가_transcript.txt', 'r', encoding='utf-8') as f:\n",
    "    transcript = f.read()\n",
    "\n",
    "transcript = transcript.replace('. ', '.\\n\\n')\n",
    "enc35 = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "# tokenized_text_chatgpt35 = enc35.encode(transcript)\n",
    "# print(len(tokenized_text_chatgpt35))\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=3000, chunk_overlap=200)\n",
    "texts = text_splitter.split_text(transcript) # 문장 분리 길이 4000 미만 및 chunk_overlap 200\n",
    "docs = [Document(page_content=t) for t in texts]\n",
    "pprint(docs)\n",
    "\n",
    "# 나뉜 문단별 토큰수 계산\n",
    "tmp_tok = 0\n",
    "for doc in docs:\n",
    "    tokenized_text_chatgpt35 = enc35.encode(doc.page_content)\n",
    "    # print(len(tokenized_text_chatgpt35))\n",
    "    tmp_tok += len(tokenized_text_chatgpt35)\n",
    "print('전체 토큰수', tmp_tok)\n",
    "\n",
    "# 템플릿 작성\n",
    "############################################################################################################\n",
    "prompt_template = \"\"\"다음 문장을 요약해주세요:\n",
    "\n",
    "{text}\n",
    "\n",
    "한국어 문장요약 결과:\n",
    "\"\"\"\n",
    "############################################################################################################\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "refine_template = (\n",
    "    \"당신의 임무는 최종 요약을 작성하는 것입니다\\n\"\n",
    "    \"특정 지점까지 기존 요약을 제공했습니다: {existing_answer}\\n\"\n",
    "    \"기존 요약을 다듬을 기회가 있습니다.\"\n",
    "    \"(필요한 경우에만) 아래에 더 많은 컨텍스트를 추가할 수 있습니다.\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"{text}\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"새로운 문맥이 주어지면, 원래 요약을 한국어로 수정하세요.\"\n",
    "    \"문맥이 유용하지 않은 경우 원래 요약을 반환합니다.\"\n",
    ")\n",
    "refine_prompt = PromptTemplate(\n",
    "    input_variables=[\"existing_answer\", \"text\"],\n",
    "    template=refine_template,\n",
    ")\n",
    "\n",
    "# 모든 데이터에 한번에 엑세스 하므로 전체 토큰이 \n",
    "llmc = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\") # chatgpt 3.5 model\n",
    "chain = load_summarize_chain(llmc, \n",
    "                             chain_type=\"refine\",  # refine 방식\n",
    "                             return_intermediate_steps=True,\n",
    "                             question_prompt=PROMPT,\n",
    "                             refine_prompt=refine_prompt,\n",
    "                             verbose=True)\n",
    "'''\n",
    "이 방법은 첫 번째 데이터 청크에서 초기 프롬프트를 실행하여 일부 출력을 생성합니다. \n",
    "나머지 문서의 경우, 해당 출력이 다음 문서와 함께 전달되어 새 문서를 기반으로 출력을 수정하도록 LLM에 요청합니다.\n",
    "\n",
    "장점: 더 관련성 높은 컨텍스트를 가져올 수 있으며, MapReduceDocumentsChain보다 손실이 적을 수 있습니다.\n",
    "\n",
    "단점: StuffDocumentsChain보다 LLM에 대한 호출이 더 많이 필요합니다. \n",
    "     또한 호출은 독립적이지 않으므로 MapReduceDocumentsChain처럼 병렬로 실행할 수 없습니다.\n",
    "     또한 문서 순서에 대한 잠재적인 종속성이 있습니다.\n",
    "'''\n",
    "# chain.run(docs[:])\n",
    "res = chain({\"input_documents\": docs}, return_only_outputs=True)\n",
    "\n",
    "# refine chain 이렇게 생김\n",
    "# 프롬프트 하나 때리고 나서 refine 프롬프트를 또 때림 \n",
    "# verbose 기능으로 보면 알 수 있다\n",
    "# \n",
    "# issue: 아래처럼 issue인줄 알았는데 기능이었다 ㅋㅋㅋㅋㅋㅋ 이렇게 되는게 싫으면 chain_type=\"map_reduce\"로 하면 된다\n",
    "# fork and pull request로 기여해보자\n",
    "# To contribute to this project, please follow a \"fork and pull request\" workflow. Please do not try to push directly to this repo unless you are maintainer.\n",
    "# https://github.com/hwchase17/langchain/blob/master/.github/CONTRIBUTING.md\n",
    "\n",
    "# 요약 체인에서 제가 정의한 프롬프트로 요약을 진행하려고 하면, 먼저 사전에 정의된 refine.py 의 프롬프트가 1차적으로 실행된 뒤 제가 정의한 프롬프트가 2번째 부터 적용됩니다. \n",
    "# When I try to run the summarization with the prompts I defined in the summarization chain, the predefined prompts from refine.py are executed first, and then the prompts I defined are applied second. \n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intermediate_steps': ['인공신경망은 CPU가 잘하는 일이 아니며, 인공지능 개발에는 데이터가 필요하다. 인공신경망은 용량이 크고, NVIDIA GPU도 완벽한 칩은 아니며, 인공지능을 만들기 위해서는 여러 가지 아이디어를 사용한다. 인공신경망은 CPU보다는 GPU를 사용하며, 인공신경망은 입력값을 소수점으로 바꾼 다음 소수점 곱셈을 많이 사용한다.',\n",
       "  '인공신경망은 CPU보다는 GPU를 사용하며, 입력값을 소수점으로 바꾼 다음 소수점 곱셈을 많이 사용한다. 인공지능 개발에는 데이터가 필요하며, 인공신경망은 용량이 크고 NVIDIA GPU도 완벽한 칩은 아니다. 인공지능을 만들기 위해서는 여러 가지 아이디어를 사용한다. 인공신경망은 CPU가 잘하는 일이 아니며, 인공지능 기술은 CPU가 아닌 GPU와 같은 칩을 사용해야 한다. 인공신경망은 인간 뇌세포를 모방한 것이며, 연결관계를 수조개 모아놓으면 지성이 된다. 인공신경망을 만들기 위해서는 GPU를 사용하는 것이 좋으며, GPU를 사용하는 방법을 익히는 것이 중요하다.',\n",
       "  '인공신경망은 CPU보다는 GPU를 사용하며, 입력값을 소수점으로 바꾼 다음 소수점 곱셈을 많이 사용한다는 것이 기존 요약이었다. 인공지능 개발에는 데이터가 필요하며, 인공신경망은 용량이 크고 NVIDIA GPU도 완벽한 칩은 아니다. 인공신경망은 인간 뇌세포를 모방한 것이며, 연결관계를 수조개 모아놓으면 지성이 된다. 인공신경망을 만들기 위해서는 GPU를 사용하는 것이 좋으며, GPU를 사용하는 방법을 익히는 것이 중요하다는 것이다. 추가적으로, 인공지능을 만들기 위해서는 여러 가지 아이디어를 사용하며, 인공신경망은 CPU가 잘하는 일이 아니며, 인공지능 기술은 CPU가 아닌 GPU와 같은 칩을 사용해야 한다는 것이다. 또한, 메모리 중에 고용량, 고대역폭 메모리가 중요하며, 인공신경망의 용량이 크기 때문에 메모리 용량이 큰 것이 필요하다는 것이다.',\n",
       "  '인공신경망은 GPU를 사용하며, 데이터가 필요하다. 인공신경망은 인간 뇌세포를 모방한 것이며, GPU를 사용하는 것이 중요하다. 인공지능 개발에는 여러 가지 아이디어를 사용하며, CPU가 아닌 GPU와 같은 칩을 사용해야 한다. 메모리 중에 고용량, 고대역폭 메모리가 중요하며, 인공신경망의 용량이 크기 때문에 메모리 용량이 큰 것이 필요하다. 그러나 인공지능을 만들기 위해서는 데이터 쌍이 필요하며, 이를 찾는 것이 어렵다. GPT와 같은 언어모델은 요약을 잘하며, 이는 이미 인터넷에 많이 존재하는 데이터를 활용하기 때문이다. 그러나 GPT와 같은 모델을 사용하기 위해서는 데이터가 많이 필요하며, NVIDIA GPU와 같은 칩을 사용해야 한다. 이를 위해서는 새로운 반도체 기술이 필요하다.'],\n",
       " 'output_text': '인공신경망은 GPU를 사용하며, 데이터가 필요하다. 인공신경망은 인간 뇌세포를 모방한 것이며, GPU를 사용하는 것이 중요하다. 인공지능 개발에는 여러 가지 아이디어를 사용하며, CPU가 아닌 GPU와 같은 칩을 사용해야 한다. 메모리 중에 고용량, 고대역폭 메모리가 중요하며, 인공신경망의 용량이 크기 때문에 메모리 용량이 큰 것이 필요하다. 그러나 인공지능을 만들기 위해서는 데이터 쌍이 필요하며, 이를 찾는 것이 어렵다. GPT와 같은 언어모델은 요약을 잘하며, 이는 이미 인터넷에 많이 존재하는 데이터를 활용하기 때문이다. 그러나 GPT와 같은 모델을 사용하기 위해서는 데이터가 많이 필요하며, NVIDIA GPU와 같은 칩을 사용해야 한다. 이를 위해서는 새로운 반도체 기술이 필요하다.'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RefineDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.  \n",
      "\n",
      "Last year COVID-19 kept us apart. This year we are finally together again. \n",
      "\n",
      "Tonight, we meet as Democrats Republicans and Independents. But most importantly as Americans. \n",
      "\n",
      "With a duty to one another to the American people to the Constitution. \n",
      "\n",
      "And with an unwavering resolve that freedom will always triumph over tyranny. \n",
      "\n",
      "Six days ago, Russia’s Vladimir Putin sought to shake the foundations of the free world thinking he could make it bend to his menacing ways. But he badly miscalculated. \n",
      "\n",
      "He thought he could roll into Ukraine and the world would roll over. Instead he met a wall of strength he never imagined. \n",
      "\n",
      "He met the Ukrainian people. \n",
      "\n",
      "From President Zelenskyy to every Ukrainian, their fearlessness, their courage, their determination, inspires the world.\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY IN KOREAN:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary\n",
      "We have provided an existing summary up to a certain point: \n",
      "\n",
      "지난해 코로나로 인해 우리는 떨어져 있었습니다. 오늘 우리는 민주당, 공화당, 독립운동가로 모이고 있습니다. 우리는 서로, 미국 사람들, 헌법에 대한 의무를 가지고 있습니다. 러시아의 블라디미르 푸틴이 자유 세계의 \n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "He met the Ukrainian people. \n",
      "\n",
      "From President Zelenskyy to every Ukrainian, their fearlessness, their courage, their determination, inspires the world. \n",
      "\n",
      "Groups of citizens blocking tanks with their bodies. Everyone from students to retirees teachers turned soldiers defending their homeland. \n",
      "\n",
      "In this struggle as President Zelenskyy said in his speech to the European Parliament “Light will win over darkness.” The Ukrainian Ambassador to the United States is here tonight. \n",
      "\n",
      "Let each of us here tonight in this Chamber send an unmistakable signal to Ukraine and to the world. \n",
      "\n",
      "Please rise if you are able and show that, Yes, we the United States of America stand with the Ukrainian people. \n",
      "\n",
      "Throughout our history we’ve learned this lesson when dictators do not pay a price for their aggression they cause more chaos.   \n",
      "\n",
      "They keep moving.   \n",
      "\n",
      "And the costs and the threats to America and the world keep rising.\n",
      "------------\n",
      "Given the new context, refine the original summaryIf the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary\n",
      "We have provided an existing summary up to a certain point: \n",
      "\n",
      "지난해 코로나로 인해 우리는 떨어져 있었습니다. 오늘 우리는 민주당, 공화당, 독립운동가로 모이고 있습니다. 우리는 서로, 미국 사람들, 헌법에 대한 의무를 가지고 있습니다. 러시아의 블라디미르 푸틴이 자유 세계의\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "They keep moving.   \n",
      "\n",
      "And the costs and the threats to America and the world keep rising.   \n",
      "\n",
      "That’s why the NATO Alliance was created to secure peace and stability in Europe after World War 2. \n",
      "\n",
      "The United States is a member along with 29 other nations. \n",
      "\n",
      "It matters. American diplomacy matters. American resolve matters. \n",
      "\n",
      "Putin’s latest attack on Ukraine was premeditated and unprovoked. \n",
      "\n",
      "He rejected repeated efforts at diplomacy. \n",
      "\n",
      "He thought the West and NATO wouldn’t respond. And he thought he could divide us at home. Putin was wrong. We were ready.  Here is what we did.   \n",
      "\n",
      "We prepared extensively and carefully. \n",
      "\n",
      "We spent months building a coalition of other freedom-loving nations from Europe and the Americas to Asia and Africa to confront Putin. \n",
      "\n",
      "I spent countless hours unifying our European allies. We shared with the world in advance what we knew Putin was planning and precisely how he would try to falsely justify his aggression.  \n",
      "\n",
      "We countered Russia’s lies with truth.\n",
      "------------\n",
      "Given the new context, refine the original summaryIf the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n지난해 코로나로 인해 우리는 떨어져 있었습니다. 오늘 우리는 민주당, 공화당, 독립운동가로 모이고 있습니다. 우리는 서로, 미국 사람들, 헌법에 대한 의무를 가지고 있습니다. 러시아의 블라디미르 푸틴이 자유 세계의 '"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = load_summarize_chain(llm, chain_type=\"refine\", verbose=True)\n",
    "\n",
    "chain.run(stu_docs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogpt",
   "language": "python",
   "name": "autogpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
